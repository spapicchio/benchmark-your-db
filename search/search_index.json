{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#qatch-benchmarking-sql-centric-tasks-with-table-representation-learning-models-on-your-data","title":"QATCH: Benchmarking SQL-centric tasks with Table Representation Learning Models on Your Data","text":"<p>This Python library is the official implementation of QATCH: Benchmarking SQL-centric tasks with Table Representation Learning Models on Your Data to appear in NeurIPS Dataset and Benchmark track 2023.</p>"},{"location":"#overview","title":"\udb40\udc76\udb40\udc75\udb40\udc6d\udb40\udc61\udb40\udc70\udb40\udc7f Overview","text":"<ul> <li>What is QATCH? Query-Aided TRL Checklist (QATCH) is a toolbox to highlight TRL models\u2019 strengths   and weaknesses on prorietary tables for Question Answering (QA) and Semantic Parsing (SP).</li> <li>How does it work? Given a proprietary database as input, it generates a testing checklist for QA and SP.</li> <li>More specifically? A query generation algorithm crafts tests by means of the expressive power of SQL.</li> <li>Ok cool, that's it? To evaluate the model's predictions, we propose 5 new metrics intra and inter tuple.</li> <li>Where is processed the data? The data is processed locally. We do not store any data. If you use the ChatGPT   wrapper the data is processed by OpenAI.</li> </ul> QATCH usage pipeline. <p>QATCH's automatically generates and evaluates test checklists on TRL models based on the three-step process depicted below:</p> <ol> <li> <p>QATCH-Generate. It generates a set of queries tailored to proprietary data. For each query it formulates both the    SQL declaration, its free-text version, and the expected ground truth consisting of table instances.    The SQL declaration expresses the logical complexity of the query and reflects the presence/absence of specific    features peculiar to relational data model such as presence of missing values and duplicate values.</p> </li> <li> <p>TRL Model Predictions. It processes the tests for various TRL models and tasks. The current toolbox version    supports three Table Representation Learning (TRL) models for    QA: TAPAS, TAPEX    and Omnitab.    In addition, two LLMs are implemented for QA and SP ChatGPT 3.5 (need the API key)    and LLama2 (need the HuggingFace token).</p> </li> <li> <p>QATCH-Evaluate. It evaluates the models outputs according to a set of cross-task performance metrics.</p> </li> </ol> <p> </p> QATCH\u2019s metrics are computed between the model output (prediction) and expected  ground-truth results (target). The target is the answer of the NL question \"Show me all the data\" over a table with three tuples and two attributes."},{"location":"#who-should-use-qatch","title":"Who should use QATCH?","text":"<p>QATCH is designed to create \"behavioral testing\" checklist for QA and SP tasks. The checklist is used to understand in which case the models fail when processing proprietary data.</p> <p>In a corporate setting, there are at least three scenarios where a given TRL model needs to be evaluated against proprietary datasets:</p> <ul> <li>Comparison: Compare TRL models fine-tuned on private examples to see which one performs best.</li> <li>Validation: As crafting examples is expensive, verify when the quality meets the requirements.</li> <li>Maintenance: Fine-tuned models need to be re-calibrated to avoid data and conceptual shifting,   continuous evaluation helps the identification of this issue.</li> </ul> <p>But the usage of QATCH it is not limited to the TRL models. Indeed, we propose two scenarios where QATCH can be used with LLMs:</p> <ul> <li>LLM compatibility version: Compare different version of the same LLMs to see the best performing one.</li> <li>Prompt engineering: Analyse the best prompt definition based on the proprietary data.</li> </ul> <p> </p> Use case example of engineer Walter.  With QATCH it is able to create a model ranking on his proprietary data for QA and SP."},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the Apache 2.0 license. For more details,  see the <code>LICENSE</code> file in this repository.</p>"},{"location":"database_reader/","title":"Database Reader & Creation","text":""},{"location":"database_reader/#overview","title":"Overview","text":"<p>The database_reader package handles connections with the databases file.</p> <p>It contains two class:</p> <ul> <li>SingleDatabase: Given a dictionary of pandas dataframe, it creates the database folder with the database sqlite file.</li> <li>MultipleDatabases: Given the path where the databases are stored, it automatically creates the connection with the stored file. </li> </ul> <p>If the data is already stored in database sqlite files following this pattern \"db_save_path/db_id/db_id.sqlite\" you can create a connection between the tool and the files with MultipleDatabase class:</p> <pre><code>from qatch.database_reader import MultipleDatabases\n\n# The path to multiple databases\ndb_save_path = 'test_db'\ndatabases = MultipleDatabases(db_save_path)\n</code></pre> <p>Instead, if you want to specify different data you can use the SingleDatabase class  to create the sqlite databases in \"db_save_path/db_id/db_id.sqlite\"</p> <p>Assume the PKs have all different names. No two tables with the same PK name.</p> <pre><code>import pandas as pd\n\nfrom qatch.database_reader import SingleDatabase\n\n# Create dummy table\ndata = {\n    \"year\": [1896, 1900, 1904, 2004, 2008, 2012],\n    \"city\": [\"athens\", \"paris\", \"st. louis\", \"athens\", \"beijing\", \"london\"]\n}\ntable = pd.DataFrame.from_dict(data)\n\n# define the tables in the database (&lt;table_name&gt; : &lt;table&gt;)\ndb_tables = {'olympic_games': table}\n\n# define where to store the sqlite database\ndb_save_path = 'test_db'\n\n# define the name of the database\ndb_id = 'olympic'\n\n# define the PK\n# Assume the PKs have all different names. Two tables cannot have same PK name.\ntable2primary_key = {'olympic_games': 'id'}\n\n# create database connection\ndb = SingleDatabase(db_path=db_save_path, db_name=db_id, tables=db_tables, table2primary_key=table2primary_key)\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.MultipleDatabases","title":"<code>MultipleDatabases</code>","text":"<p>Manages multiple SQLite databases, allowing dynamic creation and access to individual databases.</p> <p>Attributes:</p> Name Type Description <code>db_path</code> <code>str</code> <p>The base path where the database files are stored.</p> <code>db_ids2db</code> <code>dict</code> <p>A dictionary where the key is the database name, and the value is the SingleDatabase object.</p> <code>_max_db_in_memory</code> <code>int</code> <p>The maximum number of databases to keep in memory. Default is 15.</p> Source code in <code>qatch/database_reader/multiple_databases.py</code> <pre><code>class MultipleDatabases:\n    \"\"\"Manages multiple SQLite databases, allowing dynamic creation and access to individual databases.\n\n    Attributes:\n        db_path (str): The base path where the database files are stored.\n        db_ids2db (dict): A dictionary where the key is the database name, and the value is the SingleDatabase object.\n        _max_db_in_memory (int): The maximum number of databases to keep in memory. Default is 15.\n    \"\"\"\n\n    def __init__(self, db_path: str, _max_db_in_memory=15):\n        self.db_path = db_path\n        self.db_ids2db: dict[str, SingleDatabase] = dict()\n        self._max_db_in_memory = _max_db_in_memory\n\n    def get_db_names(self) -&gt; list[str]:\n        \"\"\"Gets the name of the database file from the path.\n\n        Returns:\n            list[str]: A list of database file names.\n        \"\"\"\n        # return x only if it is a directory\n        return [x for x in os.listdir(self.db_path) if os.path.isdir(os.path.join(self.db_path, x))]\n\n    def __contains__(self, other: str) -&gt; bool:\n        # Checks if a database with the given name exists in the managed databases.\n        return any(other in db_id for db_id in self.db_ids2db)\n\n    def __getitem__(self, key: str) -&gt; SingleDatabase:\n        # Allows accessing a specific database by its name\n        # if the key does not exist, open the db\n        if key not in self.db_ids2db:\n            self.open_db(key)\n        return self.db_ids2db[key]\n\n    def open_db(self, db_id: str):\n        \"\"\"Opens a database with the given name and stores it in memory.\n\n        Args:\n            db_id (str): The name of the database to open.\n        \"\"\"\n        if db_id not in self.db_ids2db:\n            if len(self.db_ids2db) &gt;= self._max_db_in_memory:\n                # FIFO strategy if max reached\n                self.db_ids2db.popitem()\n            self.db_ids2db[db_id] = SingleDatabase(self.db_path, db_name=db_id)\n\n    def get_table(self, db_id: str, tbl_name: str) -&gt; pd.DataFrame:\n        \"\"\"Retrieves a specified table from the database as a Pandas DataFrame.\n\n        Args:\n            db_id (str): The name of the database.\n            tbl_name (str): The name of the table to retrieve from the database.\n\n        Returns:\n            pd.DataFrame: A Pandas DataFrame representing the specified table from the database.\n        \"\"\"\n        return self[db_id].get_table_given(tbl_name)\n\n    def get_schema(self, db_id: str, tbl_name: str) -&gt; pd.DataFrame:\n        \"\"\"Retrieves the schema of a specified table from the database.\n\n        Args:\n            db_id (str): The name of the database.\n            tbl_name (str): The name of the table to retrieve the schema from.\n\n        Returns:\n            pd.DataFrame: A Pandas DataFrame representing the schema of the specified table.\n        \"\"\"\n        return self[db_id].get_schema_given(tbl_name)\n\n    def get_all_table_schema_given(self, db_id: str) -&gt; dict[str, pd.DataFrame]:\n        \"\"\"Retrieves all the table schema from the database.\n\n        Args:\n            db_id (str): The name of the database.\n\n        Returns:\n            pd.DataFrame: A Pandas DataFrame representing the schema of the specified table.\n        \"\"\"\n\n        return self[db_id].table_schemas\n\n    def run_multiple_queries(self, db_id: str, queries: list) -&gt; list[list]:\n        \"\"\"Executes multiple queries on the specified database and returns the results.\n\n          Args:\n              db_id (str): The name of the database to execute the query on.\n              queries (list): The list of SQL queries to be executed on the database.\n\n          Returns:\n              list[list]: A list containing the query results.\n        \"\"\"\n        db = self[db_id]\n        queries_result = map(db.run_query, queries)\n        queries_result = list(map(lambda x: [list(item) for item in x], queries_result))\n        return queries_result\n\n    def run_query(self, db_id: str, query: str) -&gt; list | None:\n        \"\"\"Executes an SQL query on the specified database and returns the results.\n\n        Args:\n            db_id (str): The name of the database to execute the query on.\n            query (str): The SQL query to be executed on the database.\n\n        Returns:\n            list | None: A list containing the query results.\n        \"\"\"\n        ans_query = self[db_id].run_query(query)\n        return [list(x) for x in ans_query]\n\n    def close(self):\n        \"\"\"Closes all the opened databases and clears the memory.\"\"\"\n        [db.close_connection() for db in self.db_ids2db.values()]\n        self.db_ids2db = dict()\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.MultipleDatabases.close","title":"<code>close()</code>","text":"<p>Closes all the opened databases and clears the memory.</p> Source code in <code>qatch/database_reader/multiple_databases.py</code> <pre><code>def close(self):\n    \"\"\"Closes all the opened databases and clears the memory.\"\"\"\n    [db.close_connection() for db in self.db_ids2db.values()]\n    self.db_ids2db = dict()\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.MultipleDatabases.get_all_table_schema_given","title":"<code>get_all_table_schema_given(db_id)</code>","text":"<p>Retrieves all the table schema from the database.</p> <p>Parameters:</p> Name Type Description Default <code>db_id</code> <code>str</code> <p>The name of the database.</p> required <p>Returns:</p> Type Description <code>dict[str, DataFrame]</code> <p>pd.DataFrame: A Pandas DataFrame representing the schema of the specified table.</p> Source code in <code>qatch/database_reader/multiple_databases.py</code> <pre><code>def get_all_table_schema_given(self, db_id: str) -&gt; dict[str, pd.DataFrame]:\n    \"\"\"Retrieves all the table schema from the database.\n\n    Args:\n        db_id (str): The name of the database.\n\n    Returns:\n        pd.DataFrame: A Pandas DataFrame representing the schema of the specified table.\n    \"\"\"\n\n    return self[db_id].table_schemas\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.MultipleDatabases.get_db_names","title":"<code>get_db_names()</code>","text":"<p>Gets the name of the database file from the path.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of database file names.</p> Source code in <code>qatch/database_reader/multiple_databases.py</code> <pre><code>def get_db_names(self) -&gt; list[str]:\n    \"\"\"Gets the name of the database file from the path.\n\n    Returns:\n        list[str]: A list of database file names.\n    \"\"\"\n    # return x only if it is a directory\n    return [x for x in os.listdir(self.db_path) if os.path.isdir(os.path.join(self.db_path, x))]\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.MultipleDatabases.get_schema","title":"<code>get_schema(db_id, tbl_name)</code>","text":"<p>Retrieves the schema of a specified table from the database.</p> <p>Parameters:</p> Name Type Description Default <code>db_id</code> <code>str</code> <p>The name of the database.</p> required <code>tbl_name</code> <code>str</code> <p>The name of the table to retrieve the schema from.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A Pandas DataFrame representing the schema of the specified table.</p> Source code in <code>qatch/database_reader/multiple_databases.py</code> <pre><code>def get_schema(self, db_id: str, tbl_name: str) -&gt; pd.DataFrame:\n    \"\"\"Retrieves the schema of a specified table from the database.\n\n    Args:\n        db_id (str): The name of the database.\n        tbl_name (str): The name of the table to retrieve the schema from.\n\n    Returns:\n        pd.DataFrame: A Pandas DataFrame representing the schema of the specified table.\n    \"\"\"\n    return self[db_id].get_schema_given(tbl_name)\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.MultipleDatabases.get_table","title":"<code>get_table(db_id, tbl_name)</code>","text":"<p>Retrieves a specified table from the database as a Pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>db_id</code> <code>str</code> <p>The name of the database.</p> required <code>tbl_name</code> <code>str</code> <p>The name of the table to retrieve from the database.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A Pandas DataFrame representing the specified table from the database.</p> Source code in <code>qatch/database_reader/multiple_databases.py</code> <pre><code>def get_table(self, db_id: str, tbl_name: str) -&gt; pd.DataFrame:\n    \"\"\"Retrieves a specified table from the database as a Pandas DataFrame.\n\n    Args:\n        db_id (str): The name of the database.\n        tbl_name (str): The name of the table to retrieve from the database.\n\n    Returns:\n        pd.DataFrame: A Pandas DataFrame representing the specified table from the database.\n    \"\"\"\n    return self[db_id].get_table_given(tbl_name)\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.MultipleDatabases.open_db","title":"<code>open_db(db_id)</code>","text":"<p>Opens a database with the given name and stores it in memory.</p> <p>Parameters:</p> Name Type Description Default <code>db_id</code> <code>str</code> <p>The name of the database to open.</p> required Source code in <code>qatch/database_reader/multiple_databases.py</code> <pre><code>def open_db(self, db_id: str):\n    \"\"\"Opens a database with the given name and stores it in memory.\n\n    Args:\n        db_id (str): The name of the database to open.\n    \"\"\"\n    if db_id not in self.db_ids2db:\n        if len(self.db_ids2db) &gt;= self._max_db_in_memory:\n            # FIFO strategy if max reached\n            self.db_ids2db.popitem()\n        self.db_ids2db[db_id] = SingleDatabase(self.db_path, db_name=db_id)\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.MultipleDatabases.run_multiple_queries","title":"<code>run_multiple_queries(db_id, queries)</code>","text":"<p>Executes multiple queries on the specified database and returns the results.</p> <p>Parameters:</p> Name Type Description Default <code>db_id</code> <code>str</code> <p>The name of the database to execute the query on.</p> required <code>queries</code> <code>list</code> <p>The list of SQL queries to be executed on the database.</p> required <p>Returns:</p> Type Description <code>list[list]</code> <p>list[list]: A list containing the query results.</p> Source code in <code>qatch/database_reader/multiple_databases.py</code> <pre><code>def run_multiple_queries(self, db_id: str, queries: list) -&gt; list[list]:\n    \"\"\"Executes multiple queries on the specified database and returns the results.\n\n      Args:\n          db_id (str): The name of the database to execute the query on.\n          queries (list): The list of SQL queries to be executed on the database.\n\n      Returns:\n          list[list]: A list containing the query results.\n    \"\"\"\n    db = self[db_id]\n    queries_result = map(db.run_query, queries)\n    queries_result = list(map(lambda x: [list(item) for item in x], queries_result))\n    return queries_result\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.MultipleDatabases.run_query","title":"<code>run_query(db_id, query)</code>","text":"<p>Executes an SQL query on the specified database and returns the results.</p> <p>Parameters:</p> Name Type Description Default <code>db_id</code> <code>str</code> <p>The name of the database to execute the query on.</p> required <code>query</code> <code>str</code> <p>The SQL query to be executed on the database.</p> required <p>Returns:</p> Type Description <code>list | None</code> <p>list | None: A list containing the query results.</p> Source code in <code>qatch/database_reader/multiple_databases.py</code> <pre><code>def run_query(self, db_id: str, query: str) -&gt; list | None:\n    \"\"\"Executes an SQL query on the specified database and returns the results.\n\n    Args:\n        db_id (str): The name of the database to execute the query on.\n        query (str): The SQL query to be executed on the database.\n\n    Returns:\n        list | None: A list containing the query results.\n    \"\"\"\n    ans_query = self[db_id].run_query(query)\n    return [list(x) for x in ans_query]\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.SingleDatabase","title":"<code>SingleDatabase</code>","text":"<p>Provides a simplified interface for interacting with SQLite databases in Python.</p> <p>Note: If the database already exist, do not replace the tables</p> <p>Attributes:</p> Name Type Description <code>conn</code> <code>Connection</code> <p>A connection object representing the SQLite database.</p> <code>cursor</code> <code>Cursor</code> <p>A cursor object used to execute SQL commands and retrieve results.</p> <code>db_name</code> <code>str</code> <p>The name of the database.</p> <code>table_schemas</code> <code>Dict[str, DataFrame]</code> <p>Table name as key, table schema as value. Table schema is a Pandas DataFrame with columns: cid, name, type, notnull, dflt_value, pk.</p> <code>table_names</code> <code>str</code> <p>The names of the tables in the database.</p> <code>db_path</code> <code>str</code> <p>Path to the folder which contains the SQLite file.</p> <code>db_path_sqlite</code> <code>str</code> <p>Path to the SQLite file.</p> Source code in <code>qatch/database_reader/single_database.py</code> <pre><code>class SingleDatabase:\n    \"\"\"Provides a simplified interface for interacting with SQLite databases in Python.\n\n    Note: If the database already exist, do not replace the tables\n\n    Attributes:\n        conn (sqlite3.Connection): A connection object representing the SQLite database.\n        cursor (sqlite3.Cursor): A cursor object used to execute SQL commands and retrieve results.\n        db_name (str): The name of the database.\n        table_schemas (Dict[str, pd.DataFrame]): Table name as key, table schema as value.\n            Table schema is a Pandas DataFrame with columns: cid, name, type, notnull, dflt_value, pk.\n        table_names (str): The names of the tables in the database.\n        db_path (str): Path to the folder which contains the SQLite file.\n        db_path_sqlite (str): Path to the SQLite file.\n    \"\"\"\n\n    def __init__(self, db_path: str, db_name: str,\n                 tables: dict[str, pd.DataFrame] | None = None,\n                 table2primary_key: dict[str, str] | None = None):\n        # Get the valid directory for the database\n        self.db_path = self._ensure_valid_directory(db_path, db_name)\n        # Store the name of the database\n        self.db_name = db_name\n        # Create the final path for the SQLite database file\n        self.db_path_sqlite = os.path.join(self.db_path, f'{db_name}.sqlite')\n        # Get the existing table names in the database\n        self.table_names = self._get_existing_table_names()\n        # If there are no existing tables\n        if not self.table_names:\n            # If no tables dictionary is provided\n            if not tables:\n                raise ValueError(f\"No tables provided and no database found at \"\n                                 f\"{self.db_path_sqlite}\")\n            # Otherwise, set the tables in the database\n            self.set_tables_in_db(tables, table2primary_key)\n            # Get the table names from the provided dictionary\n            self.table_names = list(tables.keys())\n            # Logs that the tables are stored in the database\n            logging.info(f\"Tables stored in {self.db_path_sqlite}\")\n\n        # Store the dictionary mapping table names to their primary keys\n        self.table2primary_key = table2primary_key\n        # Get the schemas of the tables\n        self.table_schemas = self._get_table_schemas()\n\n    @contextlib.contextmanager\n    def connect_cursor(self):\n        with sqlite3.connect(self.db_path_sqlite) as conn:\n            conn.text_factory = lambda b: b.decode(errors='ignore')\n            yield conn.cursor()\n\n    @staticmethod\n    def _ensure_valid_directory(db_path: str, db_name: str) -&gt; str:\n        \"\"\"Ensures the db_path/db_name exist, create if necessary\"\"\"\n        if db_path in ('', '.', './'):\n            db_path = os.getcwd()\n\n        full_path = os.path.join(db_path, db_name)\n        os.makedirs(full_path, exist_ok=True)\n        return full_path\n\n    def _get_table_schemas(self) -&gt; dict[str, pd.DataFrame]:\n        \"\"\"Retrieve schemas for all the tables in the SQLite database\"\"\"\n        with self.connect_cursor() as cursor:\n            table_names = self._get_existing_table_names()\n            return {tbl_name: pd.read_sql_query(f'PRAGMA table_info(\"{tbl_name}\")', cursor.connection)\n                    for tbl_name in self.table_names}\n\n    def _get_existing_table_names(self) -&gt; list[str]:\n        \"\"\"Retrieve the table name in the SQLite database\"\"\"\n        with self.connect_cursor() as cursor:\n            cursor.execute('SELECT name from sqlite_master where type= \"table\"')\n            return [tbl[0] for tbl in cursor.fetchall()]\n\n    def set_tables_in_db(self, tables: dict[str, pd.DataFrame] | None,\n                         table2primary_key: dict[str, str] | None):\n        \"\"\"\n        Sets the tables in the SQLite database represented by the given connection object.\n\n        This method takes a dictionary of tables in which keys are table names and values are Pandas DataFrames\n        representing the tables, and sets these tables in the SQLite database represented by the `conn` object.\n\n        The optional `table2primary_key` argument can be used to set primary keys for some or all tables.\n        If not provided, all tables are created without primary keys.\n        If the table contains an attribute with the same name of a primary key, a foreign key relationship is created.\n\n        Note:\n            - If a table is named as 'table', the method will replace its name with 'my_table'.\n            - Assume the PKs have all different names. two tables must have different PK names.\n\n        Args:\n            tables (Optional[Dict[str, pd.DataFrame]]): A dictionary of tables to set in the SQLite database.\n                Keys are table names and values are corresponding Pandas DataFrames.\n\n            table2primary_key (Optional[Dict[str, str]]): A dictionary mapping table names to primary keys.\n                For example, if you want to set the primary key of table `A` to be `Key_1`, you should pass\n                `table2primary_key={'A': 'Key_1'}`. Default is None.\n        \"\"\"\n        with self.connect_cursor() as cursor:\n            conn = cursor.connection\n            for name, table in tables.items():\n                if name == 'table':\n                    name = 'my_table'\n                if not table2primary_key:\n                    table.to_sql(name, conn, if_exists='replace', index=False)\n                else:\n                    create_table_string = SingleDatabase._create_table_in_db(name, table, table2primary_key)\n                    conn.cursor().execute(create_table_string)\n                    table.to_sql(name, conn, if_exists='append', index=False)\n\n    @staticmethod\n    def _create_table_in_db(name, table, table2primary_key):\n        \"\"\"\n        Returns a SQLite CREATE TABLE command as a string, constructed based on the given table name, DataFrame,\n        and primary_key2table dict.\n\n        This method first converts pandas DataFrame dtypes to SQLite data types.\n        Then, a SQLite CREATE TABLE command is built step by step.\n        The command includes creating simple columns, adding primary keys, and creating foreign key relationships.\n        Finally, the CREATE TABLE command is returned as a string.\n\n        Args:\n             name (str): The name of the table to be created in SQLite database.\n             table (pd.DataFrame): A pandas DataFrame holding the data and structure of the SQL table.\n                                  The dtype of each column translated to SQLite data types.\n             table2primary_key (dict): A dictionary where the keys are the names of columns of the table,\n                                        and the values are the names of the tables they are primary keys to.\n\n        Example:\n            &gt;&gt;&gt; import pandas as pd\n            &gt;&gt;&gt; from qatch.database_reader import SingleDatabase\n\n            &gt;&gt;&gt; name = 'sample_table'\n            &gt;&gt;&gt; table = pd.DataFrame({\n            &gt;&gt;&gt;    'id': [1, 2, 3],\n            &gt;&gt;&gt;    'name': ['Alice', 'Bob', 'Charlie'],\n            &gt;&gt;&gt;})\n            &gt;&gt;&gt;primary_key2table = {\n            &gt;&gt;&gt;    'sample_table_id': 'sample_table'\n            &gt;&gt;&gt;}\n            &gt;&gt;&gt;print(SingleDatabase._create_table_in_db(name,table,primary_key2table))\n            &gt;&gt;&gt;# Outputs: CREATE TABLE `sample_table`( \"id\" INTEGER, \"name\" TEXT, PRIMARY KEY (\"id\") );\n        \"\"\"\n\n        def convert_pandas_dtype_to_sqlite_type(type_):\n            if 'int' in type_:\n                return 'INTEGER'\n            if 'float' in type_:\n                return 'REAL'\n            if 'object' in type_ or 'date' in type_:\n                return 'TEXT'\n\n        primary_key2table = {tbl_PK: tbl_name for tbl_name, tbl_PK in\n                             table2primary_key.items()} if table2primary_key else None\n        column2type = {k: convert_pandas_dtype_to_sqlite_type(str(table.dtypes[k]))\n                       for k in table.dtypes.index}\n        create_table = [f'CREATE TABLE `{name}`(']\n        # add simple col\n        # \"Round\" real,\n        [create_table.append(f'\"{col}\" {column2type[col]},') for col in table.columns]\n        # Add primary key and foreign key\n        for col in table.columns:\n            if col in primary_key2table:\n                if name == primary_key2table[col]:\n                    # PRIMARY KEY (\"Round\"),\n                    create_table.append(f'PRIMARY KEY (\"{col}\"),')\n                else:\n                    # FOREIGN KEY (`Winning_Aircraft`) REFERENCES `aircraft`(`Aircraft_ID`),\n                    create_table.append(f'FOREIGN KEY (`{col}`) REFERENCES `{primary_key2table[col]}`(`{col}`),')\n        # remove last comma\n        create_table[-1] = create_table[-1][:-1]\n        # add closing statement\n        create_table.append(');')\n        return \" \".join(create_table)\n\n    def get_table_given(self, table_name: str) -&gt; pd.DataFrame:\n        \"\"\"\n        Retrieves a specified table from the database as a Pandas DataFrame.\n\n        Args:\n            table_name (str): The name of the table to retrieve from the database.\n\n        Returns:\n            pd.DataFrame: A Pandas DataFrame representing the specified table from the database.\n        \"\"\"\n        with self.connect_cursor() as cursor:\n            conn = cursor.connection\n            return pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n\n    def get_schema_given(self, table_name: str) -&gt; pd.DataFrame:\n        \"\"\"\n        Given the table name, returns the schema of the table.\n        Table schema is a Pandas DataFrame with columns: cid, name, type, notnull, dflt_value, pk.\n\n        Args:\n            table_name (str): The name of the table to retrieve the schema from the database.\n\n        Returns:\n            pd.DataFrame: A Pandas DataFrame representing the schema of the specified table from the database.\n        \"\"\"\n        return self.table_schemas[table_name]\n\n    def run_query(self, query: str) -&gt; list[list]:\n        \"\"\"\n        Run a query on the database and return the result.\n\n        Args:\n            query (str): The SQL query to be executed on the database.\n        Returns:\n            list[list]: A list of lists representing the result of the SQL query.\n        \"\"\"\n        with self.connect_cursor() as cursor:\n            try:\n                cursor.execute(query)\n                output = cursor.fetchall()\n                if not output:\n                    logging.warning(f'No query result for this query: {query}')\n                return output\n            except sqlite3.OperationalError as e:\n                logging.error(f\"Error while executing query: {query}\")\n                logging.error(e)\n                raise\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.SingleDatabase.get_schema_given","title":"<code>get_schema_given(table_name)</code>","text":"<p>Given the table name, returns the schema of the table. Table schema is a Pandas DataFrame with columns: cid, name, type, notnull, dflt_value, pk.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to retrieve the schema from the database.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A Pandas DataFrame representing the schema of the specified table from the database.</p> Source code in <code>qatch/database_reader/single_database.py</code> <pre><code>def get_schema_given(self, table_name: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Given the table name, returns the schema of the table.\n    Table schema is a Pandas DataFrame with columns: cid, name, type, notnull, dflt_value, pk.\n\n    Args:\n        table_name (str): The name of the table to retrieve the schema from the database.\n\n    Returns:\n        pd.DataFrame: A Pandas DataFrame representing the schema of the specified table from the database.\n    \"\"\"\n    return self.table_schemas[table_name]\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.SingleDatabase.get_table_given","title":"<code>get_table_given(table_name)</code>","text":"<p>Retrieves a specified table from the database as a Pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to retrieve from the database.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A Pandas DataFrame representing the specified table from the database.</p> Source code in <code>qatch/database_reader/single_database.py</code> <pre><code>def get_table_given(self, table_name: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Retrieves a specified table from the database as a Pandas DataFrame.\n\n    Args:\n        table_name (str): The name of the table to retrieve from the database.\n\n    Returns:\n        pd.DataFrame: A Pandas DataFrame representing the specified table from the database.\n    \"\"\"\n    with self.connect_cursor() as cursor:\n        conn = cursor.connection\n        return pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.SingleDatabase.run_query","title":"<code>run_query(query)</code>","text":"<p>Run a query on the database and return the result.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The SQL query to be executed on the database.</p> required <p>Returns:     list[list]: A list of lists representing the result of the SQL query.</p> Source code in <code>qatch/database_reader/single_database.py</code> <pre><code>def run_query(self, query: str) -&gt; list[list]:\n    \"\"\"\n    Run a query on the database and return the result.\n\n    Args:\n        query (str): The SQL query to be executed on the database.\n    Returns:\n        list[list]: A list of lists representing the result of the SQL query.\n    \"\"\"\n    with self.connect_cursor() as cursor:\n        try:\n            cursor.execute(query)\n            output = cursor.fetchall()\n            if not output:\n                logging.warning(f'No query result for this query: {query}')\n            return output\n        except sqlite3.OperationalError as e:\n            logging.error(f\"Error while executing query: {query}\")\n            logging.error(e)\n            raise\n</code></pre>"},{"location":"database_reader/#qatch.database_reader.SingleDatabase.set_tables_in_db","title":"<code>set_tables_in_db(tables, table2primary_key)</code>","text":"<p>Sets the tables in the SQLite database represented by the given connection object.</p> <p>This method takes a dictionary of tables in which keys are table names and values are Pandas DataFrames representing the tables, and sets these tables in the SQLite database represented by the <code>conn</code> object.</p> <p>The optional <code>table2primary_key</code> argument can be used to set primary keys for some or all tables. If not provided, all tables are created without primary keys. If the table contains an attribute with the same name of a primary key, a foreign key relationship is created.</p> Note <ul> <li>If a table is named as 'table', the method will replace its name with 'my_table'.</li> <li>Assume the PKs have all different names. two tables must have different PK names.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>tables</code> <code>Optional[Dict[str, DataFrame]]</code> <p>A dictionary of tables to set in the SQLite database. Keys are table names and values are corresponding Pandas DataFrames.</p> required <code>table2primary_key</code> <code>Optional[Dict[str, str]]</code> <p>A dictionary mapping table names to primary keys. For example, if you want to set the primary key of table <code>A</code> to be <code>Key_1</code>, you should pass <code>table2primary_key={'A': 'Key_1'}</code>. Default is None.</p> required Source code in <code>qatch/database_reader/single_database.py</code> <pre><code>def set_tables_in_db(self, tables: dict[str, pd.DataFrame] | None,\n                     table2primary_key: dict[str, str] | None):\n    \"\"\"\n    Sets the tables in the SQLite database represented by the given connection object.\n\n    This method takes a dictionary of tables in which keys are table names and values are Pandas DataFrames\n    representing the tables, and sets these tables in the SQLite database represented by the `conn` object.\n\n    The optional `table2primary_key` argument can be used to set primary keys for some or all tables.\n    If not provided, all tables are created without primary keys.\n    If the table contains an attribute with the same name of a primary key, a foreign key relationship is created.\n\n    Note:\n        - If a table is named as 'table', the method will replace its name with 'my_table'.\n        - Assume the PKs have all different names. two tables must have different PK names.\n\n    Args:\n        tables (Optional[Dict[str, pd.DataFrame]]): A dictionary of tables to set in the SQLite database.\n            Keys are table names and values are corresponding Pandas DataFrames.\n\n        table2primary_key (Optional[Dict[str, str]]): A dictionary mapping table names to primary keys.\n            For example, if you want to set the primary key of table `A` to be `Key_1`, you should pass\n            `table2primary_key={'A': 'Key_1'}`. Default is None.\n    \"\"\"\n    with self.connect_cursor() as cursor:\n        conn = cursor.connection\n        for name, table in tables.items():\n            if name == 'table':\n                name = 'my_table'\n            if not table2primary_key:\n                table.to_sql(name, conn, if_exists='replace', index=False)\n            else:\n                create_table_string = SingleDatabase._create_table_in_db(name, table, table2primary_key)\n                conn.cursor().execute(create_table_string)\n                table.to_sql(name, conn, if_exists='append', index=False)\n</code></pre>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#installation","title":"Installation","text":"<p>First need to install QATCH. You can do this by running the following command:</p> <pre><code># Using poetry (recommended)\npoetry add QATCH\n\n# Using pip\npip install QATCH \n</code></pre> <p>Since QATCH is intended to be used without the inference step, the base installation does not come with the models' requirements. However, in case you want to use our implementation you can add the extras requirements.</p> <pre><code># Using poetry (recommended)\npoetry add QATCH -E model\n\n# Using pip\npip install QATCH[model] \n</code></pre>"},{"location":"getting_started/#create-connection-with-input-data","title":"Create connection with input data","text":"<p>Once you have installed QATCH, you need to create a connection between your data and the tool. If your data is not stored in a sqlite database you can use our code to generate it. If this is not the case, you can skip this passage.</p> <p><pre><code>import pandas as pd\n\nfrom qatch.database_reader import SingleDatabase\n\n# Create dummy table\ndata = {\n    \"id\": [0, 1, 2, 3, 4, 5],\n    \"year\": [1896, 1900, 1904, 2004, 2008, 2012],\n    \"city\": [\"athens\", \"paris\", \"st. louis\", \"athens\", \"beijing\", \"london\"]\n}\ntable = pd.DataFrame.from_dict(data)\n\n# define the tables in the database (&lt;table_name&gt; : &lt;table&gt;)\ndb_tables = {'olympic_games': table}\n\n# Assume the PKs have all different names. Two tables cannot have same PK name.\ntable2primary_key = {'olympic_games': 'id'}\n# define where to store the sqlite database\ndb_save_path = 'test_db'\n\n# define the name of the database\ndb_id = 'olympic'\n\n# create database connection\ndb = SingleDatabase(db_path=db_save_path, db_name=db_id, tables=db_tables, table2primary_key=table2primary_key)\n</code></pre> This class will create the sqlite database in \"db_save_path/db_id/db_id.sqlite\".</p> <p>Once you have the database stored in this format \"db_save_path/db_id/db_id.sqlite\", you can create a connection in the following way:</p> <pre><code>from qatch.database_reader import MultipleDatabases\n\n# The path to multiple databases\ndb_save_path = 'test_db'\ndatabases = MultipleDatabases(db_save_path)\n</code></pre> <p>This class automatically detects the available databases and handle the communication between the code and the sqlite files.</p>"},{"location":"getting_started/#step-1-qatch-generate","title":"Step 1: QATCH generate","text":"<pre><code>from qatch import TestGenerator\n\n# init generator\ntest_generator = TestGenerator(databases=databases)\n\n# generate tests for each database and for each generator\ntests_df = test_generator.generate()\n</code></pre> <p>Test generator automatically creates a checklist based on the proprietary data. The tests_df dataframe contains:</p> <ul> <li>db_id: The database name associated with the test.</li> <li>tbl_name: The table name associated with the test.</li> <li>sql_tags: the SQL generator used to create the test.</li> <li>query: The generated query. Used to evaluate the model.</li> <li>question: The generated question associated with the query. Used as input for the model.</li> </ul>"},{"location":"getting_started/#step-2-trl-model-predictions","title":"Step 2: TRL model predictions","text":"<p>QATCH is intended to be used without the inference step. However, it supports several models for reproducibility reason.</p> <pre><code>from tqdm import tqdm\n\nfrom qatch.models import Tapas\n\n# init the model \nmodel = Tapas(model_name=\"google/tapas-large-finetuned-wtq\")\n\n# iterate for each row and run prediction\ntqdm.pandas(desc=f'Predicting for {model.name}')\ntests_df[f'predictions_{model.name}'] = tests_df.progress_apply(\n    lambda row: model.predict(table=databases.get_table(db_id=row['db_id'], tbl_name=row['tbl_name']),\n                              query=row['question'], tbl_name=row['tbl_name']),\n    axis=1\n)\n</code></pre> <p>Since Tapas, Tapex, Omnitab and LLama2 are based on huggingFace, the model_name parameter can be any possible name associate with the model in the hub.</p> <p>To use ChatGPT_QA or ChatGPT_SP you need to provide the API credentials:</p> <pre><code>from qatch.models import ChatGPT_QA\n\nmodel = ChatGPT_QA(model_name=\"gpt-3.5-turbo-0613\",\n                   api_key=\"your_api_key_chatgpt\",\n                   api_org=\"your_api_org_chatgpt\")\n</code></pre> <p>To use LLama2_QA or LLama2_SP you need to specify the HuggingFace token</p> <p><pre><code>from qatch.models import LLama2_QA\n\nmodel = LLama2_QA(model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n                  hugging_face_token=\"your_hugging_face_token\")\n</code></pre> The tests_df dataframe after the prediction phase contains:</p> <ul> <li>db_id: The database name associated with the test.</li> <li>tbl_name: The table name associated with the test.</li> <li>sql_tags: the SQL generator used to create the test.</li> <li>query: The generated query. Used to evaluate the model.</li> <li>question: The generated question associated with the query. Used as input for the model.</li> <li>predictions_: The predicted query/cells based on the task (SP or QA respectively)"},{"location":"getting_started/#step-3-qatch-evaluate","title":"Step 3: QATCH evaluate","text":"<p>QATCH MetricEvaluator is composed of 5 metrics (3 intra-tuple and 2 inter-tuple).</p> <p><pre><code>from qatch import MetricEvaluator\n\nevaluator = MetricEvaluator(databases=databases)\ntests_df = evaluator.evaluate_with_df(tests_df,\n                                      prediction_col_name=\"&lt;prediction_col_name&gt;\",\n                                      task=\"QA\")\n</code></pre> The final dataframe contains:</p> <ul> <li>db_id: The database name associated with the test.</li> <li>tbl_name: The table name associated with the test.</li> <li>sql_tags: the SQL generator associated with the test.</li> <li>query: The generated query from step 1.</li> <li>question: The generated question from step 1. Used as input for the model.</li> <li>predictions_: The predicted query/cells from step 2. <li>5 metrics: The metrics used to evaluate the models.</li>"},{"location":"metrics/","title":"QATCH Evaluate","text":""},{"location":"metrics/#qatch.metric_evaluator.MetricEvaluator","title":"<code>MetricEvaluator</code>","text":"<p>Class for evaluating SQL query prediction metrics using target results and predicted outputs.</p> <p>Attributes:</p> Name Type Description <code>databases</code> <code>MultipleDatabases</code> <p>Object representing database connections. This attribute stores information about multiple database connections.</p> <code>metrics</code> <code>list[str]</code> <p>List of metric names to be evaluated. Default metrics include: ['cell_precision', 'cell_recall', 'tuple_cardinality', 'tuple_constraint', 'tuple_order']</p> Source code in <code>qatch/metric_evaluator.py</code> <pre><code>class MetricEvaluator:\n    \"\"\"\n    Class for evaluating SQL query prediction metrics using target results and predicted outputs.\n\n    Attributes:\n        databases (MultipleDatabases): Object representing database connections.\n            This attribute stores information about multiple database connections.\n\n        metrics (list[str]): List of metric names to be evaluated. Default metrics include:\n            ['cell_precision', 'cell_recall', 'tuple_cardinality', 'tuple_constraint', 'tuple_order']\n    \"\"\"\n\n    def __init__(self, databases: MultipleDatabases, metrics: list[str] | str | None = None):\n        if metrics is None:\n            metrics = ['cell_precision', 'cell_recall',\n                       'tuple_cardinality', 'tuple_constraint',\n                       'tuple_order']\n\n        self.metrics = metrics if isinstance(metrics, list) else [metrics]\n\n        self._tags_generator = {\n            'cell_precision': CellPrecisionTag(),\n            'cell_recall': CellRecallTag(),\n            'tuple_cardinality': TupleCardinalityTag(),\n            'tuple_constraint': TupleConstraintTag(),\n            'tuple_order': TupleOrderTag(),\n        }\n        self.databases = databases\n\n    def evaluate_with_df(self, df, prediction_col_name: str, task: str, target_col_name: str = 'query',\n                         keep_target: bool = False\n                         ) -&gt; pd.DataFrame:\n        \"\"\"Evaluates SQL queries for various metrics including cell precision, cell recall,\n        tuple cardinality, tuple constraint, tuple order.\n\n        For each row in the input DataFrame, it evaluates either the task as a QA\n        (Question Answering) or SP (Semantic Parsing). Then, it concatenates the original DataFrame\n        and the evaluated metric DataFrame.\n\n        Args:\n            df (pd.DataFrame): Input DataFrame where each row represents a test.\n            prediction_col_name (str): Name of the column in the DataFrame that contains predictions.\n            task (str): Type of evaluation task. Could be `QA` or `SP`.\n            target_col_name (str): Name of the column in the DataFrame that contains target queries.\n            Default is `'query'`.\n            keep_target (bool): FALSE by default. If TRUE, keeps the target query.\n\n        Returns:\n            pd.DataFrame: Output DataFrame that has the original DataFrame along with the evaluated metric DataFrame.\n        \"\"\"\n        if task.upper() == 'QA':\n            # add the new metrics at the bottom of the dataframe\n            df_metrics = df.apply(lambda row: self.evaluate_single_test_QA(row.to_dict(),\n                                                                           prediction_col_name,\n                                                                           target_col_name),\n                                  axis=1, result_type='expand')\n        else:\n            df_metrics = df.apply(lambda row: self.evaluate_single_test_SP(row.to_dict(),\n                                                                           prediction_col_name,\n                                                                           target_col_name), axis=1,\n                                  result_type='expand')\n        return pd.concat([df, df_metrics], axis=1).replace({np.nan: None})\n\n    def evaluate_single_test_QA(self, test: dict, prediction_col_name: str, target_col_name: str) -&gt; dict:\n        \"\"\"\n        Evaluates metric scores on a single test QA task where a test is a dictionary (or pd.Series) and the\n        `prediction_col_name` and `target_col_name` are the column names in the test data containing model predictions\n        and actual target values respectively.\n\n        Args:\n            test (dict | pd.Series): A dictionary or pandas Series containing a single test data. The keys (columns for Series)\n                should include `prediction_col_name` and `target_col_name`.\n            prediction_col_name (str): String representing the key in `test` dictionary (or column in `test` pandas Series)\n                where the predicted values are.\n            target_col_name (str): String representing the key in `test` dictionary (or column in `test` pandas Series)\n                where the actual target values are.\n\n        Returns:\n            dict: A dictionary with keys are metric name and value is the evaluated metric score for each metric in `self.metrics`.\n\n        Examples:\n            &gt;&gt;&gt; eval_task = MetricEvaluator(databases, metrics=['cell_precision', 'cell_recall'])\n            &gt;&gt;&gt; test = {\"sql_tags\": \"SELECT\",\n            ...         \"prediction\": [[\"wales\", \"scotland\"], [\"england\"]],\n            ...         \"target\": [[\"scotland\", \"wales\"], [\"england\"]]}\n            &gt;&gt;&gt; prediction_col_name = \"prediction\"\n            &gt;&gt;&gt; target_col_name = \"target\"\n            &gt;&gt;&gt;result = eval_task.evaluate_single_test_QA(test, prediction_col_name, target_col_name)\n            &gt;&gt;&gt; print(result)\n            {'cell_precision_prediction': 0.66, 'cell_recall_prediction': 1.0}\n\n        Notes:\n            In the above example, `cell_precision_prediction` is calculated as 2/3 = 0.66,\n            \"wales\" and \"scotland\" are in the correct position.\n            `cell_recall_prediction` is 2/2 = 1, all actual outcomes are included in the prediction.\n        \"\"\"\n\n        # Runs the target query on the database\n        new_target_col = f'{target_col_name}_result'\n        try:\n            test[new_target_col] = self.databases.run_query(test['db_id'], test[target_col_name])\n        except sqlite3.Error as e:\n            # catch any possible error of prediction and return all zeros\n            logging.error(e)\n            return {f'{metric}_{prediction_col_name}': 0 for metric in self.metrics}\n\n        metric2evaluation = {f'{metric}_{prediction_col_name}': None for metric in self.metrics}\n        for metric in self.metrics:\n            generator = self._tags_generator[metric]\n            # initialize the metric column\n            # evaluate the metric only for the test where the prediction is not equal to the target\n            tqdm.pandas(desc=f'Evaluating {metric}')\n            if metric == 'tuple_order' and 'order by' not in test[target_col_name].lower():\n                continue\n            evaluation = generator.evaluate_single_test_metric(test[new_target_col], test[prediction_col_name])\n            metric2evaluation[f'{metric}_{prediction_col_name}'] = evaluation\n        return metric2evaluation\n\n    def evaluate_single_test_SP(self, test: dict, prediction_col_name: str, target_col_name: str) -&gt; dict:\n        \"\"\"\n        Evaluates metrics for a single SQL prediction test by fetching the results of the predicted and\n        target queries from the database.\n\n        This function fetches results based on provided `prediction_col_name` and `target_col_name`. Then it evaluates\n        performance of the prediction by invoking `evaluate_single_test_QA`.\n\n        Args:\n            self (MetricEvaluator): The object instance the method is called on.\n            test (dict | pd.Series): The test data as a dictionary or pandas Series. It contains the 'db_id' (database identifier).\n                                     It is expected to have 'predictions_SP' and 'target_SP' keys/columns updated in process.\n            prediction_col_name (str): The name of column where prediction is stored.\n            target_col_name (str): The name of column where the target is stored.\n\n        Returns:\n            dict: A dictionary containing evaluation results obtained from `evaluate_single_test_QA`.\n\n        Notes:\n            If the predicted query cannot be run on the db, the resulting metrics are all zeros\n\n        Examples:\n            &gt;&gt;&gt; test = {'db_id': 'database1', 'target': 'SELECT DISTINCT emailisfree FROM fraud', 'prediction': 'SELECT emailsisfree, income FROM fraud'}\n            &gt;&gt;&gt; evaluator = MetricEvaluator(databases)\n            &gt;&gt;&gt; results = evaluator.evaluate_single_test_SP(test, 'prediction', 'target')\n            &gt;&gt;&gt; print(results)\n            {'cell_precision_prediction': 0.50, 'cell_recall_prediction': 1.0}\n        \"\"\"\n        # Compares the target and predicted SQL queries after cleaning and formatting. If they are identical, it returns metrics as 1\n        if self.are_cleaned_sql_identical(test[target_col_name], test[prediction_col_name]):\n            metrics_result = {f'{metric}_{prediction_col_name}': 1 for metric in self.metrics}\n            metrics_result[f'tuple_order_{prediction_col_name}'] = None \\\n                if 'order' not in test[target_col_name].lower() else 1\n            return metrics_result\n\n        # Tries to run the predicted query on the database. If there is an error (e.g. syntax error in the query),\n        # it logs the error and returns metrics as 0\n        try:\n            test[prediction_col_name] = self.databases.run_query(test['db_id'], test[prediction_col_name])\n        except sqlite3.Error as e:\n            # catch any possible error of prediction and return all zeros\n            logging.error(e)\n            return {f'{metric}_{prediction_col_name}': 0 for metric in self.metrics}\n        # Evaluates the results of the target and predicted queries using the evaluate_single_test_QA function\n        return self.evaluate_single_test_QA(test, prediction_col_name, target_col_name)\n\n    @staticmethod\n    def are_cleaned_sql_identical(target: str, prediction: str) -&gt; bool:\n        \"\"\"\n        Create a mask based on whether the target and prediction strings are equal after cleaning.\n\n        Args:\n            target (str): The target string.\n            prediction (str): The prediction string.\n\n        Returns:\n            bool: True if cleaned prediction equals cleaned target, False otherwise.\n        \"\"\"\n        new_target = (target.lower()\n                      .replace(\" ,\", \",\")\n                      .replace(\"  \", \" \")\n                      .replace('\"', '')\n                      .replace(\"'\", '')\n                      .strip())\n\n        new_pred = (prediction.lower()\n                    .replace(\" ,\", \",\")\n                    .replace(\"  \", \" \")\n                    .replace('\"', '')\n                    .replace(\"'\", '')\n                    .replace(' ( ', '(')\n                    .replace(' )', ')')\n                    .strip())\n        return new_pred == new_target\n</code></pre>"},{"location":"metrics/#qatch.metric_evaluator.MetricEvaluator.are_cleaned_sql_identical","title":"<code>are_cleaned_sql_identical(target, prediction)</code>  <code>staticmethod</code>","text":"<p>Create a mask based on whether the target and prediction strings are equal after cleaning.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>The target string.</p> required <code>prediction</code> <code>str</code> <p>The prediction string.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if cleaned prediction equals cleaned target, False otherwise.</p> Source code in <code>qatch/metric_evaluator.py</code> <pre><code>@staticmethod\ndef are_cleaned_sql_identical(target: str, prediction: str) -&gt; bool:\n    \"\"\"\n    Create a mask based on whether the target and prediction strings are equal after cleaning.\n\n    Args:\n        target (str): The target string.\n        prediction (str): The prediction string.\n\n    Returns:\n        bool: True if cleaned prediction equals cleaned target, False otherwise.\n    \"\"\"\n    new_target = (target.lower()\n                  .replace(\" ,\", \",\")\n                  .replace(\"  \", \" \")\n                  .replace('\"', '')\n                  .replace(\"'\", '')\n                  .strip())\n\n    new_pred = (prediction.lower()\n                .replace(\" ,\", \",\")\n                .replace(\"  \", \" \")\n                .replace('\"', '')\n                .replace(\"'\", '')\n                .replace(' ( ', '(')\n                .replace(' )', ')')\n                .strip())\n    return new_pred == new_target\n</code></pre>"},{"location":"metrics/#qatch.metric_evaluator.MetricEvaluator.evaluate_single_test_QA","title":"<code>evaluate_single_test_QA(test, prediction_col_name, target_col_name)</code>","text":"<p>Evaluates metric scores on a single test QA task where a test is a dictionary (or pd.Series) and the <code>prediction_col_name</code> and <code>target_col_name</code> are the column names in the test data containing model predictions and actual target values respectively.</p> <p>Parameters:</p> Name Type Description Default <code>test</code> <code>dict | Series</code> <p>A dictionary or pandas Series containing a single test data. The keys (columns for Series) should include <code>prediction_col_name</code> and <code>target_col_name</code>.</p> required <code>prediction_col_name</code> <code>str</code> <p>String representing the key in <code>test</code> dictionary (or column in <code>test</code> pandas Series) where the predicted values are.</p> required <code>target_col_name</code> <code>str</code> <p>String representing the key in <code>test</code> dictionary (or column in <code>test</code> pandas Series) where the actual target values are.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary with keys are metric name and value is the evaluated metric score for each metric in <code>self.metrics</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; eval_task = MetricEvaluator(databases, metrics=['cell_precision', 'cell_recall'])\n&gt;&gt;&gt; test = {\"sql_tags\": \"SELECT\",\n...         \"prediction\": [[\"wales\", \"scotland\"], [\"england\"]],\n...         \"target\": [[\"scotland\", \"wales\"], [\"england\"]]}\n&gt;&gt;&gt; prediction_col_name = \"prediction\"\n&gt;&gt;&gt; target_col_name = \"target\"\n&gt;&gt;&gt;result = eval_task.evaluate_single_test_QA(test, prediction_col_name, target_col_name)\n&gt;&gt;&gt; print(result)\n{'cell_precision_prediction': 0.66, 'cell_recall_prediction': 1.0}\n</code></pre> Notes <p>In the above example, <code>cell_precision_prediction</code> is calculated as 2/3 = 0.66, \"wales\" and \"scotland\" are in the correct position. <code>cell_recall_prediction</code> is 2/2 = 1, all actual outcomes are included in the prediction.</p> Source code in <code>qatch/metric_evaluator.py</code> <pre><code>def evaluate_single_test_QA(self, test: dict, prediction_col_name: str, target_col_name: str) -&gt; dict:\n    \"\"\"\n    Evaluates metric scores on a single test QA task where a test is a dictionary (or pd.Series) and the\n    `prediction_col_name` and `target_col_name` are the column names in the test data containing model predictions\n    and actual target values respectively.\n\n    Args:\n        test (dict | pd.Series): A dictionary or pandas Series containing a single test data. The keys (columns for Series)\n            should include `prediction_col_name` and `target_col_name`.\n        prediction_col_name (str): String representing the key in `test` dictionary (or column in `test` pandas Series)\n            where the predicted values are.\n        target_col_name (str): String representing the key in `test` dictionary (or column in `test` pandas Series)\n            where the actual target values are.\n\n    Returns:\n        dict: A dictionary with keys are metric name and value is the evaluated metric score for each metric in `self.metrics`.\n\n    Examples:\n        &gt;&gt;&gt; eval_task = MetricEvaluator(databases, metrics=['cell_precision', 'cell_recall'])\n        &gt;&gt;&gt; test = {\"sql_tags\": \"SELECT\",\n        ...         \"prediction\": [[\"wales\", \"scotland\"], [\"england\"]],\n        ...         \"target\": [[\"scotland\", \"wales\"], [\"england\"]]}\n        &gt;&gt;&gt; prediction_col_name = \"prediction\"\n        &gt;&gt;&gt; target_col_name = \"target\"\n        &gt;&gt;&gt;result = eval_task.evaluate_single_test_QA(test, prediction_col_name, target_col_name)\n        &gt;&gt;&gt; print(result)\n        {'cell_precision_prediction': 0.66, 'cell_recall_prediction': 1.0}\n\n    Notes:\n        In the above example, `cell_precision_prediction` is calculated as 2/3 = 0.66,\n        \"wales\" and \"scotland\" are in the correct position.\n        `cell_recall_prediction` is 2/2 = 1, all actual outcomes are included in the prediction.\n    \"\"\"\n\n    # Runs the target query on the database\n    new_target_col = f'{target_col_name}_result'\n    try:\n        test[new_target_col] = self.databases.run_query(test['db_id'], test[target_col_name])\n    except sqlite3.Error as e:\n        # catch any possible error of prediction and return all zeros\n        logging.error(e)\n        return {f'{metric}_{prediction_col_name}': 0 for metric in self.metrics}\n\n    metric2evaluation = {f'{metric}_{prediction_col_name}': None for metric in self.metrics}\n    for metric in self.metrics:\n        generator = self._tags_generator[metric]\n        # initialize the metric column\n        # evaluate the metric only for the test where the prediction is not equal to the target\n        tqdm.pandas(desc=f'Evaluating {metric}')\n        if metric == 'tuple_order' and 'order by' not in test[target_col_name].lower():\n            continue\n        evaluation = generator.evaluate_single_test_metric(test[new_target_col], test[prediction_col_name])\n        metric2evaluation[f'{metric}_{prediction_col_name}'] = evaluation\n    return metric2evaluation\n</code></pre>"},{"location":"metrics/#qatch.metric_evaluator.MetricEvaluator.evaluate_single_test_SP","title":"<code>evaluate_single_test_SP(test, prediction_col_name, target_col_name)</code>","text":"<p>Evaluates metrics for a single SQL prediction test by fetching the results of the predicted and target queries from the database.</p> <p>This function fetches results based on provided <code>prediction_col_name</code> and <code>target_col_name</code>. Then it evaluates performance of the prediction by invoking <code>evaluate_single_test_QA</code>.</p> <p>Parameters:</p> Name Type Description Default <code>self</code> <code>MetricEvaluator</code> <p>The object instance the method is called on.</p> required <code>test</code> <code>dict | Series</code> <p>The test data as a dictionary or pandas Series. It contains the 'db_id' (database identifier).                      It is expected to have 'predictions_SP' and 'target_SP' keys/columns updated in process.</p> required <code>prediction_col_name</code> <code>str</code> <p>The name of column where prediction is stored.</p> required <code>target_col_name</code> <code>str</code> <p>The name of column where the target is stored.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing evaluation results obtained from <code>evaluate_single_test_QA</code>.</p> Notes <p>If the predicted query cannot be run on the db, the resulting metrics are all zeros</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; test = {'db_id': 'database1', 'target': 'SELECT DISTINCT emailisfree FROM fraud', 'prediction': 'SELECT emailsisfree, income FROM fraud'}\n&gt;&gt;&gt; evaluator = MetricEvaluator(databases)\n&gt;&gt;&gt; results = evaluator.evaluate_single_test_SP(test, 'prediction', 'target')\n&gt;&gt;&gt; print(results)\n{'cell_precision_prediction': 0.50, 'cell_recall_prediction': 1.0}\n</code></pre> Source code in <code>qatch/metric_evaluator.py</code> <pre><code>def evaluate_single_test_SP(self, test: dict, prediction_col_name: str, target_col_name: str) -&gt; dict:\n    \"\"\"\n    Evaluates metrics for a single SQL prediction test by fetching the results of the predicted and\n    target queries from the database.\n\n    This function fetches results based on provided `prediction_col_name` and `target_col_name`. Then it evaluates\n    performance of the prediction by invoking `evaluate_single_test_QA`.\n\n    Args:\n        self (MetricEvaluator): The object instance the method is called on.\n        test (dict | pd.Series): The test data as a dictionary or pandas Series. It contains the 'db_id' (database identifier).\n                                 It is expected to have 'predictions_SP' and 'target_SP' keys/columns updated in process.\n        prediction_col_name (str): The name of column where prediction is stored.\n        target_col_name (str): The name of column where the target is stored.\n\n    Returns:\n        dict: A dictionary containing evaluation results obtained from `evaluate_single_test_QA`.\n\n    Notes:\n        If the predicted query cannot be run on the db, the resulting metrics are all zeros\n\n    Examples:\n        &gt;&gt;&gt; test = {'db_id': 'database1', 'target': 'SELECT DISTINCT emailisfree FROM fraud', 'prediction': 'SELECT emailsisfree, income FROM fraud'}\n        &gt;&gt;&gt; evaluator = MetricEvaluator(databases)\n        &gt;&gt;&gt; results = evaluator.evaluate_single_test_SP(test, 'prediction', 'target')\n        &gt;&gt;&gt; print(results)\n        {'cell_precision_prediction': 0.50, 'cell_recall_prediction': 1.0}\n    \"\"\"\n    # Compares the target and predicted SQL queries after cleaning and formatting. If they are identical, it returns metrics as 1\n    if self.are_cleaned_sql_identical(test[target_col_name], test[prediction_col_name]):\n        metrics_result = {f'{metric}_{prediction_col_name}': 1 for metric in self.metrics}\n        metrics_result[f'tuple_order_{prediction_col_name}'] = None \\\n            if 'order' not in test[target_col_name].lower() else 1\n        return metrics_result\n\n    # Tries to run the predicted query on the database. If there is an error (e.g. syntax error in the query),\n    # it logs the error and returns metrics as 0\n    try:\n        test[prediction_col_name] = self.databases.run_query(test['db_id'], test[prediction_col_name])\n    except sqlite3.Error as e:\n        # catch any possible error of prediction and return all zeros\n        logging.error(e)\n        return {f'{metric}_{prediction_col_name}': 0 for metric in self.metrics}\n    # Evaluates the results of the target and predicted queries using the evaluate_single_test_QA function\n    return self.evaluate_single_test_QA(test, prediction_col_name, target_col_name)\n</code></pre>"},{"location":"metrics/#qatch.metric_evaluator.MetricEvaluator.evaluate_with_df","title":"<code>evaluate_with_df(df, prediction_col_name, task, target_col_name='query', keep_target=False)</code>","text":"<p>Evaluates SQL queries for various metrics including cell precision, cell recall, tuple cardinality, tuple constraint, tuple order.</p> <p>For each row in the input DataFrame, it evaluates either the task as a QA (Question Answering) or SP (Semantic Parsing). Then, it concatenates the original DataFrame and the evaluated metric DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame where each row represents a test.</p> required <code>prediction_col_name</code> <code>str</code> <p>Name of the column in the DataFrame that contains predictions.</p> required <code>task</code> <code>str</code> <p>Type of evaluation task. Could be <code>QA</code> or <code>SP</code>.</p> required <code>target_col_name</code> <code>str</code> <p>Name of the column in the DataFrame that contains target queries.</p> <code>'query'</code> <code>keep_target</code> <code>bool</code> <p>FALSE by default. If TRUE, keeps the target query.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Output DataFrame that has the original DataFrame along with the evaluated metric DataFrame.</p> Source code in <code>qatch/metric_evaluator.py</code> <pre><code>def evaluate_with_df(self, df, prediction_col_name: str, task: str, target_col_name: str = 'query',\n                     keep_target: bool = False\n                     ) -&gt; pd.DataFrame:\n    \"\"\"Evaluates SQL queries for various metrics including cell precision, cell recall,\n    tuple cardinality, tuple constraint, tuple order.\n\n    For each row in the input DataFrame, it evaluates either the task as a QA\n    (Question Answering) or SP (Semantic Parsing). Then, it concatenates the original DataFrame\n    and the evaluated metric DataFrame.\n\n    Args:\n        df (pd.DataFrame): Input DataFrame where each row represents a test.\n        prediction_col_name (str): Name of the column in the DataFrame that contains predictions.\n        task (str): Type of evaluation task. Could be `QA` or `SP`.\n        target_col_name (str): Name of the column in the DataFrame that contains target queries.\n        Default is `'query'`.\n        keep_target (bool): FALSE by default. If TRUE, keeps the target query.\n\n    Returns:\n        pd.DataFrame: Output DataFrame that has the original DataFrame along with the evaluated metric DataFrame.\n    \"\"\"\n    if task.upper() == 'QA':\n        # add the new metrics at the bottom of the dataframe\n        df_metrics = df.apply(lambda row: self.evaluate_single_test_QA(row.to_dict(),\n                                                                       prediction_col_name,\n                                                                       target_col_name),\n                              axis=1, result_type='expand')\n    else:\n        df_metrics = df.apply(lambda row: self.evaluate_single_test_SP(row.to_dict(),\n                                                                       prediction_col_name,\n                                                                       target_col_name), axis=1,\n                              result_type='expand')\n    return pd.concat([df, df_metrics], axis=1).replace({np.nan: None})\n</code></pre>"},{"location":"metrics/#qatch.metrics.CellPrecisionTag","title":"<code>CellPrecisionTag</code>","text":"<p>             Bases: <code>AbstractMetric</code></p> Source code in <code>qatch/metrics/cell_precision_tag.py</code> <pre><code>class CellPrecisionTag(AbstractMetric):\n    def evaluate_single_no_special_case(self, target: list[list],\n                                        prediction: list[list]) -&gt; float:\n        \"\"\"\n        Calculates the ratio of predicted cells that are in the target.\n        Does not consider cardinality (measured by other tags).\n        High precision indicates that the model is good at identifying relevant instances\n        and has a low false positive rate.\n\n        Args:\n            target (list[list]): Target table to be compared with the prediction table.\n            prediction (list[list]): Prediction table to be compared with the target table.\n\n        Returns:\n            float: Precision score between [0, 1].\n                - 0 indicates no cell in the prediction is in the target.\n                - 1 indicates all cells in the prediction are in the target.\n\n        Examples:\n            &gt;&gt;&gt; evaluator = CellPrecisionTag()\n            &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n            &gt;&gt;&gt; prediction = [['a', 'b'], ['c', 'd']\n            &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n            1.0\n\n            &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n            &gt;&gt;&gt; prediction = [['a', 'b'], ['c', 'e']\n            &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n            0.75\n\n            &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n            &gt;&gt;&gt; prediction = [['a'], ['b'], ['c'], ['d']]\n            &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n            1.0  # it is one even if the schema does not match (we introduce tuple constraints for this)\n        \"\"\"\n        target = np.array(target)\n        prediction = np.array(prediction)\n\n        sum_cell_match = np.sum(np.isin(prediction, target))\n        return round(sum_cell_match / prediction.size, 3)\n</code></pre>"},{"location":"metrics/#qatch.metrics.CellPrecisionTag.evaluate_single_no_special_case","title":"<code>evaluate_single_no_special_case(target, prediction)</code>","text":"<p>Calculates the ratio of predicted cells that are in the target. Does not consider cardinality (measured by other tags). High precision indicates that the model is good at identifying relevant instances and has a low false positive rate.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>list[list]</code> <p>Target table to be compared with the prediction table.</p> required <code>prediction</code> <code>list[list]</code> <p>Prediction table to be compared with the target table.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Precision score between [0, 1]. - 0 indicates no cell in the prediction is in the target. - 1 indicates all cells in the prediction are in the target.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; evaluator = CellPrecisionTag()\n&gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n&gt;&gt;&gt; prediction = [['a', 'b'], ['c', 'd']\n&gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n1.0\n</code></pre> <pre><code>&gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n&gt;&gt;&gt; prediction = [['a', 'b'], ['c', 'e']\n&gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n0.75\n</code></pre> <pre><code>&gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n&gt;&gt;&gt; prediction = [['a'], ['b'], ['c'], ['d']]\n&gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n1.0  # it is one even if the schema does not match (we introduce tuple constraints for this)\n</code></pre> Source code in <code>qatch/metrics/cell_precision_tag.py</code> <pre><code>def evaluate_single_no_special_case(self, target: list[list],\n                                    prediction: list[list]) -&gt; float:\n    \"\"\"\n    Calculates the ratio of predicted cells that are in the target.\n    Does not consider cardinality (measured by other tags).\n    High precision indicates that the model is good at identifying relevant instances\n    and has a low false positive rate.\n\n    Args:\n        target (list[list]): Target table to be compared with the prediction table.\n        prediction (list[list]): Prediction table to be compared with the target table.\n\n    Returns:\n        float: Precision score between [0, 1].\n            - 0 indicates no cell in the prediction is in the target.\n            - 1 indicates all cells in the prediction are in the target.\n\n    Examples:\n        &gt;&gt;&gt; evaluator = CellPrecisionTag()\n        &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n        &gt;&gt;&gt; prediction = [['a', 'b'], ['c', 'd']\n        &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n        1.0\n\n        &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n        &gt;&gt;&gt; prediction = [['a', 'b'], ['c', 'e']\n        &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n        0.75\n\n        &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n        &gt;&gt;&gt; prediction = [['a'], ['b'], ['c'], ['d']]\n        &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n        1.0  # it is one even if the schema does not match (we introduce tuple constraints for this)\n    \"\"\"\n    target = np.array(target)\n    prediction = np.array(prediction)\n\n    sum_cell_match = np.sum(np.isin(prediction, target))\n    return round(sum_cell_match / prediction.size, 3)\n</code></pre>"},{"location":"metrics/#qatch.metrics.CellRecallTag","title":"<code>CellRecallTag</code>","text":"<p>             Bases: <code>AbstractMetric</code></p> Source code in <code>qatch/metrics/cell_recall_tag.py</code> <pre><code>class CellRecallTag(AbstractMetric):\n    def evaluate_single_no_special_case(self, target: list[list],\n                                        prediction: list[list]) -&gt; float:\n        \"\"\"\n        Calculates the ratio of target cells that are in the prediction.\n        High recall indicates that the model is good at identifying all relevant instances\n        and has a low false negative rate.\n\n        Args:\n            target (list[list]): Target table to be compared with the prediction table.\n            prediction (list[list]): Prediction table to be compared with the target table.\n\n        Returns:\n            float: Recall score between [0, 1].\n                - 0 indicates no cell in the target is in the prediction.\n                - 1 indicates all cells in the target are in the prediction.\n\n        Examples:\n            &gt;&gt;&gt; evaluator = CellRecallTag()\n            &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n            &gt;&gt;&gt; prediction = [['a', 'b'], ['c', 'd']\n            &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n            1.0\n\n            &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n            &gt;&gt;&gt; prediction = [['a', 'x'], ['y', 'd']]\n            &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n            0.5\n\n            &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n            &gt;&gt;&gt; prediction = [['a', 'a'], ['b', 'b'], ['c', 'd']]\n            &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n            1.0\n        \"\"\"\n        target = np.array(target)\n        prediction = np.array(prediction)\n        sum_cell_match = np.sum(np.isin(target, prediction))\n        return round(sum_cell_match / target.size, 3)\n</code></pre>"},{"location":"metrics/#qatch.metrics.CellRecallTag.evaluate_single_no_special_case","title":"<code>evaluate_single_no_special_case(target, prediction)</code>","text":"<p>Calculates the ratio of target cells that are in the prediction. High recall indicates that the model is good at identifying all relevant instances and has a low false negative rate.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>list[list]</code> <p>Target table to be compared with the prediction table.</p> required <code>prediction</code> <code>list[list]</code> <p>Prediction table to be compared with the target table.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Recall score between [0, 1]. - 0 indicates no cell in the target is in the prediction. - 1 indicates all cells in the target are in the prediction.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; evaluator = CellRecallTag()\n&gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n&gt;&gt;&gt; prediction = [['a', 'b'], ['c', 'd']\n&gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n1.0\n</code></pre> <pre><code>&gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n&gt;&gt;&gt; prediction = [['a', 'x'], ['y', 'd']]\n&gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n0.5\n</code></pre> <pre><code>&gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n&gt;&gt;&gt; prediction = [['a', 'a'], ['b', 'b'], ['c', 'd']]\n&gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n1.0\n</code></pre> Source code in <code>qatch/metrics/cell_recall_tag.py</code> <pre><code>def evaluate_single_no_special_case(self, target: list[list],\n                                    prediction: list[list]) -&gt; float:\n    \"\"\"\n    Calculates the ratio of target cells that are in the prediction.\n    High recall indicates that the model is good at identifying all relevant instances\n    and has a low false negative rate.\n\n    Args:\n        target (list[list]): Target table to be compared with the prediction table.\n        prediction (list[list]): Prediction table to be compared with the target table.\n\n    Returns:\n        float: Recall score between [0, 1].\n            - 0 indicates no cell in the target is in the prediction.\n            - 1 indicates all cells in the target are in the prediction.\n\n    Examples:\n        &gt;&gt;&gt; evaluator = CellRecallTag()\n        &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n        &gt;&gt;&gt; prediction = [['a', 'b'], ['c', 'd']\n        &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n        1.0\n\n        &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n        &gt;&gt;&gt; prediction = [['a', 'x'], ['y', 'd']]\n        &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n        0.5\n\n        &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n        &gt;&gt;&gt; prediction = [['a', 'a'], ['b', 'b'], ['c', 'd']]\n        &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n        1.0\n    \"\"\"\n    target = np.array(target)\n    prediction = np.array(prediction)\n    sum_cell_match = np.sum(np.isin(target, prediction))\n    return round(sum_cell_match / target.size, 3)\n</code></pre>"},{"location":"metrics/#qatch.metrics.TupleCardinalityTag","title":"<code>TupleCardinalityTag</code>","text":"<p>             Bases: <code>AbstractMetric</code></p> Source code in <code>qatch/metrics/tuple_cardinality_tag.py</code> <pre><code>class TupleCardinalityTag(AbstractMetric):\n    def evaluate_single_no_special_case(self,\n                                        target: list[list],\n                                        prediction: list[list]) -&gt; float:\n        \"\"\"\n        Evaluates the ratio of the length of the smaller list to the length of the larger list.\n\n        Calculates the ratio of the length of the target table to the length of the prediction table\n        or vice-versa based on the maximum length to ensure the score falls between 0 and 1.\n\n        Args:\n            target (list[list]): Target table to be compared with the prediction table.\n            prediction (list[list]): Prediction table to be compared with the target table.\n\n        Returns:\n            float: Score between [0, 1].\n                - 0 indicates the target/prediction is zero and the other is not.\n                - 1 indicates the target/prediction is the same size as the other.\n\n        Examples:\n            &gt;&gt;&gt; evaluator = TupleCardinalityTag()\n            &gt;&gt;&gt; target = [[a, b], [c, d], [c, d], [f, g]]\n            &gt;&gt;&gt; prediction = [[a, b], [3, 2]]\n            &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n            0.5  # 2/4\n\n            &gt;&gt;&gt; evaluator = TupleCardinalityTag()\n            &gt;&gt;&gt; target = [[a, b], [3, 2]]\n            &gt;&gt;&gt; prediction = [[a, b], [c, d], [c, d], [f, g]]\n            &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n            0.5\n\n            &gt;&gt;&gt; evaluator = TupleCardinalityTag()\n            &gt;&gt;&gt; target = [[a, b], [3, 2]]\n            &gt;&gt;&gt; prediction = [[a, b], ['c', 'd']]\n            &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n            1.0\n        \"\"\"\n        if len(prediction) &gt;= len(target):\n            # in case we have more elements in the prediction than in the target\n            return round(len(target) / len(prediction), 3)\n\n        # in case we have more elements in the target than in the prediction\n        elif len(prediction) &lt; len(target):\n            return round(len(prediction) / len(target), 3)\n</code></pre>"},{"location":"metrics/#qatch.metrics.TupleCardinalityTag.evaluate_single_no_special_case","title":"<code>evaluate_single_no_special_case(target, prediction)</code>","text":"<p>Evaluates the ratio of the length of the smaller list to the length of the larger list.</p> <p>Calculates the ratio of the length of the target table to the length of the prediction table or vice-versa based on the maximum length to ensure the score falls between 0 and 1.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>list[list]</code> <p>Target table to be compared with the prediction table.</p> required <code>prediction</code> <code>list[list]</code> <p>Prediction table to be compared with the target table.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Score between [0, 1]. - 0 indicates the target/prediction is zero and the other is not. - 1 indicates the target/prediction is the same size as the other.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; evaluator = TupleCardinalityTag()\n&gt;&gt;&gt; target = [[a, b], [c, d], [c, d], [f, g]]\n&gt;&gt;&gt; prediction = [[a, b], [3, 2]]\n&gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n0.5  # 2/4\n</code></pre> <pre><code>&gt;&gt;&gt; evaluator = TupleCardinalityTag()\n&gt;&gt;&gt; target = [[a, b], [3, 2]]\n&gt;&gt;&gt; prediction = [[a, b], [c, d], [c, d], [f, g]]\n&gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n0.5\n</code></pre> <pre><code>&gt;&gt;&gt; evaluator = TupleCardinalityTag()\n&gt;&gt;&gt; target = [[a, b], [3, 2]]\n&gt;&gt;&gt; prediction = [[a, b], ['c', 'd']]\n&gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n1.0\n</code></pre> Source code in <code>qatch/metrics/tuple_cardinality_tag.py</code> <pre><code>def evaluate_single_no_special_case(self,\n                                    target: list[list],\n                                    prediction: list[list]) -&gt; float:\n    \"\"\"\n    Evaluates the ratio of the length of the smaller list to the length of the larger list.\n\n    Calculates the ratio of the length of the target table to the length of the prediction table\n    or vice-versa based on the maximum length to ensure the score falls between 0 and 1.\n\n    Args:\n        target (list[list]): Target table to be compared with the prediction table.\n        prediction (list[list]): Prediction table to be compared with the target table.\n\n    Returns:\n        float: Score between [0, 1].\n            - 0 indicates the target/prediction is zero and the other is not.\n            - 1 indicates the target/prediction is the same size as the other.\n\n    Examples:\n        &gt;&gt;&gt; evaluator = TupleCardinalityTag()\n        &gt;&gt;&gt; target = [[a, b], [c, d], [c, d], [f, g]]\n        &gt;&gt;&gt; prediction = [[a, b], [3, 2]]\n        &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n        0.5  # 2/4\n\n        &gt;&gt;&gt; evaluator = TupleCardinalityTag()\n        &gt;&gt;&gt; target = [[a, b], [3, 2]]\n        &gt;&gt;&gt; prediction = [[a, b], [c, d], [c, d], [f, g]]\n        &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n        0.5\n\n        &gt;&gt;&gt; evaluator = TupleCardinalityTag()\n        &gt;&gt;&gt; target = [[a, b], [3, 2]]\n        &gt;&gt;&gt; prediction = [[a, b], ['c', 'd']]\n        &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n        1.0\n    \"\"\"\n    if len(prediction) &gt;= len(target):\n        # in case we have more elements in the prediction than in the target\n        return round(len(target) / len(prediction), 3)\n\n    # in case we have more elements in the target than in the prediction\n    elif len(prediction) &lt; len(target):\n        return round(len(prediction) / len(target), 3)\n</code></pre>"},{"location":"metrics/#qatch.metrics.TupleConstraintTag","title":"<code>TupleConstraintTag</code>","text":"<p>             Bases: <code>AbstractMetric</code></p> Source code in <code>qatch/metrics/tuple_constraint_tag.py</code> <pre><code>class TupleConstraintTag(AbstractMetric):\n    def evaluate_single_no_special_case(self,\n                                        target: list[list],\n                                        prediction: list[list]\n                                        ) -&gt; float:\n        \"\"\"\n        Evaluates the ratio between the cardinality of the target tuples and the prediction.\n        Returns a score between 0 and 1. It is 1 if the schema, the cardinality and the cell values are equal.\n\n        Args:\n            target (list[list]): Target table to be compared with the prediction table.\n            prediction (list[list]): Prediction table to be compared with the target table.\n\n        Returns:\n            float: Score between [0, 1].\n                - 0 indicates NONE of the schema/cardinality/cell_values  are the same in prediction.\n                - 1 indicates the schema, the cardinality and the cell values of\n                    the prediction tuples are equal to the target ones.\n\n        Examples:\n            &gt;&gt;&gt; evaluator = TupleConstraintTag()\n            &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n            &gt;&gt;&gt; prediction = [['a', 'b'], ['c', 'd']]\n            &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n            1.0\n\n            &gt;&gt;&gt; evaluator = TupleConstraintTag()\n            &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n            &gt;&gt;&gt; prediction = [['a', 'b'], ['a', 'b'], ['c', 'd']]\n            &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n            0.5  # only ['c', 'd'] is the same in both tables\n\n            &gt;&gt;&gt; evaluator = TupleConstraintTag()\n            &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n            &gt;&gt;&gt; prediction = [['a', 'b'], ['a', 'b'], ['c', 'd'], ['c', 'd']]\n            &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n            0.0\n        \"\"\"\n        target = map(sorted, target)\n        prediction = map(sorted, prediction)\n\n        target = map(tuple, target)\n        prediction = map(tuple, prediction)\n\n        count_targ_dict = Counter(target)\n        count_pred_dict = Counter(prediction)\n\n        cardinality = [count_pred_dict[key] == count for key, count in count_targ_dict.items()]\n\n        return round(sum(cardinality) / len(cardinality), 3)\n</code></pre>"},{"location":"metrics/#qatch.metrics.TupleConstraintTag.evaluate_single_no_special_case","title":"<code>evaluate_single_no_special_case(target, prediction)</code>","text":"<p>Evaluates the ratio between the cardinality of the target tuples and the prediction. Returns a score between 0 and 1. It is 1 if the schema, the cardinality and the cell values are equal.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>list[list]</code> <p>Target table to be compared with the prediction table.</p> required <code>prediction</code> <code>list[list]</code> <p>Prediction table to be compared with the target table.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Score between [0, 1]. - 0 indicates NONE of the schema/cardinality/cell_values  are the same in prediction. - 1 indicates the schema, the cardinality and the cell values of     the prediction tuples are equal to the target ones.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; evaluator = TupleConstraintTag()\n&gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n&gt;&gt;&gt; prediction = [['a', 'b'], ['c', 'd']]\n&gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n1.0\n</code></pre> <pre><code>&gt;&gt;&gt; evaluator = TupleConstraintTag()\n&gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n&gt;&gt;&gt; prediction = [['a', 'b'], ['a', 'b'], ['c', 'd']]\n&gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n0.5  # only ['c', 'd'] is the same in both tables\n</code></pre> <pre><code>&gt;&gt;&gt; evaluator = TupleConstraintTag()\n&gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n&gt;&gt;&gt; prediction = [['a', 'b'], ['a', 'b'], ['c', 'd'], ['c', 'd']]\n&gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n0.0\n</code></pre> Source code in <code>qatch/metrics/tuple_constraint_tag.py</code> <pre><code>def evaluate_single_no_special_case(self,\n                                    target: list[list],\n                                    prediction: list[list]\n                                    ) -&gt; float:\n    \"\"\"\n    Evaluates the ratio between the cardinality of the target tuples and the prediction.\n    Returns a score between 0 and 1. It is 1 if the schema, the cardinality and the cell values are equal.\n\n    Args:\n        target (list[list]): Target table to be compared with the prediction table.\n        prediction (list[list]): Prediction table to be compared with the target table.\n\n    Returns:\n        float: Score between [0, 1].\n            - 0 indicates NONE of the schema/cardinality/cell_values  are the same in prediction.\n            - 1 indicates the schema, the cardinality and the cell values of\n                the prediction tuples are equal to the target ones.\n\n    Examples:\n        &gt;&gt;&gt; evaluator = TupleConstraintTag()\n        &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n        &gt;&gt;&gt; prediction = [['a', 'b'], ['c', 'd']]\n        &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n        1.0\n\n        &gt;&gt;&gt; evaluator = TupleConstraintTag()\n        &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n        &gt;&gt;&gt; prediction = [['a', 'b'], ['a', 'b'], ['c', 'd']]\n        &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n        0.5  # only ['c', 'd'] is the same in both tables\n\n        &gt;&gt;&gt; evaluator = TupleConstraintTag()\n        &gt;&gt;&gt; target = [['a', 'b'], ['c', 'd']]\n        &gt;&gt;&gt; prediction = [['a', 'b'], ['a', 'b'], ['c', 'd'], ['c', 'd']]\n        &gt;&gt;&gt; evaluator.evaluate_single_no_special_case(target, prediction)\n        0.0\n    \"\"\"\n    target = map(sorted, target)\n    prediction = map(sorted, prediction)\n\n    target = map(tuple, target)\n    prediction = map(tuple, prediction)\n\n    count_targ_dict = Counter(target)\n    count_pred_dict = Counter(prediction)\n\n    cardinality = [count_pred_dict[key] == count for key, count in count_targ_dict.items()]\n\n    return round(sum(cardinality) / len(cardinality), 3)\n</code></pre>"},{"location":"metrics/#qatch.metrics.TupleOrderTag","title":"<code>TupleOrderTag</code>","text":"<p>             Bases: <code>AbstractMetric</code></p> Source code in <code>qatch/metrics/tuple_order_tag.py</code> <pre><code>class TupleOrderTag(AbstractMetric):\n    def evaluate_single_no_special_case(self,\n                                        target: list[list],\n                                        prediction: list[list]) -&gt; float:\n        \"\"\"\n        Evaluates the similarity in tuple order between the target and prediction.\n        The score is based on the Spearman rank correlation coefficient normalized between 0 and 1.\n        This metric ONLY checks whether the order of the tuples is the same in the target and prediction.\n        Therefore, the elements that are in predictions but nor in target are ignored (and viceversa).\n\n        Args:\n            target (list[list]): Target table to be compared with the prediction table.\n            prediction (list[list]): Prediction table to be compared with the target table.\n\n        Returns:\n            float: Score between [-1, 1].\n            - 1 indicates that the order of rows in prediction is the same as in the target.\n            - 0.5 indicates that there is no correlation between the two lists.\n            - 0 indicates the order of rows in prediction is opposite to the target.\n\n        Examples:\n            &gt;&gt;&gt; evaluator = TupleOrderTag()\n            &gt;&gt;&gt;  target = [['a', 'b'], ['c', 'd']]\n            &gt;&gt;&gt;  prediction = [['c', 'd'], ['a', 'b']]\n            &gt;&gt;&gt; evaluator.evaluate(target, prediction)\n            0.0\n\n            &gt;&gt;&gt; evaluator = TupleOrderTag()\n            &gt;&gt;&gt;  target = [['apple', 'orange'], ['pear']]\n            &gt;&gt;&gt;  prediction = [['pear'], ['apple', 'orange']]\n            &gt;&gt;&gt; evaluator.evaluate(target, prediction)\n            0.0\n\n            &gt;&gt;&gt; evaluator = TupleOrderTag()\n            &gt;&gt;&gt;  target = [['apple', 'orange'], ['pear']]\n            &gt;&gt;&gt;  prediction = [['pear']]\n            &gt;&gt;&gt; evaluator.evaluate(target, prediction)\n            1.0\n        \"\"\"\n\n        # take only prediction that are in target without duplicates\n        # MAINTAINING the order\n        new_pred = []\n        [new_pred.append(pred) for pred in prediction\n         if pred in target and pred not in new_pred]\n        # same for target\n        new_target = []\n        [new_target.append(tar) for tar in target\n         if tar in prediction and tar not in new_target]\n\n        if len(new_target) == 0:\n\n            rho = 0.0\n        else:\n            target_ranks = [i for i in range(len(new_target))]\n            pred_ranks = [new_target.index(row) for row in new_pred]\n\n            diff_rank_squared = [(tar - pred) ** 2\n                                 for tar, pred in zip(target_ranks, pred_ranks)]\n\n            sum_diff_rank_squared = sum(diff_rank_squared)\n\n            n = len(new_target) if len(new_target) &gt; 1 else 2\n            rho = 1 - 6 * sum_diff_rank_squared / (n * (n ** 2 - 1))\n\n        return self.normalize(round(rho, 3))\n\n    @staticmethod\n    def normalize(data: float):\n        data = [-1, data, 1]\n        data = (data - np.min(data)) / (np.max(data) - np.min(data))\n        return data[1]\n</code></pre>"},{"location":"metrics/#qatch.metrics.TupleOrderTag.evaluate_single_no_special_case","title":"<code>evaluate_single_no_special_case(target, prediction)</code>","text":"<p>Evaluates the similarity in tuple order between the target and prediction. The score is based on the Spearman rank correlation coefficient normalized between 0 and 1. This metric ONLY checks whether the order of the tuples is the same in the target and prediction. Therefore, the elements that are in predictions but nor in target are ignored (and viceversa).</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>list[list]</code> <p>Target table to be compared with the prediction table.</p> required <code>prediction</code> <code>list[list]</code> <p>Prediction table to be compared with the target table.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Score between [-1, 1].</p> <code>float</code> <ul> <li>1 indicates that the order of rows in prediction is the same as in the target.</li> </ul> <code>float</code> <ul> <li>0.5 indicates that there is no correlation between the two lists.</li> </ul> <code>float</code> <ul> <li>0 indicates the order of rows in prediction is opposite to the target.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; evaluator = TupleOrderTag()\n&gt;&gt;&gt;  target = [['a', 'b'], ['c', 'd']]\n&gt;&gt;&gt;  prediction = [['c', 'd'], ['a', 'b']]\n&gt;&gt;&gt; evaluator.evaluate(target, prediction)\n0.0\n</code></pre> <pre><code>&gt;&gt;&gt; evaluator = TupleOrderTag()\n&gt;&gt;&gt;  target = [['apple', 'orange'], ['pear']]\n&gt;&gt;&gt;  prediction = [['pear'], ['apple', 'orange']]\n&gt;&gt;&gt; evaluator.evaluate(target, prediction)\n0.0\n</code></pre> <pre><code>&gt;&gt;&gt; evaluator = TupleOrderTag()\n&gt;&gt;&gt;  target = [['apple', 'orange'], ['pear']]\n&gt;&gt;&gt;  prediction = [['pear']]\n&gt;&gt;&gt; evaluator.evaluate(target, prediction)\n1.0\n</code></pre> Source code in <code>qatch/metrics/tuple_order_tag.py</code> <pre><code>def evaluate_single_no_special_case(self,\n                                    target: list[list],\n                                    prediction: list[list]) -&gt; float:\n    \"\"\"\n    Evaluates the similarity in tuple order between the target and prediction.\n    The score is based on the Spearman rank correlation coefficient normalized between 0 and 1.\n    This metric ONLY checks whether the order of the tuples is the same in the target and prediction.\n    Therefore, the elements that are in predictions but nor in target are ignored (and viceversa).\n\n    Args:\n        target (list[list]): Target table to be compared with the prediction table.\n        prediction (list[list]): Prediction table to be compared with the target table.\n\n    Returns:\n        float: Score between [-1, 1].\n        - 1 indicates that the order of rows in prediction is the same as in the target.\n        - 0.5 indicates that there is no correlation between the two lists.\n        - 0 indicates the order of rows in prediction is opposite to the target.\n\n    Examples:\n        &gt;&gt;&gt; evaluator = TupleOrderTag()\n        &gt;&gt;&gt;  target = [['a', 'b'], ['c', 'd']]\n        &gt;&gt;&gt;  prediction = [['c', 'd'], ['a', 'b']]\n        &gt;&gt;&gt; evaluator.evaluate(target, prediction)\n        0.0\n\n        &gt;&gt;&gt; evaluator = TupleOrderTag()\n        &gt;&gt;&gt;  target = [['apple', 'orange'], ['pear']]\n        &gt;&gt;&gt;  prediction = [['pear'], ['apple', 'orange']]\n        &gt;&gt;&gt; evaluator.evaluate(target, prediction)\n        0.0\n\n        &gt;&gt;&gt; evaluator = TupleOrderTag()\n        &gt;&gt;&gt;  target = [['apple', 'orange'], ['pear']]\n        &gt;&gt;&gt;  prediction = [['pear']]\n        &gt;&gt;&gt; evaluator.evaluate(target, prediction)\n        1.0\n    \"\"\"\n\n    # take only prediction that are in target without duplicates\n    # MAINTAINING the order\n    new_pred = []\n    [new_pred.append(pred) for pred in prediction\n     if pred in target and pred not in new_pred]\n    # same for target\n    new_target = []\n    [new_target.append(tar) for tar in target\n     if tar in prediction and tar not in new_target]\n\n    if len(new_target) == 0:\n\n        rho = 0.0\n    else:\n        target_ranks = [i for i in range(len(new_target))]\n        pred_ranks = [new_target.index(row) for row in new_pred]\n\n        diff_rank_squared = [(tar - pred) ** 2\n                             for tar, pred in zip(target_ranks, pred_ranks)]\n\n        sum_diff_rank_squared = sum(diff_rank_squared)\n\n        n = len(new_target) if len(new_target) &gt; 1 else 2\n        rho = 1 - 6 * sum_diff_rank_squared / (n * (n ** 2 - 1))\n\n    return self.normalize(round(rho, 3))\n</code></pre>"},{"location":"sql_generator/","title":"QATCH Generate","text":""},{"location":"sql_generator/#qatch.test_generator.TestGenerator","title":"<code>TestGenerator</code>","text":"<p>The interface to connect the MultipleDatabase with the SQL generators. Use this class to generate queries and questions from the databases.</p> <p>Attributes:</p> Name Type Description <code>databases</code> <code>MultipleDatabases</code> <p>The MultipleDatabases object representing the database connections.</p> Source code in <code>qatch/test_generator.py</code> <pre><code>class TestGenerator:\n    \"\"\"\n    The interface to connect the MultipleDatabase with the SQL generators.\n    Use this class to generate queries and questions from the databases.\n\n    Attributes:\n        databases (MultipleDatabases): The MultipleDatabases object representing the database connections.\n    \"\"\"\n\n    def __init__(self, databases: MultipleDatabases):\n        self.databases = databases\n\n        self._generators = {'select': SelectGenerator,\n                            'orderby': OrderByGenerator,\n                            'distinct': DistinctGenerator,\n                            'where': WhereGenerator,\n                            'groupby': GroupByGenerator,\n                            'having': HavingGenerator,\n                            'simpleAgg': SimpleAggGenerator,\n                            'nullCount': NullGenerator,\n                            'join': JoinGenerator}\n\n    def generate(self,\n                 generators: list[str] | str | None = None,\n                 db_names: str | list[str] | None = None,\n                 seed=2023\n                 ) -&gt; pd.DataFrame:\n        \"\"\"\n        Generate test queries and questions for specified generators and databases.\n\n        Args:\n            generators (list[str] | str | None): Optional. A list of generator names to be used.\n                                                  Default is to use all available generators\n                                                  ['select', 'orderby', 'distinct', 'where', 'groupby',\n                                                   'having', 'simpleAgg', 'nullCount'].\n            db_names (str | list[str] | None): Optional. The name or list of names of databases to generate tests for.\n                                                Default is to use all available databases.\n            seed (int): Optional. Seed value for randomization. Default is 2023.\n\n        Returns:\n            pd.DataFrame: A DataFrame containing generated test queries, questions, and related information.\n\n        Examples:\n            Given a MultipleDatabases object \"database\", with three databases 'sakila', 'world', and 'employees'\n            &gt;&gt;&gt; generator = TestGenerator(databases)\n            &gt;&gt;&gt; tests_df = generator.generate(generators=['select', 'orderby'], db_names=['sakila', 'world'])\n            generate tests only for select and orderby generators, and only for sakila and world databases\n        \"\"\"\n        # TODO possible change of the db_name, add dictionary to specify also the tbl_names\n        generators, db_names, = self._init_params(generators, db_names)\n\n        tests_df_list = []\n        for db_name in tqdm(db_names, desc='Generating test for each database'):\n            # for each db_name\n            for generator in generators:\n                # init generator\n                db = self.databases[db_name]\n                generator = self._generators[generator](db, seed)\n                for tbl in db.table_names:\n                    sql_generated = generator.sql_generate(tbl)\n                    df = self._build_df(db_name, tbl, sql_generated)\n                    tests_df_list.append(df)\n\n        tests_df = pd.concat(tests_df_list, ignore_index=True)\n        return tests_df\n\n    def _init_params(self, generators: list[str] | str | None,\n                     db_names: str | list[str] | None) -&gt; tuple[list[str], list[str]]:\n        \"\"\"\n        Validate and initialize generator names and database names.\n\n        Args:\n            generators (list[str] | str | None): The list of generator names or a single generator name.\n            db_names (str | list[str] | None): The name or list of names of databases to generate tests for.\n\n        Returns:\n            tuple[list[str], list[str]]: Validated generator names and database names.\n        \"\"\"\n        # generators check\n        if generators is None:\n            generators = list(self._generators.keys())\n        else:\n            if isinstance(generators, str):\n                generators = [generators]\n            for generator in generators:\n                if generator not in self._generators.keys():\n                    raise KeyError(f'Generators must be one of {list(self._generators.keys())}')\n\n        # db_names check\n        available_dbs = self.databases.get_db_names()\n        if db_names is None:\n            db_names = available_dbs\n        else:\n            if isinstance(db_names, str):\n                db_names = [db_names]\n            for db_name in db_names:\n                if db_name not in available_dbs:\n                    raise KeyError(f'Database name \"{db_name}\" must be one of {available_dbs}')\n        return generators, db_names\n\n    @staticmethod\n    def _build_df(db_name: str, tbl_name: str, sql_generated: dict[str, list]) -&gt; pd.DataFrame:\n        \"\"\"\n        Build a DataFrame from generated SQL queries, questions, and related information.\n\n        Args:\n            db_name (str): The name of the database.\n            tbl_name (str): The name of the table in the database.\n            sql_generated (dict[str, list]): A dictionary containing generated SQL tags, queries, and questions.\n\n        Returns:\n            pd.DataFrame: A DataFrame containing generated test queries, questions, and related information.\n        \"\"\"\n\n        sql_tags = sql_generated['sql_tags']\n        queries = sql_generated['queries']\n        questions = sql_generated['questions']\n        return pd.DataFrame({\n            'db_id': [db_name] * len(sql_tags),\n            'tbl_name': [tbl_name] * len(sql_tags),\n            'sql_tags': sql_tags,\n            'query': queries,\n            'question': questions\n        })\n</code></pre>"},{"location":"sql_generator/#qatch.test_generator.TestGenerator.generate","title":"<code>generate(generators=None, db_names=None, seed=2023)</code>","text":"<p>Generate test queries and questions for specified generators and databases.</p> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>list[str] | str | None</code> <p>Optional. A list of generator names to be used.                                   Default is to use all available generators                                   ['select', 'orderby', 'distinct', 'where', 'groupby',                                    'having', 'simpleAgg', 'nullCount'].</p> <code>None</code> <code>db_names</code> <code>str | list[str] | None</code> <p>Optional. The name or list of names of databases to generate tests for.                                 Default is to use all available databases.</p> <code>None</code> <code>seed</code> <code>int</code> <p>Optional. Seed value for randomization. Default is 2023.</p> <code>2023</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame containing generated test queries, questions, and related information.</p> <p>Examples:</p> <p>Given a MultipleDatabases object \"database\", with three databases 'sakila', 'world', and 'employees'</p> <pre><code>&gt;&gt;&gt; generator = TestGenerator(databases)\n&gt;&gt;&gt; tests_df = generator.generate(generators=['select', 'orderby'], db_names=['sakila', 'world'])\ngenerate tests only for select and orderby generators, and only for sakila and world databases\n</code></pre> Source code in <code>qatch/test_generator.py</code> <pre><code>def generate(self,\n             generators: list[str] | str | None = None,\n             db_names: str | list[str] | None = None,\n             seed=2023\n             ) -&gt; pd.DataFrame:\n    \"\"\"\n    Generate test queries and questions for specified generators and databases.\n\n    Args:\n        generators (list[str] | str | None): Optional. A list of generator names to be used.\n                                              Default is to use all available generators\n                                              ['select', 'orderby', 'distinct', 'where', 'groupby',\n                                               'having', 'simpleAgg', 'nullCount'].\n        db_names (str | list[str] | None): Optional. The name or list of names of databases to generate tests for.\n                                            Default is to use all available databases.\n        seed (int): Optional. Seed value for randomization. Default is 2023.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing generated test queries, questions, and related information.\n\n    Examples:\n        Given a MultipleDatabases object \"database\", with three databases 'sakila', 'world', and 'employees'\n        &gt;&gt;&gt; generator = TestGenerator(databases)\n        &gt;&gt;&gt; tests_df = generator.generate(generators=['select', 'orderby'], db_names=['sakila', 'world'])\n        generate tests only for select and orderby generators, and only for sakila and world databases\n    \"\"\"\n    # TODO possible change of the db_name, add dictionary to specify also the tbl_names\n    generators, db_names, = self._init_params(generators, db_names)\n\n    tests_df_list = []\n    for db_name in tqdm(db_names, desc='Generating test for each database'):\n        # for each db_name\n        for generator in generators:\n            # init generator\n            db = self.databases[db_name]\n            generator = self._generators[generator](db, seed)\n            for tbl in db.table_names:\n                sql_generated = generator.sql_generate(tbl)\n                df = self._build_df(db_name, tbl, sql_generated)\n                tests_df_list.append(df)\n\n    tests_df = pd.concat(tests_df_list, ignore_index=True)\n    return tests_df\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.DistinctGenerator","title":"<code>DistinctGenerator</code>","text":"<p>             Bases: <code>AbstractSqlGenerator</code></p> <p>A class for generating DISTINCT SQL queries and corresponding questions based on categorical columns of a database table.</p> <p>Attributes:</p> Name Type Description <code>database</code> <code>SingleDatabase</code> <p>The SingleDatabase object representing the database to generate queries from.</p> <code>sql_generated</code> <code>dict</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}</p> Source code in <code>qatch/sql_generator/distinct_generator.py</code> <pre><code>class DistinctGenerator(AbstractSqlGenerator):\n    \"\"\"\n    A class for generating DISTINCT SQL queries and corresponding questions based on\n    categorical columns of a database table.\n\n    Attributes:\n        database (SingleDatabase): The SingleDatabase object representing the database to generate queries from.\n        sql_generated (dict): A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n    \"\"\"\n\n    def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n        \"\"\"\n        Generates DISTINCT SQL queries and corresponding questions based on categorical columns of a table.\n        Generates two distinct tags: DISTINCT-SINGLE and DISTINCT-MULT only for the categorical columns.\n\n        Args:\n            table_name (str): The name of the table in the database.\n\n        Returns:\n            dict: A dictionary containing generated SQL tags, queries, and questions.\n                Format: {\"sql_tags\": List[str], \"queries\": List[str], \"questions\": List[str]}\n\n        Examples:\n            Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"names\"\n            &gt;&gt;&gt; generator = DistinctGenerator(database)\n            &gt;&gt;&gt; generator._distinct_single_col(\"table_name\", [\"colors\"])\n            &gt;&gt;&gt; generator.sql_generated\n            {\"sql_tags\": [\"DISTINCT-SINGLE\"],\n            \"queries\": [\"SELECT DISTINCT \\\"colors\\\" FROM \\\"table_name\\\"\"],\n            \"questions\": [\"Show the different \\\"colors\\\" in the table table_name\"]}\n            &gt;&gt;&gt; generator_distinct_mult_col(\"table_name\", [\"colors\", \"names\"])\n            &gt;&gt;&gt; generator.sql_generated\n            {\"sql_tags\": [\"DISTINCT-MULT\"],\n            \"queries\": [\"SELECT DISTINCT \\\"colors\\\", \\\"names\\\" FROM \\\"table_name\\\"\"],\n            \"questions\": [\"Show the different \\\"colors\\\", \\\"names\\\" in the table table_name\"]}\n        \"\"\"\n        _, cat_cols, _ = self._sample_cat_num_cols(table_name)\n        self._distinct_single_col(table_name, cat_cols)\n        self._distinct_mult_col(table_name, cat_cols)\n        return self.sql_generated\n\n    def _distinct_single_col(self, table_name: str, cat_columns: list):\n        \"\"\"\n        Generates DISTINCT SQL queries and questions for individual categorical columns.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            cat_columns (List[str]): List of categorical column names.\n        \"\"\"\n        queries = [f'SELECT DISTINCT `{col}` FROM `{table_name}`'\n                   for col in cat_columns]\n\n        questions = [f'Show the different \"{col}\" in the table \"{table_name}\"'\n                     for col in cat_columns]\n\n        sql_tags = ['DISTINCT-SINGLE'] * len(queries)\n        self.append_sql_generated(sql_tags=sql_tags, queries=queries, questions=questions)\n\n    def _distinct_mult_col(self, table_name: str, cat_columns: list):\n        \"\"\"\n        Generates DISTINCT SQL queries and questions for combinations of multiple categorical columns.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            cat_columns (List[str]): List of categorical column names.\n        \"\"\"\n        combinations = self._comb_random(cat_columns)\n        queries = [f'SELECT DISTINCT {self._get_col_comb_str(comb)} FROM `{table_name}`'\n                   for comb in combinations]\n\n        questions = [f'Show the different {self._get_col_comb_str(comb)} in the table \"{table_name}\"'\n                     for comb in combinations]\n\n        sql_tags = ['DISTINCT-MULT'] * len(queries)\n        self.append_sql_generated(sql_tags=sql_tags, queries=queries, questions=questions)\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.DistinctGenerator.sql_generate","title":"<code>sql_generate(table_name)</code>","text":"<p>Generates DISTINCT SQL queries and corresponding questions based on categorical columns of a table. Generates two distinct tags: DISTINCT-SINGLE and DISTINCT-MULT only for the categorical columns.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table in the database.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, list]</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": List[str], \"queries\": List[str], \"questions\": List[str]}</p> <p>Examples:</p> <p>Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"names\"</p> <pre><code>&gt;&gt;&gt; generator = DistinctGenerator(database)\n&gt;&gt;&gt; generator._distinct_single_col(\"table_name\", [\"colors\"])\n&gt;&gt;&gt; generator.sql_generated\n{\"sql_tags\": [\"DISTINCT-SINGLE\"],\n\"queries\": [\"SELECT DISTINCT \"colors\" FROM \"table_name\"\"],\n\"questions\": [\"Show the different \"colors\" in the table table_name\"]}\n&gt;&gt;&gt; generator_distinct_mult_col(\"table_name\", [\"colors\", \"names\"])\n&gt;&gt;&gt; generator.sql_generated\n{\"sql_tags\": [\"DISTINCT-MULT\"],\n\"queries\": [\"SELECT DISTINCT \"colors\", \"names\" FROM \"table_name\"\"],\n\"questions\": [\"Show the different \"colors\", \"names\" in the table table_name\"]}\n</code></pre> Source code in <code>qatch/sql_generator/distinct_generator.py</code> <pre><code>def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n    \"\"\"\n    Generates DISTINCT SQL queries and corresponding questions based on categorical columns of a table.\n    Generates two distinct tags: DISTINCT-SINGLE and DISTINCT-MULT only for the categorical columns.\n\n    Args:\n        table_name (str): The name of the table in the database.\n\n    Returns:\n        dict: A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": List[str], \"queries\": List[str], \"questions\": List[str]}\n\n    Examples:\n        Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"names\"\n        &gt;&gt;&gt; generator = DistinctGenerator(database)\n        &gt;&gt;&gt; generator._distinct_single_col(\"table_name\", [\"colors\"])\n        &gt;&gt;&gt; generator.sql_generated\n        {\"sql_tags\": [\"DISTINCT-SINGLE\"],\n        \"queries\": [\"SELECT DISTINCT \\\"colors\\\" FROM \\\"table_name\\\"\"],\n        \"questions\": [\"Show the different \\\"colors\\\" in the table table_name\"]}\n        &gt;&gt;&gt; generator_distinct_mult_col(\"table_name\", [\"colors\", \"names\"])\n        &gt;&gt;&gt; generator.sql_generated\n        {\"sql_tags\": [\"DISTINCT-MULT\"],\n        \"queries\": [\"SELECT DISTINCT \\\"colors\\\", \\\"names\\\" FROM \\\"table_name\\\"\"],\n        \"questions\": [\"Show the different \\\"colors\\\", \\\"names\\\" in the table table_name\"]}\n    \"\"\"\n    _, cat_cols, _ = self._sample_cat_num_cols(table_name)\n    self._distinct_single_col(table_name, cat_cols)\n    self._distinct_mult_col(table_name, cat_cols)\n    return self.sql_generated\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.GroupByGenerator","title":"<code>GroupByGenerator</code>","text":"<p>             Bases: <code>AbstractSqlGenerator</code></p> <p>A class for generating SQL queries and corresponding questions based on group-by operations performed on categorical and numerical columns of a database table.</p> <p>Attributes:</p> Name Type Description <code>database</code> <code>SingleDatabase</code> <p>The SingleDatabase object representing the database to generate queries from.</p> <code>sql_generated</code> <code>dict</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}</p> Source code in <code>qatch/sql_generator/groupby_generator.py</code> <pre><code>class GroupByGenerator(AbstractSqlGenerator):\n    \"\"\"\n    A class for generating SQL queries and corresponding questions based on group-by operations\n    performed on categorical and numerical columns of a database table.\n\n    Attributes:\n        database (SingleDatabase): The SingleDatabase object representing the database to generate queries from.\n        sql_generated (dict): A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n    \"\"\"\n\n    def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n        \"\"\"\n        Generates Group By queries and corresponding questions for both categorical and numerical columns.\n\n        Args:\n            table_name (str): The name of the table in the database.\n\n        Returns:\n            dict: A dictionary containing generated SQL tags, queries, and questions.\n                Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n\n        Examples:\n            Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"\n            &gt;&gt;&gt; generator = GroupByGenerator(database)\n            &gt;&gt;&gt; generator._build_group_by_no_agg(\"table_name\", [\"colors\"])\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"GROUPBY-NO-AGGR\"],\n                \"queries\": [\"SELECT `colors` FROM `table_name` GROUP BY `colors`\"],\n                \"questions\": [\"Show all \\\"colors\\\" in the table \"table_name\" for each \\\"colors\\\"\"]\n            }\n            &gt;&gt;&gt; generator._build_group_by_with_count(\"table_name\", [\"colors\"])\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"GROUPBY-COUNT\"],\n                \"queries\": [\"SELECT `colors`, COUNT(*) FROM `table_name` GROUP BY `colors`\"],\n                \"questions\": [\"For each \\\"colors\\\", count the number of rows in table \"table_name\"\"]\n            }\n            &gt;&gt;&gt; generator._build_group_by_with_agg(\"table_name\")\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"GROUPBY-AGG-MIN\", \"GROUPBY-AGG-MAX\", \"GROUPBY-AGG-AVG\", \"GROUPBY-AGG-SUM\"],\n                \"queries\": [\n                    \"SELECT `colors`, MIN(`numbers`) FROM `table_name` GROUP BY `colors`\",\n                    \"SELECT `colors`, MAX(`numbers`) FROM `table_name` GROUP BY `colors`\",\n                    \"SELECT `colors`, AVG(`numbers`) FROM `table_name` GROUP BY `colors`\",\n                    \"SELECT `colors`, SUM(`numbers`) FROM `table_name` GROUP BY `colors`\"\n                ],\n                \"questions\": [\n                    \"For each `colors`, find the min of `numbers` in table `table_name`\",\n                    \"For each `colors`, find the max of `numbers` in table `table_name`\",\n                    \"For each `colors`, find the avg of `numbers` in table `table_name`\",\n                    \"For each `colors`, find the sum of `numbers` in table `table_name`\"\n                ]\n            }\n        \"\"\"\n        self.empty_sql_generated()\n        df, cat_cols, num_cols = self._sample_cat_num_cols(table_name)\n        self._build_group_by_no_agg(table_name, cat_cols)\n        self._build_group_by_with_count(table_name, cat_cols)\n        self._build_group_by_with_agg(table_name)\n        return self.sql_generated\n\n    def _build_group_by_no_agg(self, table_name: str, cat_cols: list):\n        \"\"\"\n        Generate group-by SQL queries and questions without aggregation\n        for random combinations of categorical columns.\n        The query result is the same as Distinct.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            cat_cols (List[str]): List of categorical columns.\n        \"\"\"\n        random_combinations = self._comb_random(cat_cols)\n\n        questions = [f'Show all {self._get_col_comb_str(comb)}' \\\n                     f' in the table \"{table_name}\" for each {self._get_col_comb_str(comb)}'\n                     for comb in random_combinations]\n\n        queries = [f'SELECT {self._get_col_comb_str(comb)} FROM ' \\\n                   f'`{table_name}` GROUP BY {self._get_col_comb_str(comb)}'\n                   for comb in random_combinations]\n\n        sql_tags = ['GROUPBY-NO-AGGR'] * len(queries)\n\n        self.append_sql_generated(sql_tags=sql_tags, queries=queries,\n                                  questions=questions)\n\n    def _build_group_by_with_count(self, table_name: str, cat_cols: list):\n        \"\"\"\n        Generate group-by SQL queries and questions with count aggregation for categorical columns.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            cat_cols (List[str]): List of categorical columns.\n        \"\"\"\n        questions = [f'For each \"{col}\", count the number of rows in table \"{table_name}\"'\n                     for col in cat_cols]\n        queries = [f'SELECT `{col}`, COUNT(*) FROM `{table_name}` GROUP BY `{col}`'\n                   for col in cat_cols]\n        sql_tags = ['GROUPBY-COUNT'] * len(queries)\n\n        self.append_sql_generated(sql_tags=sql_tags, queries=queries,\n                                  questions=questions)\n\n    def _build_group_by_with_agg(self, table_name: str):\n        \"\"\"\n        Generate group-by SQL queries and questions with aggregation for numerical columns.\n\n        Args:\n            table_name (str): The name of the table in the database.\n        \"\"\"\n        # with sample == 2 we get 4 tests for each aggregation -&gt; 4*4 = 16 tests\n        # with sample == 3 we get 9 tests for each aggregation -&gt; 9*4 = 36 tests\n        _, cat_cols, num_cols = self._sample_cat_num_cols(table_name, sample=2)\n        for agg in ['min', 'max', 'avg', 'sum']:\n            questions = [f'For each \"{c_col}\", find the {agg} of \"{n_col}\" in table \"{table_name}\"'\n                         for c_col in cat_cols\n                         for n_col in num_cols]\n\n            queries = [f'SELECT `{c_col}`, {agg.upper()}(`{n_col}`) FROM `{table_name}` GROUP BY `{c_col}`'\n                       for c_col in cat_cols\n                       for n_col in num_cols]\n\n            sql_tags = [f'GROUPBY-AGG-{agg.upper()}'] * len(queries)\n\n            self.append_sql_generated(sql_tags=sql_tags, queries=queries,\n                                      questions=questions)\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.GroupByGenerator.sql_generate","title":"<code>sql_generate(table_name)</code>","text":"<p>Generates Group By queries and corresponding questions for both categorical and numerical columns.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table in the database.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, list]</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}</p> <p>Examples:</p> <p>Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"</p> <pre><code>&gt;&gt;&gt; generator = GroupByGenerator(database)\n&gt;&gt;&gt; generator._build_group_by_no_agg(\"table_name\", [\"colors\"])\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"GROUPBY-NO-AGGR\"],\n    \"queries\": [\"SELECT `colors` FROM `table_name` GROUP BY `colors`\"],\n    \"questions\": [\"Show all \"colors\" in the table \"table_name\" for each \"colors\"\"]\n}\n&gt;&gt;&gt; generator._build_group_by_with_count(\"table_name\", [\"colors\"])\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"GROUPBY-COUNT\"],\n    \"queries\": [\"SELECT `colors`, COUNT(*) FROM `table_name` GROUP BY `colors`\"],\n    \"questions\": [\"For each \"colors\", count the number of rows in table \"table_name\"\"]\n}\n&gt;&gt;&gt; generator._build_group_by_with_agg(\"table_name\")\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"GROUPBY-AGG-MIN\", \"GROUPBY-AGG-MAX\", \"GROUPBY-AGG-AVG\", \"GROUPBY-AGG-SUM\"],\n    \"queries\": [\n        \"SELECT `colors`, MIN(`numbers`) FROM `table_name` GROUP BY `colors`\",\n        \"SELECT `colors`, MAX(`numbers`) FROM `table_name` GROUP BY `colors`\",\n        \"SELECT `colors`, AVG(`numbers`) FROM `table_name` GROUP BY `colors`\",\n        \"SELECT `colors`, SUM(`numbers`) FROM `table_name` GROUP BY `colors`\"\n    ],\n    \"questions\": [\n        \"For each `colors`, find the min of `numbers` in table `table_name`\",\n        \"For each `colors`, find the max of `numbers` in table `table_name`\",\n        \"For each `colors`, find the avg of `numbers` in table `table_name`\",\n        \"For each `colors`, find the sum of `numbers` in table `table_name`\"\n    ]\n}\n</code></pre> Source code in <code>qatch/sql_generator/groupby_generator.py</code> <pre><code>def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n    \"\"\"\n    Generates Group By queries and corresponding questions for both categorical and numerical columns.\n\n    Args:\n        table_name (str): The name of the table in the database.\n\n    Returns:\n        dict: A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n\n    Examples:\n        Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"\n        &gt;&gt;&gt; generator = GroupByGenerator(database)\n        &gt;&gt;&gt; generator._build_group_by_no_agg(\"table_name\", [\"colors\"])\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"GROUPBY-NO-AGGR\"],\n            \"queries\": [\"SELECT `colors` FROM `table_name` GROUP BY `colors`\"],\n            \"questions\": [\"Show all \\\"colors\\\" in the table \"table_name\" for each \\\"colors\\\"\"]\n        }\n        &gt;&gt;&gt; generator._build_group_by_with_count(\"table_name\", [\"colors\"])\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"GROUPBY-COUNT\"],\n            \"queries\": [\"SELECT `colors`, COUNT(*) FROM `table_name` GROUP BY `colors`\"],\n            \"questions\": [\"For each \\\"colors\\\", count the number of rows in table \"table_name\"\"]\n        }\n        &gt;&gt;&gt; generator._build_group_by_with_agg(\"table_name\")\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"GROUPBY-AGG-MIN\", \"GROUPBY-AGG-MAX\", \"GROUPBY-AGG-AVG\", \"GROUPBY-AGG-SUM\"],\n            \"queries\": [\n                \"SELECT `colors`, MIN(`numbers`) FROM `table_name` GROUP BY `colors`\",\n                \"SELECT `colors`, MAX(`numbers`) FROM `table_name` GROUP BY `colors`\",\n                \"SELECT `colors`, AVG(`numbers`) FROM `table_name` GROUP BY `colors`\",\n                \"SELECT `colors`, SUM(`numbers`) FROM `table_name` GROUP BY `colors`\"\n            ],\n            \"questions\": [\n                \"For each `colors`, find the min of `numbers` in table `table_name`\",\n                \"For each `colors`, find the max of `numbers` in table `table_name`\",\n                \"For each `colors`, find the avg of `numbers` in table `table_name`\",\n                \"For each `colors`, find the sum of `numbers` in table `table_name`\"\n            ]\n        }\n    \"\"\"\n    self.empty_sql_generated()\n    df, cat_cols, num_cols = self._sample_cat_num_cols(table_name)\n    self._build_group_by_no_agg(table_name, cat_cols)\n    self._build_group_by_with_count(table_name, cat_cols)\n    self._build_group_by_with_agg(table_name)\n    return self.sql_generated\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.HavingGenerator","title":"<code>HavingGenerator</code>","text":"<p>             Bases: <code>AbstractSqlGenerator</code></p> <p>A class for generating HAVING SQL queries and corresponding questions based on a database table.</p> <p>Attributes:</p> Name Type Description <code>database</code> <code>SingleDatabase</code> <p>The SingleDatabase object representing the database to generate queries from.</p> <code>sql_generated</code> <code>dict</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}</p> Source code in <code>qatch/sql_generator/having_generator.py</code> <pre><code>class HavingGenerator(AbstractSqlGenerator):\n    \"\"\"\n    A class for generating HAVING SQL queries and corresponding questions based on a database table.\n\n    Attributes:\n        database (SingleDatabase): The SingleDatabase object representing the database to generate queries from.\n        sql_generated (dict): A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n    \"\"\"\n\n    def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n        \"\"\"\n        Generate HAVING SQL queries and corresponding questions for categorical and numerical columns.\n\n        Args:\n            table_name (str): The name of the table in the database.\n\n        Returns:\n            dict: A dictionary containing generated SQL tags, queries, and questions.\n                Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n\n        Examples:\n            Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"\n            and (i) the average number of rows for each category in \"colors\" is 2\n            (ii) the mean of the average numbers for each category is 5\n            (iii) the average sum of numbers for each category is 10:\n            &gt;&gt;&gt; generator = HavingGenerator(database)\n            &gt;&gt;&gt; generator._build_having_count(table_name, [\"colors\"], df)\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"HAVING-COUNT-GR\", \"HAVING-COUNT-LS\", \"HAVING-COUNT-EQ\"],\n                \"queries\": [\n                    'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING count(*) &gt;= 2',\n                    'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING count(*) &lt;= 2',\n                    'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING count(*) = 2'\n                ],\n                \"questions\": [\n                    'Find all the `colors` that have at least 2 records in table `table_name`',\n                    'Find all the `colors` that have at most 2 records in table `table_name`',\n                    'Find all the `colors` that have exactly 2 records in table `table_name`'\n                ]\n            }\n            &gt;&gt;&gt; generator._build_having_agg(table_name, [\"colors\"], [\"numbers\"], df)\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"HAVING-AGG-AVG-GR\", \"HAVING-AGG-AVG-LS\", \"HAVING-AGG-SUM-GR\", \"HAVING-AGG-SUM-LS\"],\n                \"queries\": [\n                    'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING AVG(`numbers`) &gt;= 5.0',\n                    'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING AVG(`numbers`) &lt;= 5.0',\n                    'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING SUM(`numbers`) &gt;= 10.0',\n                    'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING SUM(`numbers`) &lt;= 10.0'\n                ],\n                \"questions\": [\n                    'List the `colors` which average `numbers` is at least 5.0 in table `table_name`',\n                    'List the `colors` which average `numbers` is at most 5.0 in table `table_name`',\n                    'List the `colors` which summation of `numbers` is at least 5.0 in table `table_name`',\n                    'List the `colors` which summation of `numbers` is at most 5.0 in table `table_name`'\n                ]\n            }\n        \"\"\"\n        self.empty_sql_generated()\n        df, cat_cols, num_cols = self._sample_cat_num_cols(table_name)\n        self._build_having_count(table_name, cat_cols, df)\n        self._build_having_agg(table_name, cat_cols, num_cols, df)\n        return self.sql_generated\n\n    def _build_having_count(self, table_name: str, cat_cols: list, df: pd.DataFrame):\n        \"\"\"\n        Build HAVING SQL queries and questions for categorical columns based on row counts.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            cat_cols (list): List of categorical columns.\n            df (pd.DataFrame): The DataFrame containing the data.\n        \"\"\"\n\n        for cat_col in cat_cols:\n            # get a mean count of the category cat_col\n            mean_count = self._get_average_of_count_cat_col(table_name, cat_col)\n            # int(df.groupby(cat_col).count().mean().values[0])\n            queries = [\n                f\"\"\"SELECT `{cat_col}` FROM `{table_name}` GROUP BY `{cat_col}` HAVING count(*) &gt;= {mean_count}\"\"\",\n                f\"\"\"SELECT `{cat_col}` FROM `{table_name}` GROUP BY `{cat_col}` HAVING count(*) &lt;= {mean_count}\"\"\",\n                f\"\"\"SELECT `{cat_col}` FROM `{table_name}` GROUP BY `{cat_col}` HAVING count(*) = {mean_count}\"\"\"\n            ]\n\n            questions = [\n                f'Find all the \"{cat_col}\" that have at least {mean_count} records in table \"{table_name}\"',\n                f'Find all the \"{cat_col}\" that have at most {mean_count} records in table \"{table_name}\"',\n                f'Find all the \"{cat_col}\" that have exactly {mean_count} records in table \"{table_name}\"'\n            ]\n\n            sql_tags = ['HAVING-COUNT-GR', 'HAVING-COUNT-LS', 'HAVING-COUNT-EQ']\n\n            self.append_sql_generated(sql_tags, queries, questions)\n\n    def _build_having_agg(self, table_name: str, cat_cols: list, num_cols: list, df: pd.DataFrame):\n        \"\"\"\n        Build HAVING SQL queries and questions for numerical columns based on aggregations.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            cat_cols (list): List of categorical columns.\n            num_cols (list): List of numerical columns.\n            df (pd.DataFrame): The DataFrame containing the data.\n        \"\"\"\n        # with sample == 2 we get 4 tests for each aggregation -&gt; 4*4 = 16 tests\n        # with sample == 3 we get 9 tests for each aggregation -&gt; 9*4 = 36 tests\n        for cat_col in cat_cols:\n            # the mean for each grouped category\n            # mean_sum = df.groupby(cat_col).sum(numeric_only=True)\n            # mean_mean = df.groupby(cat_col).mean(numeric_only=True)\n            for num_col in num_cols:\n                # the mean of sum for the grouped category\n                # mean_mean_sum = round(mean_sum[num_col].mean(), 2)\n                # mean_mean_mean = round(mean_mean[num_col].mean(), 2)\n                mean_mean_sum, mean_mean_mean = self._get_average_of_sum_avg_cat_col(table_name, cat_col, num_col)\n                queries = [\n                    f\"\"\"SELECT `{cat_col}` FROM `{table_name}` GROUP BY `{cat_col}` HAVING AVG(`{num_col}`) &gt;= {mean_mean_mean}\"\"\",\n                    f\"\"\"SELECT `{cat_col}` FROM `{table_name}` GROUP BY `{cat_col}` HAVING AVG(`{num_col}`) &lt;= {mean_mean_mean}\"\"\",\n                    f\"\"\"SELECT `{cat_col}` FROM `{table_name}` GROUP BY `{cat_col}` HAVING SUM(`{num_col}`) &gt;= {mean_mean_sum}\"\"\",\n                    f\"\"\"SELECT `{cat_col}` FROM `{table_name}` GROUP BY `{cat_col}` HAVING SUM(`{num_col}`) &lt;= {mean_mean_sum}\"\"\",\n                ]\n\n                questions = [\n                    f'List the \"{cat_col}\" which average \"{num_col}\" is at least {mean_mean_mean} in table \"{table_name}\"',\n                    f'List the \"{cat_col}\" which average \"{num_col}\" is at most {mean_mean_mean} in table \"{table_name}\"',\n\n                    f'List the \"{cat_col}\" which summation of \"{num_col}\" is at least {mean_mean_sum} in table \"{table_name}\"',\n                    f'List the \"{cat_col}\" which summation of \"{num_col}\" is at most {mean_mean_sum} in table \"{table_name}\"',\n                ]\n\n                sql_tags = ['HAVING-AGG-AVG-GR', 'HAVING-AGG-AVG-LS',\n                            'HAVING-AGG-SUM-GR', 'HAVING-AGG-SUM-LS']\n\n                self.append_sql_generated(sql_tags, queries, questions)\n\n    def _get_average_of_count_cat_col(self, table_name, cat_col):\n        \"\"\"\n        Helper method to calculate the average count of rows for each category in a categorical column.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            cat_col (str): The name of the categorical column.\n\n        Returns:\n            int: The average count of rows for each category.\n        \"\"\"\n        # TODO: pandas performs faster when number of tuples is 5e4 or more\n        # SQL query to get the average count for each category\n        inner_query = f'SELECT COUNT(*) AS row_count FROM `{table_name}` GROUP BY `{cat_col}`'\n        # Run the inner query and get the average of row counts\n        average = self.database.run_query(f'SELECT AVG(row_count) FROM ({inner_query})')[0][0]\n        return int(average)\n\n    def _get_average_of_sum_avg_cat_col(self, table_name, cat_col, num_col):\n        \"\"\"\n        Helper method to calculate the average sum and average of a numerical column for each category in a categorical column.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            cat_col (str): The name of the categorical column.\n            num_col (str): The name of the numerical column.\n\n        Returns:\n            tuple: A tuple containing the average sum and average of the numerical column for each category.\n        \"\"\"\n        # TODO: pandas performs faster when number of tuples is 5e4 or more\n        # SQL queries to get the average sum and average of numerical column for each category\n        inner_query_sum = f'SELECT SUM(`{num_col}`) AS sum_col FROM `{table_name}` GROUP BY `{cat_col}`'\n        inner_query_avg = f'SELECT AVG(`{num_col}`) AS avg_col FROM `{table_name}` GROUP BY `{cat_col}`'\n        # Run the inner queries and get the average of sums and averages\n        average_sum = self.database.run_query(f'SELECT AVG(sum_col) FROM ({inner_query_sum})')[0][0]\n        average_avg = self.database.run_query(f'SELECT AVG(avg_col) FROM ({inner_query_avg})')[0][0]\n        return round(average_sum, 2), round(average_avg, 2)\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.HavingGenerator.sql_generate","title":"<code>sql_generate(table_name)</code>","text":"<p>Generate HAVING SQL queries and corresponding questions for categorical and numerical columns.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table in the database.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, list]</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}</p> <p>Examples:</p> <p>Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\" and (i) the average number of rows for each category in \"colors\" is 2 (ii) the mean of the average numbers for each category is 5 (iii) the average sum of numbers for each category is 10:</p> <pre><code>&gt;&gt;&gt; generator = HavingGenerator(database)\n&gt;&gt;&gt; generator._build_having_count(table_name, [\"colors\"], df)\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"HAVING-COUNT-GR\", \"HAVING-COUNT-LS\", \"HAVING-COUNT-EQ\"],\n    \"queries\": [\n        'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING count(*) &gt;= 2',\n        'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING count(*) &lt;= 2',\n        'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING count(*) = 2'\n    ],\n    \"questions\": [\n        'Find all the `colors` that have at least 2 records in table `table_name`',\n        'Find all the `colors` that have at most 2 records in table `table_name`',\n        'Find all the `colors` that have exactly 2 records in table `table_name`'\n    ]\n}\n&gt;&gt;&gt; generator._build_having_agg(table_name, [\"colors\"], [\"numbers\"], df)\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"HAVING-AGG-AVG-GR\", \"HAVING-AGG-AVG-LS\", \"HAVING-AGG-SUM-GR\", \"HAVING-AGG-SUM-LS\"],\n    \"queries\": [\n        'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING AVG(`numbers`) &gt;= 5.0',\n        'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING AVG(`numbers`) &lt;= 5.0',\n        'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING SUM(`numbers`) &gt;= 10.0',\n        'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING SUM(`numbers`) &lt;= 10.0'\n    ],\n    \"questions\": [\n        'List the `colors` which average `numbers` is at least 5.0 in table `table_name`',\n        'List the `colors` which average `numbers` is at most 5.0 in table `table_name`',\n        'List the `colors` which summation of `numbers` is at least 5.0 in table `table_name`',\n        'List the `colors` which summation of `numbers` is at most 5.0 in table `table_name`'\n    ]\n}\n</code></pre> Source code in <code>qatch/sql_generator/having_generator.py</code> <pre><code>def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n    \"\"\"\n    Generate HAVING SQL queries and corresponding questions for categorical and numerical columns.\n\n    Args:\n        table_name (str): The name of the table in the database.\n\n    Returns:\n        dict: A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n\n    Examples:\n        Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"\n        and (i) the average number of rows for each category in \"colors\" is 2\n        (ii) the mean of the average numbers for each category is 5\n        (iii) the average sum of numbers for each category is 10:\n        &gt;&gt;&gt; generator = HavingGenerator(database)\n        &gt;&gt;&gt; generator._build_having_count(table_name, [\"colors\"], df)\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"HAVING-COUNT-GR\", \"HAVING-COUNT-LS\", \"HAVING-COUNT-EQ\"],\n            \"queries\": [\n                'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING count(*) &gt;= 2',\n                'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING count(*) &lt;= 2',\n                'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING count(*) = 2'\n            ],\n            \"questions\": [\n                'Find all the `colors` that have at least 2 records in table `table_name`',\n                'Find all the `colors` that have at most 2 records in table `table_name`',\n                'Find all the `colors` that have exactly 2 records in table `table_name`'\n            ]\n        }\n        &gt;&gt;&gt; generator._build_having_agg(table_name, [\"colors\"], [\"numbers\"], df)\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"HAVING-AGG-AVG-GR\", \"HAVING-AGG-AVG-LS\", \"HAVING-AGG-SUM-GR\", \"HAVING-AGG-SUM-LS\"],\n            \"queries\": [\n                'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING AVG(`numbers`) &gt;= 5.0',\n                'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING AVG(`numbers`) &lt;= 5.0',\n                'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING SUM(`numbers`) &gt;= 10.0',\n                'SELECT `colors` FROM `table_name` GROUP BY `colors` HAVING SUM(`numbers`) &lt;= 10.0'\n            ],\n            \"questions\": [\n                'List the `colors` which average `numbers` is at least 5.0 in table `table_name`',\n                'List the `colors` which average `numbers` is at most 5.0 in table `table_name`',\n                'List the `colors` which summation of `numbers` is at least 5.0 in table `table_name`',\n                'List the `colors` which summation of `numbers` is at most 5.0 in table `table_name`'\n            ]\n        }\n    \"\"\"\n    self.empty_sql_generated()\n    df, cat_cols, num_cols = self._sample_cat_num_cols(table_name)\n    self._build_having_count(table_name, cat_cols, df)\n    self._build_having_agg(table_name, cat_cols, num_cols, df)\n    return self.sql_generated\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.JoinGenerator","title":"<code>JoinGenerator</code>","text":"<p>             Bases: <code>AbstractSqlGenerator</code></p> <p>A class for generating SQL queries, and questions based on input tables in a database.</p> <p>Attributes:</p> Name Type Description <code>database</code> <code>SingleDatabase</code> <p>The SingleDatabase object representing the database to generate queries from.</p> <code>sql_generated</code> <code>dict</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}</p> Source code in <code>qatch/sql_generator/join_generator.py</code> <pre><code>class JoinGenerator(AbstractSqlGenerator):\n    \"\"\"\n    A class for generating SQL queries, and questions based on input tables in a database.\n\n    Attributes:\n        database (SingleDatabase): The SingleDatabase object representing the database to generate queries from.\n        sql_generated (dict): A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n    \"\"\"\n\n    def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n        \"\"\"\n        This method generates SQL queries by performing JOIN operations on the\n        specified table with other tables that have common columns in the database.\n        It first empties any previously generated SQL queries, then it determines the\n        tables to join based on common columns, and finally it generates the\n        actual SQL queries.\n\n        Args:\n            table_name (str): The name of the input table.\n\n        Returns:\n            dict[str, list]: A dictionary where the keys are SQL tags and the values are lists of generated SQL queries.\n\n        Examples:\n             Assuming a MultipleDatabases object \"database\" with two tables, 'orders' and 'customers', 'orders' table has columns\n            ['order_id', 'product', 'customer_id'] and 'customers' table has columns ['customer_id', 'name', 'address'].\n            &gt;&gt;&gt; generator = JoinGenerator(database)\n            &gt;&gt;&gt; generator._generate_join_project_all(\"orders\")\n            &gt;&gt;&gt; generator.sql_generated\n            &gt;&gt;&gt; {'sql_tags': ['JOIN-PROJECT-ALL'],\n            &gt;&gt;&gt;    'queries': ['SELECT * FROM \"orders\" AS T1 JOIN customers AS T2 ON T1.customer_id=T2.customer_id'],\n            &gt;&gt;&gt;    'questions': ['Join all the records from table \"orders\" with table \"customers\" on \"customer_id\"']}\n\n            &gt;&gt;&gt; generator._generate_join_cat_columns(\"orders\")\n            &gt;&gt;&gt; generator.sql_generated\n            &gt;&gt;&gt; {'sql_tags': ['JOIN-PROJECT-CAT'],\n            &gt;&gt;&gt;    'queries': [\"SELECT T1.product, T2.name FROM orders AS T1 JOIN customers AS T2 ON T1.order_id=T2.order_id\"],\n            &gt;&gt;&gt;    'questions': ['List all the \"product\" and \"name\" from the table \"orders\" and the table \"customers\" where \"order_id\" is the same']}\n\n        Note:\n            The method makes use of other internal methods to firstly\n            get tables that can be joined with the given table and\n            generate SQL queries on this basis.\n        \"\"\"\n        self.empty_sql_generated()\n        # get columns to perform the join operator that contains\n        table_to_join2cols = self._get_table_name_to_join(table_name)\n        self._generate_join_cat_columns(table_name, table_to_join2cols)\n        self._generate_join_project_all(table_name, table_to_join2cols)\n        return self.sql_generated\n\n    def _generate_join_project_all(self, table_name: str, table_to_join2cols: dict):\n        \"\"\"\n        A helper method to generate SQL queries, questions and SQL tags that join all records from two tables.\n\n        This method constructs the join queries based on the given table name and a dictionary mapping tables to join columns.\n        After constructing the queries, questions and SQL tags, it appends them to the sql_generated attribute using the\n        append_sql_generated method.\n\n        Args:\n            table_name (str): The name of the table to be joined.\n            table_to_join2cols (dict): A dictionary where the key is the name of the table to be joined\n                                        and the value is a list of column names in the joining table.\n\n        Example:\n            Assuming we have two tables, 'orders' and 'customers', 'orders' table has columns\n            ['order_id', 'product', 'customer_id'] and 'customers' table has columns ['customer_id', 'name', 'address'].\n\n            &gt;&gt;&gt; table_to_join2cols = {'customers': ['customer_id']}\n            &gt;&gt;&gt; _generate_join_project_all('orders', table_to_join2cols)\n\n            After calling the method, the 'sql_generated' attribute of the class instance will contain the following:\n\n            &gt;&gt;&gt; {'sql_tags': ['JOIN-PROJECT-ALL'],\n            &gt;&gt;&gt;    'queries': ['SELECT * FROM \"orders\" AS T1 JOIN customers AS T2 ON T1.customer_id=T2.customer_id'],\n            &gt;&gt;&gt;    'questions': ['Join all the records from table \"orders\" with table \"customers\" on \"customer_id\"']}\n        \"\"\"\n        queries, questions, sql_tags = [], [], []\n        for t2, join_col in table_to_join2cols.items():\n            for col in join_col:\n                # create the join query\n                queries.append(f'SELECT * FROM `{table_name}` AS T1 JOIN {t2} AS T2 ON T1.`{col}`=T2.`{col}`')\n                questions.append(f'Join all the records from table \"{table_name}\" with table \"{t2}\" on \"{col}\"')\n                sql_tags.append('JOIN-PROJECT-ALL')\n        self.append_sql_generated(sql_tags, queries, questions)\n\n    def _generate_join_cat_columns(self, table_name: str, table_to_join2cols: dict):\n        \"\"\"\n        Helper method to generate SQL queries that joins categorical columns from two tables on a common column.\n        Also generates corresponding questions and SQL tags.\n\n        Args:\n            table_name (str): The name of the base table for generating SQL queries.\n            table_to_join2cols (dict): A dictionary containing table names as keys and list of common columns with base\n            table as values. It indicates which tables and columns can be used for joining.\n\n        Example:\n            Assuming we have two tables, 'orders' and 'customers', 'orders' table has columns\n            ['order_id', 'product', 'customer_id'] and 'customers' table has columns ['customer_id', 'name', 'address'].\n\n            &gt;&gt;&gt; table_to_join2cols = {'customers': ['customer_id']}\n            &gt;&gt;&gt; _generate_join_cat_columns('orders', table_to_join2cols)\n\n            After calling the method, the 'sql_generated' attribute of the class instance will contain the following:\n\n            &gt;&gt;&gt; {'sql_tags': ['JOIN-PROJECT-CAT'],\n            &gt;&gt;&gt;    'queries': [\"SELECT T1.product, T2.name FROM orders AS T1 JOIN customers AS T2 ON T1.order_id=T2.order_id\"],\n            &gt;&gt;&gt;    'questions': ['List all the \"product\" and \"name\" from the table \"orders\" and the table \"customers\" where \"order_id\" is the same']}\n        \"\"\"\n        queries, questions, sql_tags = [], [], []\n        _, t1_cat_cols, _ = self._sample_cat_num_cols(table_name, 1)\n        for t2, join_col in table_to_join2cols.items():\n            _, t2_cat_cols, _ = self._sample_cat_num_cols(t2, 1)\n            if not t1_cat_cols or not t2_cat_cols:\n                # if there is no categorical column in the table, skip\n                continue\n            for col in join_col:\n                # create the join query\n                queries.append(f'SELECT T1.`{t1_cat_cols[0]}`, T2.`{t2_cat_cols[0]}` '\n                               f'FROM `{table_name}` AS T1 JOIN {t2} AS T2 ON T1.`{col}`=T2.`{col}`')\n                questions.append(\n                    f'List all the \"{t1_cat_cols[0]}\" and \"{t2_cat_cols[0]}\" from the table \"{table_name}\" and the table \"{t2}\" '\n                    f'where {col} is the same')\n                sql_tags.append('JOIN-PROJECT-CAT')\n        self.append_sql_generated(sql_tags, queries, questions)\n\n    @staticmethod\n    def _get_columns_to_join(tbl_1_cols: list, tbl_2_cols: list) -&gt; list:\n        \"\"\"\n        Returns the list of common columns from both tables that contain the keyword 'id' in their names.\n\n        This method can be helpful in a SQL join operation to identify the common columns\n        between two tables having 'id' keyword in their names.\n\n        Args:\n            tbl_1_cols (list): A list of column names from the first table.\n            tbl_2_cols (list): A list of column names from the second table.\n\n        Returns:\n            list: A list of common column names between tbl_1_cols and tbl_2_cols,\n            which contain the keyword 'id'.\n\n        Example:\n            &gt;&gt;&gt; tbl_1_cols = ['user_id', 'username', 'email']\n            &gt;&gt;&gt; tbl_2_cols = ['product_id', 'user_id', 'product_name']\n            &gt;&gt;&gt; JoinGenerator._get_columns_to_join(tbl_1_cols, tbl_2_cols)\n            ['user_id']\n        \"\"\"\n        # remove all the columns that do not contain \"id\" in the name\n        tbl_1_cols = {col for col in tbl_1_cols if \"id\" in col.lower()}\n        tbl_2_cols = {col for col in tbl_2_cols if \"id\" in col.lower()}\n        # get the columns that are in both tables\n        cols_to_join = tbl_1_cols.intersection(tbl_2_cols)\n        return list(cols_to_join)\n\n    def _get_table_name_to_join(self, table_name: str) -&gt; dict:\n        \"\"\"\n        This function obtains all the tables that can be joined with the provided table based on the common columns.\n\n        Args:\n            table_name (str): The name of the table for which joining tables are to be obtained.\n\n        Returns:\n            dict: A dictionary with table names as keys and a list of common column names with the input table as values.\n\n        Example:\n            Consider three tables in the database: 'table1', 'table2', 'table3'.\n            'table1' has columns 'A', 'B', 'C'. 'table2' has columns 'B', 'D', 'E'.\n            'table3' has columns 'F', 'G'.\n            Calling this function with 'table1' would return:\n            {'table2': ['B']} as 'table2' can be joined with 'table1' on column 'B'.\n\n        Notes:\n            The function doesn't consider any inner join for now.\n            It interacts with the database object associated with the class instance to obtain table names and schemas.\n        \"\"\"\n        # get all the tables in the database\n        tables = self.database.table_names\n        t1_col = self.database.get_schema_given(table_name)['name']\n        table_to_join = dict()\n        for tbl in tables:\n            if tbl == table_name:\n                # skip inner join for now\n                continue\n            t2_col = self.database.get_schema_given(tbl)['name']\n            cols_to_join = self._get_columns_to_join(t1_col, t2_col)\n            if cols_to_join:\n                table_to_join[tbl] = cols_to_join\n        return table_to_join\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.JoinGenerator.sql_generate","title":"<code>sql_generate(table_name)</code>","text":"<p>This method generates SQL queries by performing JOIN operations on the specified table with other tables that have common columns in the database. It first empties any previously generated SQL queries, then it determines the tables to join based on common columns, and finally it generates the actual SQL queries.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the input table.</p> required <p>Returns:</p> Type Description <code>dict[str, list]</code> <p>dict[str, list]: A dictionary where the keys are SQL tags and the values are lists of generated SQL queries.</p> <p>Examples:</p> <p>Assuming a MultipleDatabases object \"database\" with two tables, 'orders' and 'customers', 'orders' table has columns</p> <pre><code>['order_id', 'product', 'customer_id'] and 'customers' table has columns ['customer_id', 'name', 'address'].\n&gt;&gt;&gt; generator = JoinGenerator(database)\n&gt;&gt;&gt; generator._generate_join_project_all(\"orders\")\n&gt;&gt;&gt; generator.sql_generated\n&gt;&gt;&gt; {'sql_tags': ['JOIN-PROJECT-ALL'],\n&gt;&gt;&gt;    'queries': ['SELECT * FROM \"orders\" AS T1 JOIN customers AS T2 ON T1.customer_id=T2.customer_id'],\n&gt;&gt;&gt;    'questions': ['Join all the records from table \"orders\" with table \"customers\" on \"customer_id\"']}\n\n&gt;&gt;&gt; generator._generate_join_cat_columns(\"orders\")\n&gt;&gt;&gt; generator.sql_generated\n&gt;&gt;&gt; {'sql_tags': ['JOIN-PROJECT-CAT'],\n&gt;&gt;&gt;    'queries': [\"SELECT T1.product, T2.name FROM orders AS T1 JOIN customers AS T2 ON T1.order_id=T2.order_id\"],\n&gt;&gt;&gt;    'questions': ['List all the \"product\" and \"name\" from the table \"orders\" and the table \"customers\" where \"order_id\" is the same']}\n</code></pre> Note <p>The method makes use of other internal methods to firstly get tables that can be joined with the given table and generate SQL queries on this basis.</p> Source code in <code>qatch/sql_generator/join_generator.py</code> <pre><code>def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n    \"\"\"\n    This method generates SQL queries by performing JOIN operations on the\n    specified table with other tables that have common columns in the database.\n    It first empties any previously generated SQL queries, then it determines the\n    tables to join based on common columns, and finally it generates the\n    actual SQL queries.\n\n    Args:\n        table_name (str): The name of the input table.\n\n    Returns:\n        dict[str, list]: A dictionary where the keys are SQL tags and the values are lists of generated SQL queries.\n\n    Examples:\n         Assuming a MultipleDatabases object \"database\" with two tables, 'orders' and 'customers', 'orders' table has columns\n        ['order_id', 'product', 'customer_id'] and 'customers' table has columns ['customer_id', 'name', 'address'].\n        &gt;&gt;&gt; generator = JoinGenerator(database)\n        &gt;&gt;&gt; generator._generate_join_project_all(\"orders\")\n        &gt;&gt;&gt; generator.sql_generated\n        &gt;&gt;&gt; {'sql_tags': ['JOIN-PROJECT-ALL'],\n        &gt;&gt;&gt;    'queries': ['SELECT * FROM \"orders\" AS T1 JOIN customers AS T2 ON T1.customer_id=T2.customer_id'],\n        &gt;&gt;&gt;    'questions': ['Join all the records from table \"orders\" with table \"customers\" on \"customer_id\"']}\n\n        &gt;&gt;&gt; generator._generate_join_cat_columns(\"orders\")\n        &gt;&gt;&gt; generator.sql_generated\n        &gt;&gt;&gt; {'sql_tags': ['JOIN-PROJECT-CAT'],\n        &gt;&gt;&gt;    'queries': [\"SELECT T1.product, T2.name FROM orders AS T1 JOIN customers AS T2 ON T1.order_id=T2.order_id\"],\n        &gt;&gt;&gt;    'questions': ['List all the \"product\" and \"name\" from the table \"orders\" and the table \"customers\" where \"order_id\" is the same']}\n\n    Note:\n        The method makes use of other internal methods to firstly\n        get tables that can be joined with the given table and\n        generate SQL queries on this basis.\n    \"\"\"\n    self.empty_sql_generated()\n    # get columns to perform the join operator that contains\n    table_to_join2cols = self._get_table_name_to_join(table_name)\n    self._generate_join_cat_columns(table_name, table_to_join2cols)\n    self._generate_join_project_all(table_name, table_to_join2cols)\n    return self.sql_generated\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.NullGenerator","title":"<code>NullGenerator</code>","text":"<p>             Bases: <code>AbstractSqlGenerator</code></p> <p>A class for generating NULL SQL queries and corresponding questions based on a database table.</p> <p>Attributes:</p> Name Type Description <code>database</code> <code>SingleDatabase</code> <p>The SingleDatabase object representing the database to generate queries from.</p> <code>sql_generated</code> <code>dict</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}</p> Source code in <code>qatch/sql_generator/null_generator.py</code> <pre><code>class NullGenerator(AbstractSqlGenerator):\n    \"\"\"\n    A class for generating NULL SQL queries and corresponding questions based on a database table.\n\n    Attributes:\n        database (SingleDatabase): The SingleDatabase object representing the database to generate queries from.\n        sql_generated (dict): A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n    \"\"\"\n\n    def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n        \"\"\"\n        Generates NULL queries and corresponding questions.\n\n        Args:\n            table_name (str): The name of the table in the database.\n\n        Returns:\n            dict: A dictionary containing generated SQL tags, queries, and questions.\n                Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n\n        Examples:\n            Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" with 10 NULL values:\n            &gt;&gt;&gt; generator = NullGenerator(database)\n            &gt;&gt;&gt; generator._build_null_count('table_name', ['colors'])\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": ['NULL-COUNT'],\n                \"queries\": ['SELECT COUNT(*) FROM \"table_name\" WHERE \"colors\" IS NULL'],\n                \"questions\": ['Count the rows where the values of \"colors\" are missing in table \"table_name\"']\n            }\n            &gt;&gt;&gt; generator._build_not_null_count('table_name', ['colors'])\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": ['NOT-NULL-COUNT'],\n                \"queries\": ['SELECT COUNT(*) FROM \"table_name\" WHERE \"colors\" IS NOT NULL'],\n                \"questions\": ['Count the rows where the values of \"colors\" are not missing in table \"table_name\"']\n            }\n        \"\"\"\n        self.empty_sql_generated()\n        null_cols = self._get_null_cols(table_name)\n        self._build_null_count(table_name, null_cols)\n        self._build_not_null_count(table_name, null_cols)\n        # self._build_null_with_no_null_col(table_name)\n        return self.sql_generated\n\n    def _build_null_count(self, table_name: str, null_cols: list[str]):\n        \"\"\"\n        Build SQL queries and questions for counting rows with NULL values in specified columns.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            null_cols (list): List of column names with NULL values.\n        \"\"\"\n        queries = [f'SELECT COUNT(*) FROM `{table_name}` WHERE `{col}` IS NULL'\n                   for col in null_cols]\n\n        questions = [f'Count the rows where the values of \"{col}\" are missing in table \"{table_name}\"'\n                     for col in null_cols]\n\n        sql_tags = ['NULL-COUNT'] * len(queries)\n        self.append_sql_generated(sql_tags, queries, questions)\n\n    def _build_not_null_count(self, table_name, null_cols: list[str]):\n        \"\"\"\n        Build SQL queries and questions for counting rows with non-NULL values in specified columns.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            null_cols (list): List of column names with NULL values.\n        \"\"\"\n        queries = [f'SELECT COUNT(*) FROM `{table_name}` WHERE `{col}` IS NOT NULL'\n                   for col in null_cols]\n\n        questions = [f'Count the rows where the values of \"{col}\" are not missing in table \"{table_name}\"'\n                     for col in null_cols]\n\n        sql_tags = ['NOT-NULL-COUNT'] * len(queries)\n        self.append_sql_generated(sql_tags, queries, questions)\n\n    def _get_null_cols(self, table_name: str, sample=2):\n        def _get_sample(_columns, k):\n            random.seed(self.seed)\n            return random.sample(_columns, k)\n\n        \"\"\"\n        Randomly select columns with NULL values from the given table for generating queries.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            sample (int, optional): Number of columns to sample. Default is 2.\n\n        Returns:\n            list: List of column names with NULL values.\n        \"\"\"\n        df, _, _ = self._sample_cat_num_cols(table_name)\n        mask = df.isnull().any()\n        cols = list(df.columns[mask])\n        return _get_sample(cols, sample) if len(cols) &gt;= sample else cols\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.NullGenerator.sql_generate","title":"<code>sql_generate(table_name)</code>","text":"<p>Generates NULL queries and corresponding questions.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table in the database.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, list]</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}</p> <p>Examples:</p> <p>Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" with 10 NULL values:</p> <pre><code>&gt;&gt;&gt; generator = NullGenerator(database)\n&gt;&gt;&gt; generator._build_null_count('table_name', ['colors'])\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": ['NULL-COUNT'],\n    \"queries\": ['SELECT COUNT(*) FROM \"table_name\" WHERE \"colors\" IS NULL'],\n    \"questions\": ['Count the rows where the values of \"colors\" are missing in table \"table_name\"']\n}\n&gt;&gt;&gt; generator._build_not_null_count('table_name', ['colors'])\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": ['NOT-NULL-COUNT'],\n    \"queries\": ['SELECT COUNT(*) FROM \"table_name\" WHERE \"colors\" IS NOT NULL'],\n    \"questions\": ['Count the rows where the values of \"colors\" are not missing in table \"table_name\"']\n}\n</code></pre> Source code in <code>qatch/sql_generator/null_generator.py</code> <pre><code>def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n    \"\"\"\n    Generates NULL queries and corresponding questions.\n\n    Args:\n        table_name (str): The name of the table in the database.\n\n    Returns:\n        dict: A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n\n    Examples:\n        Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" with 10 NULL values:\n        &gt;&gt;&gt; generator = NullGenerator(database)\n        &gt;&gt;&gt; generator._build_null_count('table_name', ['colors'])\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": ['NULL-COUNT'],\n            \"queries\": ['SELECT COUNT(*) FROM \"table_name\" WHERE \"colors\" IS NULL'],\n            \"questions\": ['Count the rows where the values of \"colors\" are missing in table \"table_name\"']\n        }\n        &gt;&gt;&gt; generator._build_not_null_count('table_name', ['colors'])\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": ['NOT-NULL-COUNT'],\n            \"queries\": ['SELECT COUNT(*) FROM \"table_name\" WHERE \"colors\" IS NOT NULL'],\n            \"questions\": ['Count the rows where the values of \"colors\" are not missing in table \"table_name\"']\n        }\n    \"\"\"\n    self.empty_sql_generated()\n    null_cols = self._get_null_cols(table_name)\n    self._build_null_count(table_name, null_cols)\n    self._build_not_null_count(table_name, null_cols)\n    # self._build_null_with_no_null_col(table_name)\n    return self.sql_generated\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.OrderByGenerator","title":"<code>OrderByGenerator</code>","text":"<p>             Bases: <code>AbstractSqlGenerator</code></p> <p>A class for generating ORDER BY SQL queries and corresponding questions based on a database table.</p> <p>Attributes:</p> Name Type Description <code>database</code> <code>SingleDatabase</code> <p>The SingleDatabase object representing the database to generate queries from.</p> <code>sql_generated</code> <code>dict</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}</p> Source code in <code>qatch/sql_generator/orderby_generator.py</code> <pre><code>class OrderByGenerator(AbstractSqlGenerator):\n    \"\"\"\n    A class for generating ORDER BY SQL queries and corresponding questions based on a database table.\n\n    Attributes:\n        database (SingleDatabase): The SingleDatabase object representing the database to generate queries from.\n        sql_generated (dict): A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n    \"\"\"\n\n    def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n        \"\"\"\n        Generate ORDER BY queries and corresponding questions based on the specified table.\n\n        Args:\n            table_name (str): The name of the table in the database.\n\n        Returns:\n            dict: A dictionary containing generated SQL tags, queries, and questions.\n                Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n\n        Examples:\n            Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"\n            &gt;&gt;&gt; generator = OrderByGenerator(database)\n            &gt;&gt;&gt; generator._generate_order_asc(\"table_name\", [\"colors\", \"numbers\"])\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"ORDERBY-SINGLE\", \"ORDERBY-SINGLE\"],\n                \"queries\": [\n                    'SELECT * FROM \"table_name\" ORDER BY \"colors\" ASC',\n                    'SELECT * FROM \"table_name\" ORDER BY \"numbers\" ASC'\n                ],\n                \"questions\": [\n                    'Show all data ordered by \"colors\" in ascending order for the table \"table_name\"',\n                    'Show all data ordered by \"numbers\" in ascending order for the table \"table_name\"'\n                ]\n            }\n            &gt;&gt;&gt; generator._generate_order_desc(\"table_name\", [\"colors\", \"numbers\"])\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"ORDERBY-SINGLE\", \"ORDERBY-SINGLE\"],\n                \"queries\": [\n                    'SELECT * FROM \"table_name\" ORDER BY \"colors\" DESC',\n                    'SELECT * FROM \"table_name\" ORDER BY \"numbers\" DESC'\n                ],\n                \"questions\": [\n                    'Show all data ordered by \"colors\" in descending order for the table \"table_name\"',\n                    'Show all data ordered by \"numbers\" in descending order for the table \"table_name\"'\n                ]\n            }\n            &gt;&gt;&gt; generator._generate_order_asc_project(\"table_name\", [\"colors\", \"numbers\"])\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"ORDERBY-PROJECT\", \"ORDERBY-PROJECT\"],\n                \"queries\": [\n                    'SELECT \"colors\" FROM \"table_name\" ORDER BY \"colors\" ASC',\n                    'SELECT \"numbers\" FROM \"table_name\" ORDER BY \"numbers\" ASC'\n                ],\n                \"questions\": [\n                    'Project the \"colors\" ordered in ascending order for the table \"table_name\"',\n                    'Project the \"numbers\" ordered in ascending order for the table \"table_name\"'\n                ]\n            }\n            &gt;&gt;&gt; generator._generate_order_desc_project(\"table_name\", [\"colors\", \"numbers\"])\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"ORDERBY-PROJECT\", \"ORDERBY-PROJECT\"],\n                \"queries\": [\n                    'SELECT \"colors\" FROM \"table_name\" ORDER BY \"colors\" DESC',\n                    'SELECT \"numbers\" FROM \"table_name\" ORDER BY \"numbers\" DESC'\n                ],\n                \"questions\": [\n                    'Project the \"colors\" ordered in descending order for the table \"table_name\"',\n                    'Project the \"numbers\" ordered in descending order for the table \"table_name\"'\n                ]\n            }\n        \"\"\"\n        self.empty_sql_generated()\n        # to avoid too many ORDERBY sql queries, sample only 2 Cate and 2 numerical columns\n        _, cat_cols, num_cols = self._sample_cat_num_cols(table_name, sample=2)\n        columns = cat_cols + num_cols\n        self._generate_order_asc(table_name, columns)\n        self._generate_order_desc(table_name, columns)\n\n        self._generate_order_asc_project(table_name, columns)\n\n        self._generate_order_desc_project(table_name, columns)\n        return self.sql_generated\n\n    def _generate_order_asc(self, table_name: str, columns: list[str]):\n        \"\"\"\n        Generates SQL queries and questions for ordering data in ascending order for each column.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            columns (list): List of column names.\n        \"\"\"\n        queries = [f'SELECT * FROM `{table_name}` ORDER BY `{col}` ASC'\n                   for col in columns]\n\n        questions = [\n            f'Show all data ordered by \"{col}\" in ascending order for the table \"{table_name}\"'\n            for col in columns\n        ]\n        sql_tags = ['ORDERBY-SINGLE'] * len(queries)\n        self.append_sql_generated(sql_tags, queries, questions)\n\n    def _generate_order_desc(self, table_name: str, columns: list[str]):\n        \"\"\"\n        Generates SQL queries and questions for ordering data in descending order for each column.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            columns (list): List of column names.\n        \"\"\"\n        queries = [f'SELECT * FROM `{table_name}` ORDER BY `{col}` DESC'\n                   for col in columns]\n\n        questions = [\n            f'Show all data ordered by {col} in descending order for the table {table_name}'\n            for col in columns\n        ]\n        sql_tags = ['ORDERBY-SINGLE'] * len(queries)\n        self.append_sql_generated(sql_tags, queries, questions)\n\n    def _generate_order_asc_project(self, table_name: str, columns: list[str]):\n        \"\"\"\n        Generates SQL queries and questions for projecting a single column and ordering it in ascending order.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            columns (list): List of column names.\n        \"\"\"\n        queries = [f'SELECT `{col}` FROM `{table_name}` ORDER BY `{col}` ASC'\n                   for col in columns]\n\n        questions = [\n            f'Project the \"{col}\" ordered in ascending order for the table {table_name}'\n            for col in columns\n        ]\n        sql_tags = ['ORDERBY-PROJECT'] * len(queries)\n        self.append_sql_generated(sql_tags, queries, questions)\n\n    def _generate_order_desc_project(self, table_name: str, columns: list[str]):\n        \"\"\"\n        Generates SQL queries and questions for projecting a single column and ordering it in descending order.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            columns (list): List of column names.\n        \"\"\"\n        queries = [f'SELECT `{col}` FROM `{table_name}` ORDER BY `{col}` DESC'\n                   for col in columns]\n\n        questions = [\n            f'Project the \"{col}\" ordered in descending order for the table {table_name}'\n            for col in columns\n        ]\n        sql_tags = ['ORDERBY-PROJECT'] * len(queries)\n        self.append_sql_generated(sql_tags, queries, questions)\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.OrderByGenerator.sql_generate","title":"<code>sql_generate(table_name)</code>","text":"<p>Generate ORDER BY queries and corresponding questions based on the specified table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table in the database.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, list]</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}</p> <p>Examples:</p> <p>Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"</p> <pre><code>&gt;&gt;&gt; generator = OrderByGenerator(database)\n&gt;&gt;&gt; generator._generate_order_asc(\"table_name\", [\"colors\", \"numbers\"])\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"ORDERBY-SINGLE\", \"ORDERBY-SINGLE\"],\n    \"queries\": [\n        'SELECT * FROM \"table_name\" ORDER BY \"colors\" ASC',\n        'SELECT * FROM \"table_name\" ORDER BY \"numbers\" ASC'\n    ],\n    \"questions\": [\n        'Show all data ordered by \"colors\" in ascending order for the table \"table_name\"',\n        'Show all data ordered by \"numbers\" in ascending order for the table \"table_name\"'\n    ]\n}\n&gt;&gt;&gt; generator._generate_order_desc(\"table_name\", [\"colors\", \"numbers\"])\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"ORDERBY-SINGLE\", \"ORDERBY-SINGLE\"],\n    \"queries\": [\n        'SELECT * FROM \"table_name\" ORDER BY \"colors\" DESC',\n        'SELECT * FROM \"table_name\" ORDER BY \"numbers\" DESC'\n    ],\n    \"questions\": [\n        'Show all data ordered by \"colors\" in descending order for the table \"table_name\"',\n        'Show all data ordered by \"numbers\" in descending order for the table \"table_name\"'\n    ]\n}\n&gt;&gt;&gt; generator._generate_order_asc_project(\"table_name\", [\"colors\", \"numbers\"])\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"ORDERBY-PROJECT\", \"ORDERBY-PROJECT\"],\n    \"queries\": [\n        'SELECT \"colors\" FROM \"table_name\" ORDER BY \"colors\" ASC',\n        'SELECT \"numbers\" FROM \"table_name\" ORDER BY \"numbers\" ASC'\n    ],\n    \"questions\": [\n        'Project the \"colors\" ordered in ascending order for the table \"table_name\"',\n        'Project the \"numbers\" ordered in ascending order for the table \"table_name\"'\n    ]\n}\n&gt;&gt;&gt; generator._generate_order_desc_project(\"table_name\", [\"colors\", \"numbers\"])\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"ORDERBY-PROJECT\", \"ORDERBY-PROJECT\"],\n    \"queries\": [\n        'SELECT \"colors\" FROM \"table_name\" ORDER BY \"colors\" DESC',\n        'SELECT \"numbers\" FROM \"table_name\" ORDER BY \"numbers\" DESC'\n    ],\n    \"questions\": [\n        'Project the \"colors\" ordered in descending order for the table \"table_name\"',\n        'Project the \"numbers\" ordered in descending order for the table \"table_name\"'\n    ]\n}\n</code></pre> Source code in <code>qatch/sql_generator/orderby_generator.py</code> <pre><code>def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n    \"\"\"\n    Generate ORDER BY queries and corresponding questions based on the specified table.\n\n    Args:\n        table_name (str): The name of the table in the database.\n\n    Returns:\n        dict: A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n\n    Examples:\n        Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"\n        &gt;&gt;&gt; generator = OrderByGenerator(database)\n        &gt;&gt;&gt; generator._generate_order_asc(\"table_name\", [\"colors\", \"numbers\"])\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"ORDERBY-SINGLE\", \"ORDERBY-SINGLE\"],\n            \"queries\": [\n                'SELECT * FROM \"table_name\" ORDER BY \"colors\" ASC',\n                'SELECT * FROM \"table_name\" ORDER BY \"numbers\" ASC'\n            ],\n            \"questions\": [\n                'Show all data ordered by \"colors\" in ascending order for the table \"table_name\"',\n                'Show all data ordered by \"numbers\" in ascending order for the table \"table_name\"'\n            ]\n        }\n        &gt;&gt;&gt; generator._generate_order_desc(\"table_name\", [\"colors\", \"numbers\"])\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"ORDERBY-SINGLE\", \"ORDERBY-SINGLE\"],\n            \"queries\": [\n                'SELECT * FROM \"table_name\" ORDER BY \"colors\" DESC',\n                'SELECT * FROM \"table_name\" ORDER BY \"numbers\" DESC'\n            ],\n            \"questions\": [\n                'Show all data ordered by \"colors\" in descending order for the table \"table_name\"',\n                'Show all data ordered by \"numbers\" in descending order for the table \"table_name\"'\n            ]\n        }\n        &gt;&gt;&gt; generator._generate_order_asc_project(\"table_name\", [\"colors\", \"numbers\"])\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"ORDERBY-PROJECT\", \"ORDERBY-PROJECT\"],\n            \"queries\": [\n                'SELECT \"colors\" FROM \"table_name\" ORDER BY \"colors\" ASC',\n                'SELECT \"numbers\" FROM \"table_name\" ORDER BY \"numbers\" ASC'\n            ],\n            \"questions\": [\n                'Project the \"colors\" ordered in ascending order for the table \"table_name\"',\n                'Project the \"numbers\" ordered in ascending order for the table \"table_name\"'\n            ]\n        }\n        &gt;&gt;&gt; generator._generate_order_desc_project(\"table_name\", [\"colors\", \"numbers\"])\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"ORDERBY-PROJECT\", \"ORDERBY-PROJECT\"],\n            \"queries\": [\n                'SELECT \"colors\" FROM \"table_name\" ORDER BY \"colors\" DESC',\n                'SELECT \"numbers\" FROM \"table_name\" ORDER BY \"numbers\" DESC'\n            ],\n            \"questions\": [\n                'Project the \"colors\" ordered in descending order for the table \"table_name\"',\n                'Project the \"numbers\" ordered in descending order for the table \"table_name\"'\n            ]\n        }\n    \"\"\"\n    self.empty_sql_generated()\n    # to avoid too many ORDERBY sql queries, sample only 2 Cate and 2 numerical columns\n    _, cat_cols, num_cols = self._sample_cat_num_cols(table_name, sample=2)\n    columns = cat_cols + num_cols\n    self._generate_order_asc(table_name, columns)\n    self._generate_order_desc(table_name, columns)\n\n    self._generate_order_asc_project(table_name, columns)\n\n    self._generate_order_desc_project(table_name, columns)\n    return self.sql_generated\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.SelectGenerator","title":"<code>SelectGenerator</code>","text":"<p>             Bases: <code>AbstractSqlGenerator</code></p> <p>A class for generating SELECT SQL queries and corresponding questions based on a database table.</p> <p>Attributes:</p> Name Type Description <code>database</code> <code>SingleDatabase</code> <p>The SingleDatabase object representing the database to generate queries from.</p> <code>sql_generated</code> <code>dict</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}</p> Source code in <code>qatch/sql_generator/select_generator.py</code> <pre><code>class SelectGenerator(AbstractSqlGenerator):\n    \"\"\"\n    A class for generating SELECT SQL queries and corresponding questions based on a database table.\n\n    Attributes:\n        database (SingleDatabase): The SingleDatabase object representing the database to generate queries from.\n        sql_generated (dict): A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n    \"\"\"\n\n    def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n        \"\"\"\n        Generate SQL tags, queries, and questions based on the specified table.\n\n        Args:\n            table_name (str): The name of the table in the database.\n\n        Returns:\n            dict: A dictionary containing generated SQL tags, queries, and questions.\n                Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n\n        Examples:\n            Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"name\", \"colors\" and \"numbers\":\n            &gt;&gt;&gt; generator = SelectGenerator(database)\n            &gt;&gt;&gt; generator._select_all_table(\"table_name\")\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"SELECT-ALL\"],\n                \"queries\": ['SELECT * FROM \"table_name\"'],\n                \"questions\": [\"Show all the rows in the table table_name\"]\n            }\n            &gt;&gt;&gt; generator._select_add_col(\"table_name\")\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"SELECT-ADD-COL\", \"SELECT-ADD-COL\", \"SELECT-ADD-COL\"],\n                \"queries\": ['SELECT \"colors\" FROM \"table_name\"',\n                            'SELECT \"colors\", \"numbers\" FROM \"table_name\"'\n                            'SELECT \"colors\", \"numbers\", \"name\" FROM \"table_name\"'],\n                \"questions\": [\"Show all colors in the table table_name\",\n                              \"Show all colors, numbers in the table table_name\"\n                              \"Show all colors, numbers, name in the table table_name\"]\n            }\n            &gt;&gt;&gt; generator._select_random_col(\"table_name\")\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"SELECT-RANDOM-COL\", \"SELECT-RANDOM-COL\"],\n                \"queries\": ['SELECT \"colors\" FROM \"table_name\"',\n                            'SELECT \"name\", \"numbers\" FROM \"table_name\"',\n                            'SELECT \"numbers\", \"colors\", \"name\" FROM \"table_name\"'],\n                \"questions\": [\"Show all colors in the table table_name\",\n                              \"Show all name, numbers in the table table_name\",\n                              \"Show all numbers, colors, name in the table table_name\"]\n            }\n\n        \"\"\"\n        self.empty_sql_generated()\n        self._select_all_table(table_name)\n        self._select_add_col(table_name)\n        self._select_random_col(table_name)\n        return self.sql_generated\n\n    def _select_single_col(self, table_name):\n        \"\"\"Generates SELECT SQL queries and corresponding questions for a single column of a given table.\n\n        This method selects each column of a given table one by one and generates SQL queries\n        and corresponding questions. These queries and questions are stored in the 'sql_generated' dictionary attribute of the class.\n\n        Args:\n            table_name (str): Name of the table.\n        Example:\n            Assume the 'users' table has two columns 'id' and 'name'.\n\n                &gt;&gt;&gt; self.database = SingleDatabase('sqlite:///my_db.sqlite3')\n                &gt;&gt;&gt; sql_gen = SelectGenerator(self.database)\n                &gt;&gt;&gt; sql_gen._select_single_col('users')\n                ...\n                &gt;&gt;&gt; print(sql_gen.sql_generated)\n                {\n                    \"sql_tags\": [\"SELECT-SINGLE-COL\", \"SELECT-SINGLE-COL\"],\n                    \"queries\": [\"SELECT \"id\" FROM users;\", \"SELECT \"name\" FROM users;\"],\n                    \"questions\": [\"What are the \"id\" for all users?\", \"What are the \"name\" of all users?\"]\n                }\n        \"\"\"\n        columns = self.database.get_schema_given(table_name).name.tolist()\n        columns = [[col] for col in columns]\n        # sort columns\n        questions = self._build_questions(columns, table_name)\n        queries = self._build_queries(columns, table_name)\n        self.append_sql_generated(sql_tags=['SELECT-SINGLE-COL'] * len(queries),\n                                  queries=queries,\n                                  questions=questions)\n        return self.sql_generated\n\n    def _select_all_table(self, table_name: str):\n        \"\"\"\n        Generate the SQL query and question for selecting all rows in the table.\n\n        Args:\n            table_name (str): The name of the table in the database.\n        \"\"\"\n        sql_tag = ['SELECT-ALL']\n        query = [f'SELECT * FROM `{table_name}`']\n        question = [f\"Show all the rows in the table {table_name}\"]\n        self.append_sql_generated(sql_tags=sql_tag, queries=query, questions=question)\n\n    def _select_add_col(self, table_name: str):\n        \"\"\"\n        Generate the SQL query and question for selecting increasingly more columns in the table.\n\n        Args:\n            table_name (str): The name of the table in the database.\n        \"\"\"\n        columns = self.database.get_schema_given(table_name).name.tolist()\n        comb_cols_add = self._comb_add_columns(columns)\n\n        questions = self._build_questions(comb_cols_add, table_name)\n        queries = self._build_queries(comb_cols_add, table_name)\n\n        self.append_sql_generated(sql_tags=['SELECT-ADD-COL'] * len(comb_cols_add),\n                                  queries=queries, questions=questions)\n\n    def _select_random_col(self, table_name: str):\n        \"\"\"\n        Generate the SQL query and question for selecting random columns in the table.\n\n        Args:\n            table_name (str): The name of the table in the database.\n        \"\"\"\n        columns = self.database.get_schema_given(table_name).name.tolist()\n        comb_cols_rand = self._comb_random(columns)\n\n        questions = self._build_questions(comb_cols_rand, table_name)\n        queries = self._build_queries(comb_cols_rand, table_name)\n\n        self.append_sql_generated(sql_tags=['SELECT-RANDOM-COL'] * len(comb_cols_rand),\n                                  queries=queries, questions=questions)\n\n    def _build_questions(self, combinations: list[list[str]], table_name) -&gt; list[str]:\n        \"\"\"\n        Builds questions corresponding to the given column combinations and table name.\n\n        Args:\n            combinations (list[list[str]]): List of column combinations.\n            table_name (str): The name of the table in the database.\n\n        Returns:\n            list[str]: A list of questions corresponding to the column combinations.\n        \"\"\"\n        return [f'Show all {self._get_col_comb_str(comb)} in the table {table_name}'\n                for comb in combinations]\n\n    def _build_queries(self, combinations: list[list[str]], table_name: str) -&gt; list[str]:\n        \"\"\"\n        Builds SQL queries corresponding to the given column combinations and table name.\n\n        Args:\n            combinations (list[list[str]]): List of column combinations.\n            table_name (str): The name of the table in the database.\n\n        Returns:\n            list[str]: A list of SQL queries corresponding to the column combinations.\n        \"\"\"\n        return [f'SELECT {self._get_col_comb_str(comb)} FROM `{table_name}`'\n                for comb in combinations]\n\n    @staticmethod\n    def _comb_add_columns(columns: list[str]) -&gt; list[list[str]]:\n        \"\"\"\n        Generates column combinations by incrementally adding columns to the query.\n\n        Args:\n            columns (list[str]): List of column names.\n\n        Returns:\n            list[list[str]]: A list of column combinations.\n        \"\"\"\n        return [columns[:i] for i in range(1, len(columns))]\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.SelectGenerator.sql_generate","title":"<code>sql_generate(table_name)</code>","text":"<p>Generate SQL tags, queries, and questions based on the specified table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table in the database.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, list]</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}</p> <p>Examples:</p> <p>Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"name\", \"colors\" and \"numbers\":</p> <pre><code>&gt;&gt;&gt; generator = SelectGenerator(database)\n&gt;&gt;&gt; generator._select_all_table(\"table_name\")\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"SELECT-ALL\"],\n    \"queries\": ['SELECT * FROM \"table_name\"'],\n    \"questions\": [\"Show all the rows in the table table_name\"]\n}\n&gt;&gt;&gt; generator._select_add_col(\"table_name\")\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"SELECT-ADD-COL\", \"SELECT-ADD-COL\", \"SELECT-ADD-COL\"],\n    \"queries\": ['SELECT \"colors\" FROM \"table_name\"',\n                'SELECT \"colors\", \"numbers\" FROM \"table_name\"'\n                'SELECT \"colors\", \"numbers\", \"name\" FROM \"table_name\"'],\n    \"questions\": [\"Show all colors in the table table_name\",\n                  \"Show all colors, numbers in the table table_name\"\n                  \"Show all colors, numbers, name in the table table_name\"]\n}\n&gt;&gt;&gt; generator._select_random_col(\"table_name\")\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"SELECT-RANDOM-COL\", \"SELECT-RANDOM-COL\"],\n    \"queries\": ['SELECT \"colors\" FROM \"table_name\"',\n                'SELECT \"name\", \"numbers\" FROM \"table_name\"',\n                'SELECT \"numbers\", \"colors\", \"name\" FROM \"table_name\"'],\n    \"questions\": [\"Show all colors in the table table_name\",\n                  \"Show all name, numbers in the table table_name\",\n                  \"Show all numbers, colors, name in the table table_name\"]\n}\n</code></pre> Source code in <code>qatch/sql_generator/select_generator.py</code> <pre><code>def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n    \"\"\"\n    Generate SQL tags, queries, and questions based on the specified table.\n\n    Args:\n        table_name (str): The name of the table in the database.\n\n    Returns:\n        dict: A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n\n    Examples:\n        Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"name\", \"colors\" and \"numbers\":\n        &gt;&gt;&gt; generator = SelectGenerator(database)\n        &gt;&gt;&gt; generator._select_all_table(\"table_name\")\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"SELECT-ALL\"],\n            \"queries\": ['SELECT * FROM \"table_name\"'],\n            \"questions\": [\"Show all the rows in the table table_name\"]\n        }\n        &gt;&gt;&gt; generator._select_add_col(\"table_name\")\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"SELECT-ADD-COL\", \"SELECT-ADD-COL\", \"SELECT-ADD-COL\"],\n            \"queries\": ['SELECT \"colors\" FROM \"table_name\"',\n                        'SELECT \"colors\", \"numbers\" FROM \"table_name\"'\n                        'SELECT \"colors\", \"numbers\", \"name\" FROM \"table_name\"'],\n            \"questions\": [\"Show all colors in the table table_name\",\n                          \"Show all colors, numbers in the table table_name\"\n                          \"Show all colors, numbers, name in the table table_name\"]\n        }\n        &gt;&gt;&gt; generator._select_random_col(\"table_name\")\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"SELECT-RANDOM-COL\", \"SELECT-RANDOM-COL\"],\n            \"queries\": ['SELECT \"colors\" FROM \"table_name\"',\n                        'SELECT \"name\", \"numbers\" FROM \"table_name\"',\n                        'SELECT \"numbers\", \"colors\", \"name\" FROM \"table_name\"'],\n            \"questions\": [\"Show all colors in the table table_name\",\n                          \"Show all name, numbers in the table table_name\",\n                          \"Show all numbers, colors, name in the table table_name\"]\n        }\n\n    \"\"\"\n    self.empty_sql_generated()\n    self._select_all_table(table_name)\n    self._select_add_col(table_name)\n    self._select_random_col(table_name)\n    return self.sql_generated\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.SimpleAggGenerator","title":"<code>SimpleAggGenerator</code>","text":"<p>             Bases: <code>AbstractSqlGenerator</code></p> <p>A class for generating Simple Aggregation queries and corresponding questions based on a database table.</p> <p>Attributes:</p> Name Type Description <code>database</code> <code>SingleDatabase</code> <p>The SingleDatabase object representing the database to generate queries from.</p> <code>sql_generated</code> <code>dict</code> <p>A dictionary containing generated SQL tags, queries, and questions. Format: {\"sql_tags\": List[str], \"queries\": List[str], \"questions\": List[str]}</p> Source code in <code>qatch/sql_generator/simple_agg_generator.py</code> <pre><code>class SimpleAggGenerator(AbstractSqlGenerator):\n    \"\"\"\n    A class for generating Simple Aggregation queries and corresponding questions based on a database table.\n\n    Attributes:\n        database (SingleDatabase): The SingleDatabase object representing the database to generate queries from.\n        sql_generated (dict): A dictionary containing generated SQL tags, queries, and questions.\n            Format: {\"sql_tags\": List[str], \"queries\": List[str], \"questions\": List[str]}\n    \"\"\"\n\n    def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n        \"\"\"\n        Generates Simple Aggregation SQL queries and corresponding questions for the specified table.\n\n        Args:\n            table_name (str): The name of the table in the database.\n\n        Returns:\n            dict: A dictionary containing generated SQL tags, queries, and questions.\n                  Format: {\"sql_tags\": List[str], \"queries\": List[str], \"questions\": List[str]}\n\n        Examples:\n            Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"\n            &gt;&gt;&gt; generator = SimpleAggGenerator(database)\n            &gt;&gt;&gt; generator._build_count_cat(\"table_name\", [\"colors\"])\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"SIMPLE-AGG-COUNT\", \"SIMPLE-AGG-COUNT-DISTINCT\"],\n                \"queries\": [\n                    'SELECT COUNT(*) FROM \"table_name\"',\n                    'SELECT COUNT(DISTINCT\"colors\") FROM \"table_name\"'\n                ],\n                \"questions\": [\n                    'Count the records in table \"table_name\"?',\n                    'How many different \"colors\" are in table \"table_name\"?'\n                ]\n            }\n            &gt;&gt;&gt; generator._build_count_agg(\"table_name\", [\"numbers\"])\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"SIMPLE-AGG-MAX\", \"SIMPLE-AGG-MIN\", \"SIMPLE-AGG-AVG\"],\n                \"queries\": [\n                    'SELECT MAX(\"numbers\") FROM \"table_name\"',\n                    'SELECT MIN(\"numbers\") FROM \"table_name\"',\n                    'SELECT AVG(\"numbers\") FROM \"table_name\"'\n                ],\n                \"questions\": [\n                    'Find the maximum \"numbers\" for the table \"table_name\"',\n                    'Find the minimum \"numbers\" for the table \"table_name\"',\n                    'Find the average \"numbers\" for the table \"table_name\"'\n                ]\n            }\n        \"\"\"\n        self.empty_sql_generated()\n        _, cat_cols, num_cols = self._sample_cat_num_cols(table_name)\n        self._build_count_cat(table_name, cat_cols)\n        self._build_count_agg(table_name, num_cols)\n        return self.sql_generated\n\n    def _build_count_cat(self, table_name, cat_cols):\n        \"\"\"\n        Generates COUNT SQL queries and questions for categorical columns.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            cat_cols (List[str]): List of categorical columns in the table.\n        \"\"\"\n\n        queries = [f'SELECT COUNT(*) FROM `{table_name}`']\n        questions = [f'Count the records in table \"{table_name}\"?']\n        sql_tags = ['SIMPLE-AGG-COUNT']\n\n        for cat_col in cat_cols:\n            queries += [f'SELECT COUNT(DISTINCT `{cat_col}`) FROM `{table_name}`']\n            questions += [f'How many different \"{cat_col}\" are in table \"{table_name}\"?']\n            sql_tags += ['SIMPLE-AGG-COUNT-DISTINCT']\n\n        self.append_sql_generated(sql_tags, queries, questions)\n\n    def _build_count_agg(self, table_name, num_cols):\n        \"\"\"\n        Generates MAX, MIN, and AVG SQL queries and questions for numerical columns.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            num_cols (List[str]): List of numerical columns in the table.\n        \"\"\"\n        for num_col in num_cols:\n            queries = [\n                f'SELECT MAX(`{num_col}`) FROM `{table_name}`',\n                f'SELECT MIN(`{num_col}`) FROM `{table_name}`',\n                f'SELECT AVG(`{num_col}`) FROM `{table_name}`'\n            ]\n            questions = [\n                f'Find the maximum \"{num_col}\" for the table \"{table_name}\"',\n                f'Find the minimum \"{num_col}\" for the table \"{table_name}\"',\n                f'Find the average \"{num_col}\" for the table \"{table_name}\"'\n            ]\n            sql_tags = ['SIMPLE-AGG-MAX', 'SIMPLE-AGG-MIN', 'SIMPLE-AGG-AVG']\n            self.append_sql_generated(sql_tags, queries, questions)\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.SimpleAggGenerator.sql_generate","title":"<code>sql_generate(table_name)</code>","text":"<p>Generates Simple Aggregation SQL queries and corresponding questions for the specified table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table in the database.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, list]</code> <p>A dictionary containing generated SQL tags, queries, and questions.   Format: {\"sql_tags\": List[str], \"queries\": List[str], \"questions\": List[str]}</p> <p>Examples:</p> <p>Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"</p> <pre><code>&gt;&gt;&gt; generator = SimpleAggGenerator(database)\n&gt;&gt;&gt; generator._build_count_cat(\"table_name\", [\"colors\"])\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"SIMPLE-AGG-COUNT\", \"SIMPLE-AGG-COUNT-DISTINCT\"],\n    \"queries\": [\n        'SELECT COUNT(*) FROM \"table_name\"',\n        'SELECT COUNT(DISTINCT\"colors\") FROM \"table_name\"'\n    ],\n    \"questions\": [\n        'Count the records in table \"table_name\"?',\n        'How many different \"colors\" are in table \"table_name\"?'\n    ]\n}\n&gt;&gt;&gt; generator._build_count_agg(\"table_name\", [\"numbers\"])\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"SIMPLE-AGG-MAX\", \"SIMPLE-AGG-MIN\", \"SIMPLE-AGG-AVG\"],\n    \"queries\": [\n        'SELECT MAX(\"numbers\") FROM \"table_name\"',\n        'SELECT MIN(\"numbers\") FROM \"table_name\"',\n        'SELECT AVG(\"numbers\") FROM \"table_name\"'\n    ],\n    \"questions\": [\n        'Find the maximum \"numbers\" for the table \"table_name\"',\n        'Find the minimum \"numbers\" for the table \"table_name\"',\n        'Find the average \"numbers\" for the table \"table_name\"'\n    ]\n}\n</code></pre> Source code in <code>qatch/sql_generator/simple_agg_generator.py</code> <pre><code>def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n    \"\"\"\n    Generates Simple Aggregation SQL queries and corresponding questions for the specified table.\n\n    Args:\n        table_name (str): The name of the table in the database.\n\n    Returns:\n        dict: A dictionary containing generated SQL tags, queries, and questions.\n              Format: {\"sql_tags\": List[str], \"queries\": List[str], \"questions\": List[str]}\n\n    Examples:\n        Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"\n        &gt;&gt;&gt; generator = SimpleAggGenerator(database)\n        &gt;&gt;&gt; generator._build_count_cat(\"table_name\", [\"colors\"])\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"SIMPLE-AGG-COUNT\", \"SIMPLE-AGG-COUNT-DISTINCT\"],\n            \"queries\": [\n                'SELECT COUNT(*) FROM \"table_name\"',\n                'SELECT COUNT(DISTINCT\"colors\") FROM \"table_name\"'\n            ],\n            \"questions\": [\n                'Count the records in table \"table_name\"?',\n                'How many different \"colors\" are in table \"table_name\"?'\n            ]\n        }\n        &gt;&gt;&gt; generator._build_count_agg(\"table_name\", [\"numbers\"])\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"SIMPLE-AGG-MAX\", \"SIMPLE-AGG-MIN\", \"SIMPLE-AGG-AVG\"],\n            \"queries\": [\n                'SELECT MAX(\"numbers\") FROM \"table_name\"',\n                'SELECT MIN(\"numbers\") FROM \"table_name\"',\n                'SELECT AVG(\"numbers\") FROM \"table_name\"'\n            ],\n            \"questions\": [\n                'Find the maximum \"numbers\" for the table \"table_name\"',\n                'Find the minimum \"numbers\" for the table \"table_name\"',\n                'Find the average \"numbers\" for the table \"table_name\"'\n            ]\n        }\n    \"\"\"\n    self.empty_sql_generated()\n    _, cat_cols, num_cols = self._sample_cat_num_cols(table_name)\n    self._build_count_cat(table_name, cat_cols)\n    self._build_count_agg(table_name, num_cols)\n    return self.sql_generated\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.WhereGenerator","title":"<code>WhereGenerator</code>","text":"<p>             Bases: <code>AbstractSqlGenerator</code></p> <p>A class for generating WHERE SQL queries and corresponding questions based on a database table.</p> <p>Attributes:</p> Name Type Description <code>database</code> <code>SingleDatabase</code> <p>The SingleDatabase object representing the database to generate queries from.</p> <code>sql_generated</code> <code>dict</code> <p>A dictionary containing generated SQL tags, queries, questions, and results. Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str], \"results\": list[pd.DataFrame]}</p> Source code in <code>qatch/sql_generator/where_generator.py</code> <pre><code>class WhereGenerator(AbstractSqlGenerator):\n    \"\"\"\n    A class for generating WHERE SQL queries and corresponding questions based on a database table.\n\n    Attributes:\n        database (SingleDatabase): The SingleDatabase object representing the database to generate queries from.\n        sql_generated (dict): A dictionary containing generated SQL tags, queries, questions, and results.\n            Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str], \"results\": list[pd.DataFrame]}\n    \"\"\"\n\n    def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n        \"\"\"\n        Generates WHERE SQL queries and corresponding questions for both categorical and numerical columns.\n\n        Args:\n            table_name (str): The name of the table in the database.\n\n        Returns:\n            dict: A dictionary containing generated SQL tags, queries, questions, and results.\n                  Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n\n        Examples:\n            Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"\n            &gt;&gt;&gt; sample_df = pd.DataFrame({\"colors\": [\"green\", \"blue\", \"blue\", \"blue\", \"blue\"], \"numbers\": [1, 2, 3, 4, 5]})\n            &gt;&gt;&gt; generator = WhereGenerator(database)\n            &gt;&gt;&gt; generator._generate_where_categorical(\"table_name\", [\"colors\"], sample_df)\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": [\"WHERE-CAT-MOST-FREQUENT\", \"WHERE-CAT-LEAST-FREQUENT\",\n                            'WHERE-CAT-MOST-FREQUENT', 'WHERE-CAT-LEAST-FREQUENT',\n                            \"WHERE-NOT-MOST-FREQUENT\", \"WHERE-NOT-LEAST-FREQUENT\"],\n                \"queries\": [\n                    'SELECT * FROM \"table_name\" WHERE \"colors\" == \"blue\"',\n                    'SELECT * FROM \"table_name\" WHERE \"colors\" == \"green\"',\n                    'SELECT * FROM \"table_name\" WHERE \"colors\" != \"blue\"',\n                    'SELECT * FROM \"table_name\" WHERE \"colors\" != \"green\"',\n                    'SELECT * FROM \"table_name\" WHERE NOT \"colors\" == \"blue\"',\n                    'SELECT * FROM \"table_name\" WHERE NOT \"colors\" == \"green\"',\n                ],\n                \"questions\": [\n                    'Show the data of the table \"table_name\" where \"colors\" is equal to blue',\n                    'Show the data of the table \"table_name\" where \"colors\" is equal to green',\n                    'Show the data of the table \"table_name\" where \"colors\" is different from blue',\n                    'Show the data of the table \"table_name\" where \"colors\" is different from green',\n                    'Show the data of the table \"table_name\" where \"colors\" is not equal to blue',\n                    'Show the data of the table \"table_name\" where \"colors\" is not equal to green',\n                ]\n            }\n            &gt;&gt;&gt; generator._generate_where_numerical(\"table_name\", [\"numbers\"], sample_df)\n            &gt;&gt;&gt; generator.sql_generated\n            {\n                \"sql_tags\": ['WHERE-NUM-MAX-VALUES', 'WHERE-NUM-MIN-VALUES',\n                            'WHERE-NUM-MEAN-VALUES', 'WHERE-NUM-MEAN-VALUES'],\n                \"queries\": ['SELECT * FROM \"table_name\" WHERE \"numbers\" &lt; 5',\n                            'SELECT * FROM \"table_name\" WHERE \"numbers\" &gt; 1,\n                            'SELECT * FROM \"table_name\" WHERE \"numbers\" &gt; 3.0'\n                            'SELECT * FROM \"table_name\" WHERE \"numbers\" &lt; 3.0'],\n                \"question\": ['Show the data of the table \"table_name\" where \"numbers\" is less than 5',\n                            'Show the data of the table \"table_name\" where \"numbers\" is greater than 1',\n                            'Show the data of the table \"table_name\" where \"numbers\" is greater than 3.0',\n                            'Show the data of the table \"table_name\" where \"numbers\" is less than 3.0'],\n            }\n        \"\"\"\n        self.empty_sql_generated()\n        df, cat_cols, num_cols = self._sample_cat_num_cols(table_name)\n        self._generate_where_categorical(table_name, cat_cols, df)\n        self._generate_where_numerical(table_name, num_cols, df)\n        return self.sql_generated\n\n    def _generate_where_categorical(self, table_name: str, cat_cols: list, df: pd.DataFrame):\n        \"\"\"\n        Generates WHERE SQL queries and questions for categorical columns.\n        Generates test for both most frequent and least frequent values.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            cat_cols (list): List of categorical columns.\n            df (pd.DataFrame): The DataFrame containing the data.\n        \"\"\"\n        if len(cat_cols) == 0:\n            # no categorical attributes present\n            return\n        most_frequent_elements = [self._get_most_frequent_or_max_value(df[col].values) for col in cat_cols]\n        least_frequent_elements = [self._get_least_frequent_or_min_value(df[col].values) for col in cat_cols]\n        for col, most_freq, least_freq in zip(cat_cols, most_frequent_elements, least_frequent_elements):\n            queries = [\n                f\"\"\"SELECT * FROM `{table_name}` WHERE `{col}` == `{most_freq}` \"\"\",\n                f\"\"\"SELECT * FROM `{table_name}` WHERE `{col}` == `{least_freq}` \"\"\",\n                f\"\"\"SELECT * FROM `{table_name}` WHERE `{col}` != `{most_freq}` \"\"\",\n                f\"\"\"SELECT * FROM `{table_name}` WHERE `{col}` != `{least_freq}` \"\"\",\n                f\"\"\"SELECT * FROM `{table_name}` WHERE NOT `{col}` == `{most_freq}` \"\"\",\n                f\"\"\"SELECT * FROM `{table_name}` WHERE NOT `{col}` == `{least_freq}` \"\"\",\n            ]\n\n            questions = [\n                f'Show the data of the table \"{table_name}\" where \"{col}\" is equal to {most_freq}',\n                f'Show the data of the table \"{table_name}\" where \"{col}\" is equal to {least_freq}',\n                f'Show the data of the table \"{table_name}\" where \"{col}\" is different from {most_freq}',\n                f'Show the data of the table \"{table_name}\" where \"{col}\" is different from {least_freq}',\n                f'Show the data of the table \"{table_name}\" where \"{col}\" is not equal to {most_freq}',\n                f'Show the data of the table \"{table_name}\" where \"{col}\" is not equal to {least_freq}',\n            ]\n\n            sql_tags = ['WHERE-CAT-MOST-FREQUENT', 'WHERE-CAT-LEAST-FREQUENT',\n                        'WHERE-CAT-MOST-FREQUENT', 'WHERE-CAT-LEAST-FREQUENT',\n                        'WHERE-NOT-MOST-FREQUENT', 'WHERE-NOT-LEAST-FREQUENT']\n            self.append_sql_generated(sql_tags, queries, questions)\n\n    def _generate_where_numerical(self, table_name: str, num_cols: list, df: pd.DataFrame):\n        \"\"\"\n        Generates WHERE SQL queries and questions for numerical columns.\n        Generates test for max, min, and mean values.\n\n        Args:\n            table_name (str): The name of the table in the database.\n            num_cols (list): List of numerical columns.\n            df (pd.DataFrame): The DataFrame containing the data.\n        \"\"\"\n\n        def _generate_given_value(number, n_col):\n            queries_n = [\n                f'SELECT * FROM `{table_name}` WHERE `{n_col}` &gt; {number}',\n                f'SELECT * FROM `{table_name}` WHERE `{n_col}` &lt; {number}',\n            ]\n            questions_n = [\n                f'Show the data of the table \"{table_name}\" where \"{n_col}\" is greater than {number}',\n                f'Show the data of the table \"{table_name}\" where \"{n_col}\" is less than {number}',\n            ]\n            return queries_n, questions_n\n\n        if len(num_cols) == 0:\n            return\n        max_elements = [self._get_most_frequent_or_max_value(df[col].values)\n                        for col in num_cols]\n        min_elements = [self._get_least_frequent_or_min_value(df[col].values)\n                        for col in num_cols]\n        mean_values = [self._get_median_value(df[col].values) for col in num_cols]\n        for col, max_value, min_value, mean_value in zip(num_cols, max_elements,\n                                                         min_elements, mean_values):\n            queries, questions = _generate_given_value(max_value, col)\n            sql_tags = ['WHERE-NUM-MAX-VALUES-EMPTY', 'WHERE-NUM-MAX-VALUES']\n            # avoid empty results\n            self.append_sql_generated(sql_tags[1:], queries[1:], questions[1:])\n\n            queries, questions = _generate_given_value(min_value, col)\n            sql_tags = ['WHERE-NUM-MIN-VALUES', 'WHERE-NUM-MIN-VALUES-EMPTY']\n            # avoid empty results\n            self.append_sql_generated(sql_tags[:1], queries[:1], questions[:1])\n\n            queries, questions = _generate_given_value(mean_value, col)\n            sql_tags = ['WHERE-NUM-MEAN-VALUES'] * len(queries)\n            self.append_sql_generated(sql_tags, queries, questions)\n\n    @staticmethod\n    def _get_most_frequent_or_max_value(values: np.array):\n        \"\"\"\n        Returns the most frequent value if the input is categorical, or the maximum value if numerical.\n        Null values are not considered in the calculation.\n\n        Args:\n            values (np.array): Array of values, either categorical or numerical.\n\n        Returns:\n            Union[None, Any]: Most frequent value if categorical, max value if numerical, or None if input is empty.\n        \"\"\"\n        if len(values) == 0:\n            return None\n        values = values[~pd.isna(values)]\n        # update the dtype after removing the null values\n        values = np.array(values.tolist())\n        if np.issubdtype(values.dtype, np.number):\n            return np.max(values)\n        else:\n            unique_values, counts = np.unique(values, return_counts=True)\n            index_of_max_count = np.argmax(counts)\n            most_frequent_value: str = unique_values[index_of_max_count]\n            return most_frequent_value.replace('\"', '').replace(\"'\", '').strip()\n\n    @staticmethod\n    def _get_least_frequent_or_min_value(values):\n        \"\"\"\n        Returns the least frequent value if the input is categorical, or the minimum value if numerical.\n        Null values are not considered in the calculation.\n\n        Args:\n            values (np.array): Array of values, either categorical or numerical.\n\n        Returns:\n            Union[None, Any]: Least frequent value if categorical, min value if numerical, or None if input is empty.\n        \"\"\"\n        if len(values) == 0:\n            return None\n        values = values[~pd.isna(values)]\n        # update the dtype after removing the null values\n        values = np.array(values.tolist())\n        if np.issubdtype(values.dtype, np.number):\n            return np.min(values)\n        else:\n            unique_values, counts = np.unique(values, return_counts=True)\n            index_of_min_count = np.argmin(counts)\n            lest_frequent_value: str = unique_values[index_of_min_count]\n            return lest_frequent_value.replace('\"', '').replace(\"'\", '').strip()\n\n    @staticmethod\n    def _get_median_value(values):\n        \"\"\"\n        Returns the median value if the input is numerical. Null values are not considered in the calculation.\n\n        Args:\n            values (np.array): Array of numerical values.\n\n        Returns:\n            Union[None, float]: Mean value of the input array, or None if input is empty or non-numerical.\n        \"\"\"\n        if len(values) == 0:\n            return None\n        values = values[~pd.isna(values)]\n        if np.issubdtype(values.dtype, np.number):\n            return np.mean(values)\n        else:\n            return None\n</code></pre>"},{"location":"sql_generator/#qatch.sql_generator.WhereGenerator.sql_generate","title":"<code>sql_generate(table_name)</code>","text":"<p>Generates WHERE SQL queries and corresponding questions for both categorical and numerical columns.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table in the database.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, list]</code> <p>A dictionary containing generated SQL tags, queries, questions, and results.   Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}</p> <p>Examples:</p> <p>Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"</p> <pre><code>&gt;&gt;&gt; sample_df = pd.DataFrame({\"colors\": [\"green\", \"blue\", \"blue\", \"blue\", \"blue\"], \"numbers\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; generator = WhereGenerator(database)\n&gt;&gt;&gt; generator._generate_where_categorical(\"table_name\", [\"colors\"], sample_df)\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": [\"WHERE-CAT-MOST-FREQUENT\", \"WHERE-CAT-LEAST-FREQUENT\",\n                'WHERE-CAT-MOST-FREQUENT', 'WHERE-CAT-LEAST-FREQUENT',\n                \"WHERE-NOT-MOST-FREQUENT\", \"WHERE-NOT-LEAST-FREQUENT\"],\n    \"queries\": [\n        'SELECT * FROM \"table_name\" WHERE \"colors\" == \"blue\"',\n        'SELECT * FROM \"table_name\" WHERE \"colors\" == \"green\"',\n        'SELECT * FROM \"table_name\" WHERE \"colors\" != \"blue\"',\n        'SELECT * FROM \"table_name\" WHERE \"colors\" != \"green\"',\n        'SELECT * FROM \"table_name\" WHERE NOT \"colors\" == \"blue\"',\n        'SELECT * FROM \"table_name\" WHERE NOT \"colors\" == \"green\"',\n    ],\n    \"questions\": [\n        'Show the data of the table \"table_name\" where \"colors\" is equal to blue',\n        'Show the data of the table \"table_name\" where \"colors\" is equal to green',\n        'Show the data of the table \"table_name\" where \"colors\" is different from blue',\n        'Show the data of the table \"table_name\" where \"colors\" is different from green',\n        'Show the data of the table \"table_name\" where \"colors\" is not equal to blue',\n        'Show the data of the table \"table_name\" where \"colors\" is not equal to green',\n    ]\n}\n&gt;&gt;&gt; generator._generate_where_numerical(\"table_name\", [\"numbers\"], sample_df)\n&gt;&gt;&gt; generator.sql_generated\n{\n    \"sql_tags\": ['WHERE-NUM-MAX-VALUES', 'WHERE-NUM-MIN-VALUES',\n                'WHERE-NUM-MEAN-VALUES', 'WHERE-NUM-MEAN-VALUES'],\n    \"queries\": ['SELECT * FROM \"table_name\" WHERE \"numbers\" &lt; 5',\n                'SELECT * FROM \"table_name\" WHERE \"numbers\" &gt; 1,\n                'SELECT * FROM \"table_name\" WHERE \"numbers\" &gt; 3.0'\n                'SELECT * FROM \"table_name\" WHERE \"numbers\" &lt; 3.0'],\n    \"question\": ['Show the data of the table \"table_name\" where \"numbers\" is less than 5',\n                'Show the data of the table \"table_name\" where \"numbers\" is greater than 1',\n                'Show the data of the table \"table_name\" where \"numbers\" is greater than 3.0',\n                'Show the data of the table \"table_name\" where \"numbers\" is less than 3.0'],\n}\n</code></pre> Source code in <code>qatch/sql_generator/where_generator.py</code> <pre><code>def sql_generate(self, table_name: str) -&gt; dict[str, list]:\n    \"\"\"\n    Generates WHERE SQL queries and corresponding questions for both categorical and numerical columns.\n\n    Args:\n        table_name (str): The name of the table in the database.\n\n    Returns:\n        dict: A dictionary containing generated SQL tags, queries, questions, and results.\n              Format: {\"sql_tags\": list[str], \"queries\": list[str], \"questions\": list[str]}\n\n    Examples:\n        Given a MultipleDatabases object \"database\" with a table \"table_name\" with columns \"colors\" and \"numbers\"\n        &gt;&gt;&gt; sample_df = pd.DataFrame({\"colors\": [\"green\", \"blue\", \"blue\", \"blue\", \"blue\"], \"numbers\": [1, 2, 3, 4, 5]})\n        &gt;&gt;&gt; generator = WhereGenerator(database)\n        &gt;&gt;&gt; generator._generate_where_categorical(\"table_name\", [\"colors\"], sample_df)\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": [\"WHERE-CAT-MOST-FREQUENT\", \"WHERE-CAT-LEAST-FREQUENT\",\n                        'WHERE-CAT-MOST-FREQUENT', 'WHERE-CAT-LEAST-FREQUENT',\n                        \"WHERE-NOT-MOST-FREQUENT\", \"WHERE-NOT-LEAST-FREQUENT\"],\n            \"queries\": [\n                'SELECT * FROM \"table_name\" WHERE \"colors\" == \"blue\"',\n                'SELECT * FROM \"table_name\" WHERE \"colors\" == \"green\"',\n                'SELECT * FROM \"table_name\" WHERE \"colors\" != \"blue\"',\n                'SELECT * FROM \"table_name\" WHERE \"colors\" != \"green\"',\n                'SELECT * FROM \"table_name\" WHERE NOT \"colors\" == \"blue\"',\n                'SELECT * FROM \"table_name\" WHERE NOT \"colors\" == \"green\"',\n            ],\n            \"questions\": [\n                'Show the data of the table \"table_name\" where \"colors\" is equal to blue',\n                'Show the data of the table \"table_name\" where \"colors\" is equal to green',\n                'Show the data of the table \"table_name\" where \"colors\" is different from blue',\n                'Show the data of the table \"table_name\" where \"colors\" is different from green',\n                'Show the data of the table \"table_name\" where \"colors\" is not equal to blue',\n                'Show the data of the table \"table_name\" where \"colors\" is not equal to green',\n            ]\n        }\n        &gt;&gt;&gt; generator._generate_where_numerical(\"table_name\", [\"numbers\"], sample_df)\n        &gt;&gt;&gt; generator.sql_generated\n        {\n            \"sql_tags\": ['WHERE-NUM-MAX-VALUES', 'WHERE-NUM-MIN-VALUES',\n                        'WHERE-NUM-MEAN-VALUES', 'WHERE-NUM-MEAN-VALUES'],\n            \"queries\": ['SELECT * FROM \"table_name\" WHERE \"numbers\" &lt; 5',\n                        'SELECT * FROM \"table_name\" WHERE \"numbers\" &gt; 1,\n                        'SELECT * FROM \"table_name\" WHERE \"numbers\" &gt; 3.0'\n                        'SELECT * FROM \"table_name\" WHERE \"numbers\" &lt; 3.0'],\n            \"question\": ['Show the data of the table \"table_name\" where \"numbers\" is less than 5',\n                        'Show the data of the table \"table_name\" where \"numbers\" is greater than 1',\n                        'Show the data of the table \"table_name\" where \"numbers\" is greater than 3.0',\n                        'Show the data of the table \"table_name\" where \"numbers\" is less than 3.0'],\n        }\n    \"\"\"\n    self.empty_sql_generated()\n    df, cat_cols, num_cols = self._sample_cat_num_cols(table_name)\n    self._generate_where_categorical(table_name, cat_cols, df)\n    self._generate_where_numerical(table_name, num_cols, df)\n    return self.sql_generated\n</code></pre>"},{"location":"supported_models/","title":"Supported Models","text":""},{"location":"supported_models/#qatch.models.ChatGPT_QA","title":"<code>ChatGPT_QA</code>","text":"<p>             Bases: <code>AbstractChatGPT</code></p> <p>A Subclass of <code>AbstractChatGPT</code> which provides functionality to act as a question answering model for tabular data.</p> <p>Attributes:</p> Name Type Description <code>api_key</code> <code>str</code> <p>The API key for the OpenAI client.</p> <code>api_org</code> <code>str</code> <p>The organization ID for the OpenAI account. Defaults to None.</p> <code>model_name</code> <code>str</code> <p>The name of the model to use. Defaults to 'gpt-3.5-turbo-0613'.</p> <p>Methods:</p> Name Description <code>name</code> <p>Property attribute which returns the model name.</p> <code>prompt</code> <p>Property attribute which provides instructions for the model in a defined format.</p> <code>process_input</code> <p>Converts input data into a format which model can interpret.</p> <code>_normalize_output</code> <p>Normalize the output for question answering.</p> Note <ul> <li>The model used in this class is \"gpt-3.5-turbo-0613\" but you can specify any version you want.</li> <li>The prompt contains few-shot examples to improve the QA task results</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from qatch.models import ChatGPT_QA\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = pd.DataFrame([\n...     [\"John Doe\", \"123-456-7890\"],\n...     [\"Jane Doe\", \"098-765-4321\"]\n... ], columns=[\"Name\", \"Phone Number\"])\n&gt;&gt;&gt;\n&gt;&gt;&gt; chatgpt_qa_instance =  ChatGPT_QA(api_key=credentials['api_key_chatgpt'],\n&gt;&gt;&gt;                                  api_org=credentials['api_org_chatgpt'],\n&gt;&gt;&gt;                                  model_name=\"gpt-3.5-turbo-0613\")\n&gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n&gt;&gt;&gt; answer = chatgpt_qa_instance.predict(table=data, query=query, tbl_name='Contact Info')\n&gt;&gt;&gt; print(answer)\n[['123-456-7890']]\n</code></pre> Source code in <code>qatch/models/chatgpt/chatgpt_QA.py</code> <pre><code>class ChatGPT_QA(AbstractChatGPT):\n    \"\"\"\n       A Subclass of `AbstractChatGPT` which provides functionality to act as a question answering model\n       for tabular data.\n\n       Attributes:\n           api_key (str): The API key for the OpenAI client.\n           api_org (str, optional): The organization ID for the OpenAI account. Defaults to None.\n           model_name (str, optional): The name of the model to use. Defaults to 'gpt-3.5-turbo-0613'.\n\n       Methods:\n           name: Property attribute which returns the model name.\n           prompt: Property attribute which provides instructions for the model in a defined format.\n           process_input: Converts input data into a format which model can interpret.\n           _normalize_output: Normalize the output for question answering.\n\n       Note:\n           - The model used in this class is \"gpt-3.5-turbo-0613\" but you can specify any version you want.\n           - The prompt contains few-shot examples to improve the QA task results\n\n\n       Examples:\n           &gt;&gt;&gt; import pandas as pd\n           &gt;&gt;&gt; from qatch.models import ChatGPT_QA\n           &gt;&gt;&gt;\n           &gt;&gt;&gt; data = pd.DataFrame([\n           ...     [\"John Doe\", \"123-456-7890\"],\n           ...     [\"Jane Doe\", \"098-765-4321\"]\n           ... ], columns=[\"Name\", \"Phone Number\"])\n           &gt;&gt;&gt;\n           &gt;&gt;&gt; chatgpt_qa_instance =  ChatGPT_QA(api_key=credentials['api_key_chatgpt'],\n           &gt;&gt;&gt;                                  api_org=credentials['api_org_chatgpt'],\n           &gt;&gt;&gt;                                  model_name=\"gpt-3.5-turbo-0613\")\n           &gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n           &gt;&gt;&gt; answer = chatgpt_qa_instance.predict(table=data, query=query, tbl_name='Contact Info')\n           &gt;&gt;&gt; print(answer)\n           [['123-456-7890']]\n     \"\"\"\n\n    def __init__(self, api_key: str,\n                 api_org: str | None,\n                 model_name=\"gpt-3.5-turbo-0613\",\n                 *args, **kwargs):\n        super().__init__(api_key, api_org, model_name,\n                         *args, **kwargs)\n        self.encoding = tiktoken.encoding_for_model(model_name)\n\n    @property\n    def name(self):\n        return \"ChatGPT_QA\"\n\n    @property\n    def prompt(self):\n        return [\n            {\"role\": \"user\", \"content\":\n                \"\"\"I want you to act as a question answering model for tabular data.\n                   I will pass you a table with one question.\n                   I want you to only reply with the output of the question executed on the table.\n                   I want you to return the answer in format: list of list (row and columns).\n                   The answer must be complete of all the data from the table.\n                   If an aggregations is present, return only the aggregate values.\n                   Do not write explanations. Do not type commands.\n                   This is an Example:\n                   Table:\n                    [\n                        [['Simone', '[H] Name'], ['Papicchio', '[H] Surname']],\n                         [['Marco', '[H] Name'], ['Clemente', '[H] Surname']]\n                    ],\n                    Question: 'Show all information about each body builder']\n                    I want you to output:\n                    [['Simone', 'Papicchio'], ['Marco', 'Clemente']]\n                    \"\"\"},\n            {\"role\": \"user\", \"content\":\n                \"Table:[[['24172', '[H] Student ID'], ['30', '[H] Grade'], ['3431223445', '[H] Phone Numbers']], \"\n                \"[['281811', '[H] Student ID'], ['22', '[H] Grade'], ['3435227445', '[H] Phone Numbers']]] \"\n                \"Question: 'what are all the phone numbers?'\"},\n            {\"role\": \"assistant\",\n             \"content\": \"[['3431223445'], ['3435227445']]\"},\n            {\"role\": \"user\", \"content\":\n                \"Table:[[['24172', '[H] Student ID'], ['28', '[H] Grade'], ['3431223445', '[H] Phone Numbers']], \"\n                \"[['281811', '[H] Student ID'], ['24', '[H] Grade'], ['3435227445', '[H] Phone Numbers']]] \"\n                \"Question: 'what is the average of the grade?'\"},\n            {\"role\": \"assistant\",\n             \"content\": \"[[26]]\"}\n        ]\n\n    def process_input(self,\n                      table: pd.DataFrame | None,\n                      db_table_schema: list | list[list] | None,\n                      query: str,\n                      query_tbl_name: str | list[str]) -&gt; Any | None:\n        if table is None:\n            raise ValueError('To use ChatGPT for QA, you need to pass the pandas table')\n        linearized_table = linearize_table(table)\n        prompt = f\"Table: {linearized_table},\\nQuestion: '{query}'\"\n        num_tokens = self._num_tokens_from_string(prompt)\n        if num_tokens &gt; 4098:\n            self.logger.error('prompt cannot be passed num_tokens &gt; 4098')\n            return None\n        else:\n            return {\"role\": \"user\", \"content\": prompt}\n\n    def _num_tokens_from_string(self, string: str) -&gt; int:\n        \"\"\"Returns the number of tokens in a text string.\"\"\"\n        num_tokens = len(self.encoding.encode(string))\n        return num_tokens\n\n    def _normalize_api_output(self, api_output):\n        prediction: str = api_output.choices[0].message.content\n        prediction: list = _normalize_output_for_QA(prediction)\n        return prediction\n</code></pre>"},{"location":"supported_models/#qatch.models.ChatGPT_SP","title":"<code>ChatGPT_SP</code>","text":"<p>             Bases: <code>AbstractChatGPT</code></p> <p>A Subclass of <code>AbstractChatGPT</code> which provides functionality to act as a semantic parsing model for tabular data.</p> <p>Attributes:</p> Name Type Description <code>api_key</code> <code>str</code> <p>The API key for the OpenAI client.</p> <code>api_org</code> <code>str</code> <p>The organization ID for the OpenAI account. Defaults to None.</p> <code>model_name</code> <code>str</code> <p>The name of the model to use. Defaults to 'gpt-3.5-turbo-0613'.</p> <p>Methods:</p> Name Description <code>name</code> <p>Property attribute which returns the model name.</p> <code>prompt</code> <p>Property attribute which provides instructions for the model in a defined format: Table name: \"body-builder\", Schema: \"[Name, Surname]\", Questions: \"Show all information about each body builder\"</p> <code>process_input</code> <p>Converts input data into a format which model can interpret.</p> <code>_normalize_output</code> <p>Normalize the output for question answering.</p> Note <ul> <li>The model used in this class is \"gpt-3.5-turbo-0613\" but you can specify any version you want.</li> <li>The prompt contains few-shot examples to improve the QA task results</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from qatch.models import ChatGPT_SP\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = pd.DataFrame([\n...     [\"John Doe\", \"123-456-7890\"],\n...     [\"Jane Doe\", \"098-765-4321\"]\n... ], columns=[\"Name\", \"Phone Number\"])\n&gt;&gt;&gt;\n&gt;&gt;&gt; chatgpt_sp_instance = ChatGPT_SP(api_key=credentials['api_key_chatgpt'],\n   &gt;&gt;&gt;                                  api_org=credentials['api_org_chatgpt'],\n   &gt;&gt;&gt;                                  model_name=\"gpt-3.5-turbo-0613\")\n&gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n&gt;&gt;&gt; answer = chatgpt_sp_instance.predict(table=data, query=query, tbl_name='Contact Info')\n&gt;&gt;&gt; print(answer)\nSELECT \"Phone Number\" FROM \"Contact Info\" WHERE \"Name\" = \"John Doe\"\n</code></pre> Source code in <code>qatch/models/chatgpt/chatgpt_SP.py</code> <pre><code>class ChatGPT_SP(AbstractChatGPT):\n    \"\"\"\n    A Subclass of `AbstractChatGPT` which provides functionality to act as a semantic parsing model for tabular data.\n\n    Attributes:\n        api_key (str): The API key for the OpenAI client.\n        api_org (str, optional): The organization ID for the OpenAI account. Defaults to None.\n        model_name (str, optional): The name of the model to use. Defaults to 'gpt-3.5-turbo-0613'.\n\n    Methods:\n        name: Property attribute which returns the model name.\n        prompt: Property attribute which provides instructions for the model in a defined format: Table name: \"body-builder\",\n            Schema: \"[Name, Surname]\", Questions: \"Show all information about each body builder\"\n        process_input: Converts input data into a format which model can interpret.\n        _normalize_output: Normalize the output for question answering.\n\n    Note:\n       - The model used in this class is \"gpt-3.5-turbo-0613\" but you can specify any version you want.\n       - The prompt contains few-shot examples to improve the QA task results\n\n\n    Examples:\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; from qatch.models import ChatGPT_SP\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; data = pd.DataFrame([\n        ...     [\"John Doe\", \"123-456-7890\"],\n        ...     [\"Jane Doe\", \"098-765-4321\"]\n        ... ], columns=[\"Name\", \"Phone Number\"])\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; chatgpt_sp_instance = ChatGPT_SP(api_key=credentials['api_key_chatgpt'],\n           &gt;&gt;&gt;                                  api_org=credentials['api_org_chatgpt'],\n           &gt;&gt;&gt;                                  model_name=\"gpt-3.5-turbo-0613\")\n        &gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n        &gt;&gt;&gt; answer = chatgpt_sp_instance.predict(table=data, query=query, tbl_name='Contact Info')\n        &gt;&gt;&gt; print(answer)\n        SELECT \"Phone Number\" FROM \"Contact Info\" WHERE \"Name\" = \"John Doe\"\n    \"\"\"\n\n    def __init__(self, api_key: str,\n                 api_org: str | None,\n                 model_name=\"gpt-3.5-turbo-0613\",\n                 *args, **kwargs):\n        super().__init__(api_key, api_org, model_name,\n                         *args, **kwargs)\n\n    @property\n    def name(self):\n        return 'ChatGPT_SP'\n\n    @property\n    def prompt(self):\n        return [\n            {\"role\": \"user\", \"content\":\n                \"\"\"I want you to act as a text to SQL model for tabular data.\n                   I will pass you the schema of the table and one question.\n                   I want you to parse the question into the SQL command.\n                   The SQL command must be executable with the schema of the table.\n                   Do not write explanations. Do not type commands. \n                   REPLY ONLY WITH THE SQL COMMAND.\n                   This is an Example:\n                   Table name: \"body-builder\", \n                    Schema: [Name, Surname], \n                    Questions: \"Show all information about each body builder\"\n                    I want you to output:\n                    \"SELECT * FROM \"body-builder\"\"\n                    \"\"\"},\n            {\"role\": \"user\", \"content\":\n                'Table name: \"student\",'\n                \"Schema: [StudentID, Grade, PhoneNumbers]\"\n                'Question: \"what are all the phone numbers?\"'},\n\n            {\"role\": \"assistant\",\n             \"content\": 'SELECT \"PhoneNumbers\" FROM student'},\n            {\"role\": \"user\", \"content\":\n                'Table name: \"student\"'\n                \"Schema: [StudentID, Grade, PhoneNumbers]\"\n                'Question: \"what is the average grade?\"'},\n            {\"role\": \"assistant\",\n             \"content\": \"SELECT AVG(Grade) FROM student\"},\n        ]\n\n    def process_input(self,\n                      table: pd.DataFrame | None,\n                      db_table_schema: list | list[list] | None,\n                      query: str,\n                      query_tbl_name: str | list[str]) -&gt; Any | None:\n        if not query_tbl_name:\n            raise ValueError('For Semantic Parsing, it is need the table name '\n                             'for the chatgpt input prompt')\n\n        schema = table.columns.tolist()\n        prompt = f'Table Name: \"{query_tbl_name}\",\\nSchema: {schema},\\nQuestion: \"{query}\"'\n        return {\"role\": \"user\", \"content\": prompt}\n\n    def _normalize_api_output(self, api_output):\n        prediction: str = api_output.choices[0].message.content\n        return prediction\n</code></pre>"},{"location":"supported_models/#qatch.models.ChatGPT_SP_join","title":"<code>ChatGPT_SP_join</code>","text":"<p>             Bases: <code>AbstractChatGPT</code></p> <p>Implementation of the Llama2 model specialized for semantic parsing (SP) with JOIN statements. Inherits from the Abstract Llama2 model class.</p> <p>This model processes the provided schemas and queries, and after transformation, predicts the appropriate SQL statements.</p> <p>Attributes:</p> Name Type Description <code>api_key</code> <code>str</code> <p>The API key for the OpenAI client.</p> <code>api_org</code> <code>str</code> <p>The organization ID for the OpenAI account. Defaults to None.</p> <code>model_name</code> <code>str</code> <p>The name of the model to use. Defaults to 'gpt-3.5-turbo-0613'.</p> <p>Methods:</p> Name Description <code>name</code> <p>Property attribute which returns the model name.</p> <code>prompt</code> <p>Property attribute which provides instructions for the model in a defined format:     Database table names: [\"customer\", \"product\"], Schema table \"customer\": [CustomerID, name, surname]     Schema table \"product\": [ProductID, CustomerID, name, surname, price]     Question: \"which products did Simone buy?\"</p> <code>process_input</code> <p>Processes given inputs into a form that model can consume.            Extracts and structures relevant data for the SP task.</p> <code>_normalize_output</code> <p>Normalizes the text received from model predictions.                Strips away unnecessary characters from the result SQL statement.</p> For this model, the <code>table</code> parameter in predict and process_input methods <p>is not used and can be set to None.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; chatgpt_sp_join = ChatGPT_SP_join(api_key=credentials['api_key_chatgpt'],\n   &gt;&gt;&gt;                                  api_org=credentials['api_org_chatgpt'],\n   &gt;&gt;&gt;                                  model_name=\"gpt-3.5-turbo-0613\")\n&gt;&gt;&gt; # you need to specify all the database table schema\n&gt;&gt;&gt; # if you are using QATCH, you can use database.get_all_table_schema_given(db_id='name_of_the_database')\n&gt;&gt;&gt; db_table_schema = {\n...                    \"student\": {\"name\": [\"StudentID\", \"Grade\", \"PhoneNumbers\"]},\n...                    \"customer\": {\"name\": [\"CustomerID\", \"name\", \"surname\"]},\n...                    \"product\": {\"name\": [\"ProductID\", \"CustomerID\", \"name\", \"surname\", \"price\"]}\n...                   }\n&gt;&gt;&gt; query = \"which products did Simone buy?\"\n&gt;&gt;&gt; chatgpt_sp_join.predict(table=None,\n&gt;&gt;&gt;                       query=query,\n&gt;&gt;&gt;                       tbl_name=[\"customer\", \"product\"],\n&gt;&gt;&gt;                       db_table_schema=db_table_schema)\nSELECT T1.name, T2.name FROM \"customer\" as T1 JOIN \"product\" as T2 WHERE T1.name == \"Simone\"\n</code></pre> Source code in <code>qatch/models/chatgpt/chatgpt_SP_join.py</code> <pre><code>class ChatGPT_SP_join(AbstractChatGPT):\n    \"\"\"\n    Implementation of the Llama2 model specialized for semantic parsing (SP)\n    with JOIN statements. Inherits from the Abstract Llama2 model class.\n\n    This model processes the provided schemas and queries, and after transformation,\n    predicts the appropriate SQL statements.\n\n    Attributes:\n        api_key (str): The API key for the OpenAI client.\n        api_org (str, optional): The organization ID for the OpenAI account. Defaults to None.\n        model_name (str, optional): The name of the model to use. Defaults to 'gpt-3.5-turbo-0613'.\n\n    Methods:\n        name: Property attribute which returns the model name.\n        prompt: Property attribute which provides instructions for the model in a defined format:\n                Database table names: [\"customer\", \"product\"], Schema table \"customer\": [CustomerID, name, surname]\n                Schema table \"product\": [ProductID, CustomerID, name, surname, price]\n                Question: \"which products did Simone buy?\"\n        process_input: Processes given inputs into a form that model can consume.\n                       Extracts and structures relevant data for the SP task.\n        _normalize_output: Normalizes the text received from model predictions.\n                           Strips away unnecessary characters from the result SQL statement.\n\n    Note: For this model, the `table` parameter in predict and process_input methods\n            is not used and can be set to None.\n\n    Examples:\n        &gt;&gt;&gt; chatgpt_sp_join = ChatGPT_SP_join(api_key=credentials['api_key_chatgpt'],\n           &gt;&gt;&gt;                                  api_org=credentials['api_org_chatgpt'],\n           &gt;&gt;&gt;                                  model_name=\"gpt-3.5-turbo-0613\")\n        &gt;&gt;&gt; # you need to specify all the database table schema\n        &gt;&gt;&gt; # if you are using QATCH, you can use database.get_all_table_schema_given(db_id='name_of_the_database')\n        &gt;&gt;&gt; db_table_schema = {\n        ...                    \"student\": {\"name\": [\"StudentID\", \"Grade\", \"PhoneNumbers\"]},\n        ...                    \"customer\": {\"name\": [\"CustomerID\", \"name\", \"surname\"]},\n        ...                    \"product\": {\"name\": [\"ProductID\", \"CustomerID\", \"name\", \"surname\", \"price\"]}\n        ...                   }\n        &gt;&gt;&gt; query = \"which products did Simone buy?\"\n        &gt;&gt;&gt; chatgpt_sp_join.predict(table=None,\n        &gt;&gt;&gt;                       query=query,\n        &gt;&gt;&gt;                       tbl_name=[\"customer\", \"product\"],\n        &gt;&gt;&gt;                       db_table_schema=db_table_schema)\n        SELECT T1.name, T2.name FROM \"customer\" as T1 JOIN \"product\" as T2 WHERE T1.name == \"Simone\"\n\n    \"\"\"\n\n    def __init__(self, api_key: str,\n                 api_org: str | None,\n                 model_name=\"gpt-3.5-turbo-0613\",\n                 *args, **kwargs):\n        super().__init__(api_key, api_org, model_name,\n                         *args, **kwargs)\n\n    @property\n    def name(self):\n        return 'ChatGPT_SP_join'\n\n    @property\n    def prompt(self):\n        return [\n            {\"role\": \"user\", \"content\":\n                \"\"\"I want you to act as a text to SQL model for tabular data.\n                   I will pass you as prompt: \n                   - all the table names and the respective tables schema present in the database \n                   - one question. \n                   I want you to parse the question into the SQL command.\n                   The SQL command must be executable over the database.\n                   Do not write explanations. Do not type commands. \n                   REPLY ONLY WITH THE SQL COMMAND.\n                   This is an Example:\n                    Database table names: [\"body-builder\"], \n                    Table schema \"body-builder\": [Name, Surname], \n                    Question: \"Show all information about each body builder\"\n                    I want you to output:\n                    \"SELECT * FROM \"body-builder\"\"\n                    \"\"\"},\n\n            {\"role\": \"user\", \"content\":\n                'Database table names: [\"student\"],'\n                'Schema table \"body-builder\": [StudentID, Grade, PhoneNumbers]'\n                'Question: \"what are all the phone numbers?\"'},\n            {\"role\": \"assistant\",\n             \"content\": 'SELECT \"PhoneNumbers\" FROM student'},\n\n            {\"role\": \"user\", \"content\":\n                'Database table names: [\"student\"],'\n                'Schema table \"student\": [StudentID, Grade, PhoneNumbers]'\n                'Question: \"what is the average grade?\"'},\n            {\"role\": \"assistant\",\n             \"content\": \"SELECT AVG(Grade) FROM student\"},\n\n            {\"role\": \"user\", \"content\":\n                'Database table names: [\"customer\", \"product\"]'\n                'Schema table \"customer\": [CustomerID, name, surname]'\n                'Schema table \"product\": [ProductID, CustomerID, name, surname, price]'\n                'Question: \"which products did Simone buy?\"'},\n            {\"role\": \"assistant\",\n             \"content\": 'SELECT T1.name, T2.name FROM \"customer\" as T1 JOIN \"product\" as T2 WHERE T1.name == \"Simone\"'},\n        ]\n\n    def process_input(self, table: pd.DataFrame | None,\n                      db_table_schema: dict[str, pd.DataFrame], query: str,\n                      query_tbl_name: str | list[str]) -&gt; Any | None:\n        if not db_table_schema:\n            raise ValueError('For Semantic Parsing JOIN, it is needed the schema of the database')\n\n        prompts = [f'Database table names: {list(db_table_schema.keys())}']\n        for name, schema in db_table_schema.items():\n            prompts.append(f'Schema table \"{name}\": {schema[\"name\"].tolist()}')\n        prompts.append(f'Question: \"{query}\"')\n\n        return {\"role\": \"user\", \"content\": \"\\n\".join(prompts)}\n\n    def _normalize_api_output(self, api_output):\n        prediction: str = api_output.choices[0].message.content\n        return prediction\n</code></pre>"},{"location":"supported_models/#qatch.models.LLama2_QA","title":"<code>LLama2_QA</code>","text":"<p>             Bases: <code>AbstractLLama2</code></p> <p>A Subclass of <code>AbstractLLama2</code> which provides functionality to act as a question answering model for tabular data.</p> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>Name of the Llama model.</p> <code>hugging_face_token</code> <code>(str, None)</code> <p>Token for the Hugging Face.</p> <code>force_cpu</code> <code>bool</code> <p>To force usage of cpu. Defaults to False.</p> <p>Methods:</p> Name Description <code>name</code> <p>Property attribute which returns the model name.</p> <code>prompt</code> <p>Property attribute which provides instructions for the model in a defined format.</p> <code>process_input</code> <p>Converts input data into a format which model can interpret.</p> <code>_normalize_output</code> <p>Normalize the output for question answering.</p> Note <ul> <li>The model used in this class is \"meta-llama/Llama-2-7b-chat-hf\".</li> <li>The prompt contains few-shot examples to improve the QA task results</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from qatch.models import LLama2_QA\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = pd.DataFrame([\n...     [\"John Doe\", \"123-456-7890\"],\n...     [\"Jane Doe\", \"098-765-4321\"]\n... ], columns=[\"Name\", \"Phone Number\"])\n&gt;&gt;&gt;\n&gt;&gt;&gt; llama2_qa_instance = LLama2_QA(\"meta-llama/Llama-2-7b-chat-hf\")\n&gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n&gt;&gt;&gt; answer = llama2_qa_instance.predict(table=data, query=query, tbl_name='Contact Info')\n&gt;&gt;&gt; print(answer)\n[['123-456-7890']]\n</code></pre> Source code in <code>qatch/models/llama2/llama2_QA.py</code> <pre><code>class LLama2_QA(AbstractLLama2):\n    \"\"\"\n    A Subclass of `AbstractLLama2` which provides functionality to act as a question answering model\n    for tabular data.\n\n    Attributes:\n        model_name (str): Name of the Llama model.\n        hugging_face_token (str, None): Token for the Hugging Face.\n        force_cpu (bool, optional): To force usage of cpu. Defaults to False.\n\n    Methods:\n        name: Property attribute which returns the model name.\n        prompt: Property attribute which provides instructions for the model in a defined format.\n        process_input: Converts input data into a format which model can interpret.\n        _normalize_output: Normalize the output for question answering.\n\n    Note:\n        - The model used in this class is \"meta-llama/Llama-2-7b-chat-hf\".\n        - The prompt contains few-shot examples to improve the QA task results\n\n\n    Examples:\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; from qatch.models import LLama2_QA\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; data = pd.DataFrame([\n        ...     [\"John Doe\", \"123-456-7890\"],\n        ...     [\"Jane Doe\", \"098-765-4321\"]\n        ... ], columns=[\"Name\", \"Phone Number\"])\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; llama2_qa_instance = LLama2_QA(\"meta-llama/Llama-2-7b-chat-hf\")\n        &gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n        &gt;&gt;&gt; answer = llama2_qa_instance.predict(table=data, query=query, tbl_name='Contact Info')\n        &gt;&gt;&gt; print(answer)\n        [['123-456-7890']]\n  \"\"\"\n\n    @property\n    def name(self):\n        return 'LLama2_QA'\n\n    @property\n    def prompt(self):\n        return \"\"\"\\\n        [INST] I want you to act as a question answering model for tabular data.\n        I will pass you a table with one question. \n        I want you to return the elements in the table that answer the question.\n        I want you to return the answer in format: list of list (row and columns).\n        The answer must be complete of all the data from the table.\n        If an aggregations is present, return only the aggregate values.\n        The answer must be generated only from the table provided.\n        The answer must have the same format of the Table passed as input.\n        The answer must be a list of tuples. Then for each tuple, a list of elements. For each element a list of cell values and the header. \n        Do not use different formats in the answer. \n        Do not repeat the instruction in the answer.\n        [/INST]\n        [INST] Table Name: \"Body_Builders\"\n        Table: \"[[['Simone', '[H] Name'], ['Papicchio', '[H] Surname']], [['Marco', '[H] Name'], ['Clemente', '[H] Surname']]]\"\n        Question: \"Show all information about each body builder\"\n        [/INST]\n        [[Simone', 'Papicchio'], ['Marco', 'Clemente']]\n        [INST]\n        Table Name: \"Students\"\n        Table: \"[[['24172', '[H] Student ID'], ['30', '[H] Grade'], ['3431223445', '[H] Phone Numbers']], [['281811', '[H] Student ID'], ['22', '[H] Grade'], ['3435227445', '[H] Phone Numbers']]]\"\n        Question: \"what are all the phone numbers?\"\n        [/INST]\n        [['3431223445'], ['3435227445']]\n        [INST] Table Name: \"Students\"\n        Table: \"[[['24172', '[H] Student ID'], ['28', '[H] Grade'], ['3431223445', '[H] Phone Numbers']], [['281811', '[H] Student ID'], ['24', '[H] Grade'], ['3435227445', '[H] Phone Numbers']]]\"\n        Question: \"what is the average of the grade?\"\n        [/INST]\n        [[26]]\n        \"\"\"\n\n    @override\n    def process_input(self,\n                      table: pd.DataFrame | None,\n                      db_table_schema: dict | None,\n                      query: str,\n                      query_tbl_name: str | list[str]) -&gt; Any | None:\n        if table.size &gt; 512:\n            return None\n        linearized_table = linearize_table(table)\n        model_input = \\\n            f\"\"\"[INST] Table Name: \"{query_tbl_name}\"\n            Table: \"{linearized_table}\"\n            Question: \"{query}\"\n            [/INST]\"\"\"\n        return model_input\n\n    @override\n    def _normalize_output(self, text):\n        return _normalize_output_for_QA(text)\n</code></pre>"},{"location":"supported_models/#qatch.models.LLama2_SP","title":"<code>LLama2_SP</code>","text":"<p>             Bases: <code>AbstractLLama2</code></p> <p>A Subclass of <code>AbstractLLama2</code> which provides functionality to act as a semantic parsing model for tabular data.</p> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>Name of the Llama model.</p> <code>hugging_face_token</code> <code>(str, None)</code> <p>Token for the Hugging Face.</p> <code>force_cpu</code> <code>bool</code> <p>To force usage of cpu. Defaults to False.</p> <p>Methods:</p> Name Description <code>name</code> <p>Property attribute which returns the model name.</p> <code>prompt</code> <p>Property attribute which provides instructions for the model in a defined format:  Table name: \"body-builder\", Schema: \"[Name, Surname]\", Questions: \"Show all information about each body builder\"</p> <code>process_input</code> <p>Converts input data into a format which model can interpret.</p> <code>_normalize_output</code> <p>Normalize the output for question answering.</p> Note <ul> <li>The model used in this class is \"codellama/CodeLlama-7b-Instruct-hf\".</li> <li>The prompt contains few-shot examples to improve the SP task results</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from qatch.models import LLama2_QA\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = pd.DataFrame([\n...     [\"John Doe\", \"123-456-7890\"],\n...     [\"Jane Doe\", \"098-765-4321\"]\n... ], columns=[\"Name\", \"Phone Number\"])\n&gt;&gt;&gt;\n&gt;&gt;&gt; llama2_sp_instance = LLama2_SP(\"codellama/CodeLlama-7b-Instruct-hf\")\n&gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n&gt;&gt;&gt; answer = llama2_sp_instance.predict(table=data, query=query, tbl_name='Contact Info')\n&gt;&gt;&gt; print(answer)\nSELECT \"Phone Number\" FROM \"Contact Info\" WHERE \"Name\" = \"John Doe\"\n</code></pre> Source code in <code>qatch/models/llama2/llama2_SP.py</code> <pre><code>class LLama2_SP(AbstractLLama2):\n    \"\"\"\n    A Subclass of `AbstractLLama2` which provides functionality to act as a semantic parsing model for tabular data.\n\n    Attributes:\n        model_name (str): Name of the Llama model.\n        hugging_face_token (str, None): Token for the Hugging Face.\n        force_cpu (bool, optional): To force usage of cpu. Defaults to False.\n\n    Methods:\n        name: Property attribute which returns the model name.\n        prompt: Property attribute which provides instructions for the model in a defined format:  Table name: \"body-builder\",\n            Schema: \"[Name, Surname]\", Questions: \"Show all information about each body builder\"\n        process_input: Converts input data into a format which model can interpret.\n        _normalize_output: Normalize the output for question answering.\n\n    Note:\n        - The model used in this class is \"codellama/CodeLlama-7b-Instruct-hf\".\n        - The prompt contains few-shot examples to improve the SP task results\n\n\n    Examples:\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; from qatch.models import LLama2_QA\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; data = pd.DataFrame([\n        ...     [\"John Doe\", \"123-456-7890\"],\n        ...     [\"Jane Doe\", \"098-765-4321\"]\n        ... ], columns=[\"Name\", \"Phone Number\"])\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; llama2_sp_instance = LLama2_SP(\"codellama/CodeLlama-7b-Instruct-hf\")\n        &gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n        &gt;&gt;&gt; answer = llama2_sp_instance.predict(table=data, query=query, tbl_name='Contact Info')\n        &gt;&gt;&gt; print(answer)\n        SELECT \"Phone Number\" FROM \"Contact Info\" WHERE \"Name\" = \"John Doe\"\n    \"\"\"\n\n    @property\n    def name(self):\n        return 'LLama2_SP_code'\n\n    @property\n    def prompt(self):\n        return \\\n            \"\"\"[INST] I want you to act as a text to SQL model for tabular data.\n            I will pass you the schema of the table and one question.\n            I want you to parse the question into the SQL query.\n            The SQL command must be executable with the schema of the table.\n            Do not write explanations. Do not type commands. \n            [/INST] \n            ok pass me the input\n            [INST]\n            Table name: \"body-builder\", \n            Schema: \"[Name, Surname]\", \n            Questions: \"Show all information about each body builder\"\n            [/INST]\n            SELECT * FROM \"body-builder\"\n            [INST] Table Name: \"Body_Builders\"\n            Schema: \"[Name, Surname]\"\n            Question: \"Show all information about each body builder\"\n            [/INST]\n            SELECT * FROM \"Body_Builders\"\n            [INST] Table name: \"student\"\n            Schema: \"[StudentID, Grade, PhoneNumbers]\"\n            Question: \"what are all the phone numbers?\"\n            [/INST]\n            SELECT \"PhoneNumbers\" FROM \"student\"\n            [INST] Table name: \"student\"\n            Schema: \"[StudentID, Grade, PhoneNumbers]\"\n            Question: \"what are all the phone numbers?\"\n            [/INST]\n            SELECT AVG(\"Grade\") FROM \"student\"\n            \"\"\"\n\n    def process_input(self,\n                      table: pd.DataFrame | None,\n                      db_table_schema: dict | None,\n                      query: str,\n                      query_tbl_name: str | list[str]) -&gt; Any | None:\n        schema = table.columns.tolist()\n        model_input = f\"\"\"\n        [INST] Table name: \"{query_tbl_name}\"\n        Schema: \"{schema}\"\n        Question: \"{query}\"\n        [/INST] \"\"\"\n        return model_input\n\n    def _normalize_output(self, text):\n        return text.replace('\\n', '').strip()\n</code></pre>"},{"location":"supported_models/#qatch.models.LLama2_SP_join","title":"<code>LLama2_SP_join</code>","text":"<p>             Bases: <code>AbstractLLama2</code></p> <p>Implementation of the Llama2 model specialized for semantic parsing (SP) with JOIN statements. Inherits from the Abstract Llama2 model class.</p> <p>This model processes the provided schemas and queries, and after transformation, predicts the appropriate SQL statements.</p> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>Name of the Llama model.</p> <code>hugging_face_token</code> <code>(str, None)</code> <p>Token for the Hugging Face.</p> <code>force_cpu</code> <code>bool</code> <p>To force usage of cpu. Defaults to False.</p> <p>Methods:</p> Name Description <code>name</code> <p>Property attribute which returns the model name.</p> <code>prompt</code> <p>Property attribute which provides instructions for the model in a defined format:     Database table names: [\"customer\", \"product\"], Schema table \"customer\": [CustomerID, name, surname]     Schema table \"product\": [ProductID, CustomerID, name, surname, price]     Question: \"which products did Simone buy?\"</p> <code>process_input</code> <p>Processes given inputs into a form that model can consume.            Extracts and structures relevant data for the SP task.</p> <code>_normalize_output</code> <p>Normalizes the text received from model predictions.                Strips away unnecessary characters from the result SQL statement.</p> For this model, the <code>table</code> parameter in predict and process_input methods <p>is not used and can be set to None.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; llama_sp_join = LLama2_SP_join(model_name=\"codellama/CodeLlama-7b-Instruct-hf\",\n&gt;&gt;&gt;                                hugging_face_token=credentials['hugging_face_token'])\n&gt;&gt;&gt; # you need to specify all the database table schema\n&gt;&gt;&gt; # if you are using QATCH, you can use database.get_all_table_schema_given(db_id='name_of_the_database')\n&gt;&gt;&gt; db_table_schema = {\n...                    \"student\": {\"name\": [\"StudentID\", \"Grade\", \"PhoneNumbers\"]},\n...                    \"customer\": {\"name\": [\"CustomerID\", \"name\", \"surname\"]},\n...                    \"product\": {\"name\": [\"ProductID\", \"CustomerID\", \"name\", \"surname\", \"price\"]}\n...                   }\n&gt;&gt;&gt; query = \"which products did Simone buy?\"\n&gt;&gt;&gt; llama_sp_join.predict(table=None,\n&gt;&gt;&gt;                       query=query,\n&gt;&gt;&gt;                       tbl_name=[\"customer\", \"product\"],\n&gt;&gt;&gt;                       db_table_schema=db_table_schema)\nSELECT T1.name, T2.name FROM \"customer\" as T1 JOIN \"product\" as T2 WHERE T1.name == \"Simone\"\n</code></pre> Source code in <code>qatch/models/llama2/llama2_SP_join.py</code> <pre><code>class LLama2_SP_join(AbstractLLama2):\n    \"\"\"\n    Implementation of the Llama2 model specialized for semantic parsing (SP)\n    with JOIN statements. Inherits from the Abstract Llama2 model class.\n\n    This model processes the provided schemas and queries, and after transformation,\n    predicts the appropriate SQL statements.\n\n    Attributes:\n        model_name (str): Name of the Llama model.\n        hugging_face_token (str, None): Token for the Hugging Face.\n        force_cpu (bool, optional): To force usage of cpu. Defaults to False.\n\n    Methods:\n        name: Property attribute which returns the model name.\n        prompt: Property attribute which provides instructions for the model in a defined format:\n                Database table names: [\"customer\", \"product\"], Schema table \"customer\": [CustomerID, name, surname]\n                Schema table \"product\": [ProductID, CustomerID, name, surname, price]\n                Question: \"which products did Simone buy?\"\n        process_input: Processes given inputs into a form that model can consume.\n                       Extracts and structures relevant data for the SP task.\n        _normalize_output: Normalizes the text received from model predictions.\n                           Strips away unnecessary characters from the result SQL statement.\n\n    Note: For this model, the `table` parameter in predict and process_input methods\n            is not used and can be set to None.\n\n    Examples:\n        &gt;&gt;&gt; llama_sp_join = LLama2_SP_join(model_name=\"codellama/CodeLlama-7b-Instruct-hf\",\n        &gt;&gt;&gt;                                hugging_face_token=credentials['hugging_face_token'])\n        &gt;&gt;&gt; # you need to specify all the database table schema\n        &gt;&gt;&gt; # if you are using QATCH, you can use database.get_all_table_schema_given(db_id='name_of_the_database')\n        &gt;&gt;&gt; db_table_schema = {\n        ...                    \"student\": {\"name\": [\"StudentID\", \"Grade\", \"PhoneNumbers\"]},\n        ...                    \"customer\": {\"name\": [\"CustomerID\", \"name\", \"surname\"]},\n        ...                    \"product\": {\"name\": [\"ProductID\", \"CustomerID\", \"name\", \"surname\", \"price\"]}\n        ...                   }\n        &gt;&gt;&gt; query = \"which products did Simone buy?\"\n        &gt;&gt;&gt; llama_sp_join.predict(table=None,\n        &gt;&gt;&gt;                       query=query,\n        &gt;&gt;&gt;                       tbl_name=[\"customer\", \"product\"],\n        &gt;&gt;&gt;                       db_table_schema=db_table_schema)\n        SELECT T1.name, T2.name FROM \"customer\" as T1 JOIN \"product\" as T2 WHERE T1.name == \"Simone\"\n    \"\"\"\n\n    @property\n    def name(self):\n        return 'LLama2_SP_join_code'\n\n    @property\n    def prompt(self):\n        return \\\n            \"\"\"[INST]I want you to act as a text to SQL model for tabular data.\n            I will pass you as prompt: \n            - all the table names and the respective tables schema present in the database \n            - one question. \n            I want you to parse the question into the SQL command.\n            The SQL command must be executable over the database.\n            Do not write explanations. Do not type commands. \n            REPLY ONLY WITH THE SQL COMMAND.\n            This is an Example:\n            Database table names: [\"body-builder\"] \n            Table schema \"body-builder\": [Name, Surname] \n            Question: \"Show all information about each body builder\"\n            I want you to output:\n            \"SELECT * FROM \"body-builder\"\" \n            [/INST] \n            [INST] Database table names: [\"student\"]\n            Schema table \"body-builder\": [StudentID, Grade, PhoneNumbers]\n            Question: \"what are all the phone numbers?\"\n            [/INST]\n            'SELECT \"PhoneNumbers\" FROM student'\"\n            [INST] Database table names: [\"student\"]\n            Schema table \"student\": [StudentID, Grade, PhoneNumbers]\n            Question: \"what is the average grade?\"\n            [/INST]\n            \"SELECT AVG(Grade) FROM student\"\n            [INST] Database table names: [\"customer\", \"product\"]\n            Schema table \"customer\": [CustomerID, name, surname]\n            Schema table \"product\": [ProductID, CustomerID, name, surname, price]\n            Question: \"which products did Simone buy?\"\n            [/INST]\n            SELECT T1.name, T2.name FROM \"customer\" as T1 JOIN \"product\" as T2 WHERE T1.name == \"Simone\"\n            \"\"\"\n\n    def process_input(self,\n                      table: pd.DataFrame | None,\n                      db_table_schema: dict | None,\n                      query: str,\n                      query_tbl_name: str | list[str]) -&gt; Any | None:\n        if not db_table_schema:\n            raise ValueError('For Semantic Parsing JOIN, it is needed the schema of the database')\n\n        prompts = [f'[INST] Database table names: {list(db_table_schema.keys())}']\n\n        for name, schema in db_table_schema.items():\n            prompts.append(f'Schema table \"{name}\": {schema[\"name\"].tolist()}')\n\n        prompts.append(f'Question: \"{query}\"\\n[/INST]')\n        return \"\\n\".join(prompts)\n\n    def _normalize_output(self, text):\n        \"\"\"\n        Normalizes the text received from model predictions.\n\n        Simplifies the predicted SQL command by removing any new lines and extra quotations.\n\n        Args:\n            text (str): The raw text prediction from the underlying model.\n\n        Returns:\n            str: The normalized text.\n        \"\"\"\n        return text.replace('\\n', '').replace('\"', '').strip()\n</code></pre>"},{"location":"supported_models/#qatch.models.Omnitab","title":"<code>Omnitab</code>","text":"<p>             Bases: <code>AbstractModel</code></p> <p>The Omnitab class inherits from the AbstractModel and specializes it to parse tables using the Omnitab model.</p> <p>Attributes:</p> Name Type Description <code>tokenizer</code> <code>AutoTokenizer</code> <p>The tokenizer for input preprocessing.</p> <code>model</code> <code>AutoModelForSeq2SeqLM</code> <p>The model used to answer the queries from the table.</p> Note <ul> <li>The model used in this class is 'neulab/omnitab-large-finetuned-wtq'.</li> <li>The Omnitab model works specifically with tables that only contain strings  and has a model input limit of 1024 tokens.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt;import pandas as pd\n&gt;&gt;&gt;from qatch.models import Tapas\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = pd.DataFrame([\n...     [\"John Doe\", \"123-456-7890\"],\n...     [\"Jane Doe\", \"098-765-4321\"]\n... ], columns=[\"Name\", \"Phone Number\"])\n&gt;&gt;&gt;\n&gt;&gt;&gt; omnitab_model = Omnitab(\"'neulab/omnitab-large-finetuned-wtq'\")\n&gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n&gt;&gt;&gt; answer = omnitab_model.predict(table=data, query=query, tbl_name='Contact Info')\n&gt;&gt;&gt; print(answer)\n[['123-456-7890']]\n</code></pre> Source code in <code>qatch/models/omnitab.py</code> <pre><code>class Omnitab(AbstractModel):\n    \"\"\"\n    The Omnitab class inherits from the AbstractModel and specializes it to parse tables using the Omnitab model.\n\n    Attributes:\n        tokenizer (AutoTokenizer): The tokenizer for input preprocessing.\n        model (AutoModelForSeq2SeqLM): The model used to answer the queries from the table.\n\n    Note:\n        - The model used in this class is 'neulab/omnitab-large-finetuned-wtq'.\n        - The Omnitab model works specifically with tables that only contain strings\n         and has a model input limit of 1024 tokens.\n\n    Examples:\n        &gt;&gt;&gt;import pandas as pd\n        &gt;&gt;&gt;from qatch.models import Tapas\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; data = pd.DataFrame([\n        ...     [\"John Doe\", \"123-456-7890\"],\n        ...     [\"Jane Doe\", \"098-765-4321\"]\n        ... ], columns=[\"Name\", \"Phone Number\"])\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; omnitab_model = Omnitab(\"'neulab/omnitab-large-finetuned-wtq'\")\n        &gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n        &gt;&gt;&gt; answer = omnitab_model.predict(table=data, query=query, tbl_name='Contact Info')\n        &gt;&gt;&gt; print(answer)\n        [['123-456-7890']]\n    \"\"\"\n\n    def __init__(self, model_name: str, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n        self.model.to(self.device)\n\n    @override\n    def process_input(self, table: pd.DataFrame,\n                      query: str,\n                      tbl_name: str) -&gt; Any | None:\n        # Check dimensions of the table (rows*columns). If the size is larger than 1024,\n        # we return None with a warning log. This is due to the limitation of the model input size.\n        if table.shape[0] * table.shape[1] &gt; 1024:\n            logging.warning(\"Input is too long for model\")\n            return None\n\n        # The attributes of the DataFrame 'table' are converted to strings to make sure the table\n        # representation is in a consistent format.\n        table = table.astype(str)\n\n        # The content of the DataFrame 'table' is turned to lowercase in order to standardize the information.\n        for col in table.columns:\n            table[col] = table[col].str.lower()\n\n        # Also, the query is transformed into lowercase for the same standardization reasons.\n        query = query.lower()\n\n        try:\n            # The 'table' and 'query' are tokenized using the tokenizer.\n            model_input = self.tokenizer(table=table, queries=query, return_tensors=\"pt\")\n        except ValueError as e:\n            # A ValueError is expected if the tokenized input exceeds the length accepted by the model.\n            # If such error is raised, a warning log is returned, and the function returns None.\n            logging.warning(e)\n            return None\n\n        # Before returning the tokenized input, it checks once again the length of the input.\n        # If it's longer than 1024, a warning is logged and the function returns None.\n        if model_input.input_ids.shape[1] &gt; 1024:\n            logging.warning(\"Input is too long for model\")\n            return None\n\n        # If all the above checks pass, the processed input is returned, set to the appropriate device for feeding\n        # into the model subsequently.\n        return model_input.to(self.device)\n\n    @override\n    def predict_input(self, model_input, table) -&gt; list[list[list[str]]]:\n        outputs = self.model.generate(**model_input)\n        return self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n</code></pre>"},{"location":"supported_models/#qatch.models.Tapas","title":"<code>Tapas</code>","text":"<p>             Bases: <code>AbstractModel</code></p> <p>The Tapas class inherits from the AbstractModel and specializes it to parse tables using the TAPAS model.</p> <p>Attributes:</p> Name Type Description <code>tokenizer</code> <code>TapasTokenizer</code> <p>The tokenizer for input preprocessing.</p> <code>model</code> <code>TapasForQuestionAnswering</code> <p>The model used to answer the queries from the table.</p> Note <ul> <li>The model used in this class is <code>google/tapas-large-finetuned-wtq</code>.</li> <li>The TAPAS model works specifically with tables that only contain strings  and has a model input limit of 512 tokens.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt;import pandas as pd\n&gt;&gt;&gt;from qatch.models import Tapas\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = pd.DataFrame([\n...     [\"John Doe\", \"123-456-7890\"],\n...     [\"Jane Doe\", \"098-765-4321\"]\n... ], columns=[\"Name\", \"Phone Number\"])\n&gt;&gt;&gt;\n&gt;&gt;&gt; tapas_model = Tapas(\"google/tapas-large-finetuned-wtq\")\n&gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n&gt;&gt;&gt; answer = tapas_model.predict(table=data, query=query, tbl_name='Contact Info')\n&gt;&gt;&gt; print(answer)\n[['123-456-7890']]\n</code></pre> Source code in <code>qatch/models/tapas.py</code> <pre><code>class Tapas(AbstractModel):\n    \"\"\"\n    The Tapas class inherits from the AbstractModel and specializes it to parse tables using the TAPAS model.\n\n    Attributes:\n        tokenizer (TapasTokenizer): The tokenizer for input preprocessing.\n        model (TapasForQuestionAnswering): The model used to answer the queries from the table.\n\n    Note:\n        - The model used in this class is `google/tapas-large-finetuned-wtq`.\n        - The TAPAS model works specifically with tables that only contain strings\n         and has a model input limit of 512 tokens.\n\n    Examples:\n        &gt;&gt;&gt;import pandas as pd\n        &gt;&gt;&gt;from qatch.models import Tapas\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; data = pd.DataFrame([\n        ...     [\"John Doe\", \"123-456-7890\"],\n        ...     [\"Jane Doe\", \"098-765-4321\"]\n        ... ], columns=[\"Name\", \"Phone Number\"])\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; tapas_model = Tapas(\"google/tapas-large-finetuned-wtq\")\n        &gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n        &gt;&gt;&gt; answer = tapas_model.predict(table=data, query=query, tbl_name='Contact Info')\n        &gt;&gt;&gt; print(answer)\n        [['123-456-7890']]\n    \"\"\"\n\n    def __init__(self, model_name: str, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.tokenizer = TapasTokenizer.from_pretrained(model_name)\n        self.model = TapasForQuestionAnswering.from_pretrained(model_name)\n        self.model.to(self.device)\n\n    def process_input(self, table: pd.DataFrame,\n                      query: str,\n                      tbl_name: str) -&gt; Any | None:\n        if table.shape[0] * table.shape[1] &gt; 512:\n            return None\n\n        # convert table to string\n        table = table.astype(str)\n        # tokenize inputs\n        try:\n            model_input = self.tokenizer(table=table,\n                                         queries=query,\n                                         padding=\"max_length\",\n                                         return_tensors=\"pt\")\n        except ValueError as e:\n            # we get error when the tokenized input is longer than accepted from model\n            logging.warning(e)\n            return None\n\n        return model_input.to(self.device)\n\n    def predict_input(self, model_input, table) -&gt; list[Any]:\n        # Step 1: Pass the model_input to the model for forward propagation to generate outputs.\n        outputs = self.model(**model_input)\n        # Step 2: Move the model_input tensor to cpu.\n        model_input.to('cpu')\n        # Step 3: Move the output tensors to CPU and detach them from the computational graph.\n        outputs = {idx: outputs[idx].cpu().detach() for idx in outputs}\n        # Step 4: Detach any tensors in model_input from the computational graph.\n        [model_input[idx].detach() for idx in model_input]\n\n        # Step 5: Retrieve the coordinates from the logits using a tokenizer function.\n        pred_query_cords, _ = self.tokenizer.convert_logits_to_predictions(\n            model_input,\n            outputs['logits'],\n            outputs['logits_aggregation']\n        )\n        # Step 6: Construct a list of answers.\n        answers = []\n        for tbl_cords in pred_query_cords:\n            query_answer = defaultdict(list)\n            # For each coordinate set in the predicted query coordinates,\n            # construct a dictionary of row-wise query answers.\n            [query_answer[row].append(table.iat[(row, col)])\n             for row, col in tbl_cords]\n            answers.extend(list(query_answer.values()))\n        # Step 7: Dispose of potentially memory-heavy variables.\n        del model_input\n        del outputs\n        # Step 8: Return the list of processed query answers derived from the model's predictions.\n        return answers\n</code></pre>"},{"location":"supported_models/#qatch.models.Tapex","title":"<code>Tapex</code>","text":"<p>             Bases: <code>AbstractModel</code></p> <p>The Tapex class inherits from the AbstractModel and specializes it to parse tables using the TAPEX model.</p> <p>Attributes:</p> Name Type Description <code>tokenizer</code> <code>TapexTokenizer</code> <p>The tokenizer for input preprocessing.</p> <code>model</code> <code>BartForConditionalGeneration</code> <p>The model used to answer the queries from the table.</p> Note <ul> <li>The model used in this class is 'microsoft/tapex-large-finetuned-wtq'.</li> <li>The TAPEX model works specifically with tables that only contain strings  and has a model input limit of 1024 tokens.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from qatch.models import Tapex\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = pd.DataFrame([\n...     [\"John Doe\", \"123-456-7890\"],\n...     [\"Jane Doe\", \"098-765-4321\"]\n... ], columns=[\"Name\", \"Phone Number\"])\n&gt;&gt;&gt;\n&gt;&gt;&gt; tapex_model = Tapex(\"microsoft/tapex-large-finetuned-wtq\")\n&gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n&gt;&gt;&gt; answer = tapex_model.predict(table=data, query=query, tbl_name='Contact Info')\n&gt;&gt;&gt; print(answer)\n[['123-456-7890']]\n</code></pre> Source code in <code>qatch/models/tapex.py</code> <pre><code>class Tapex(AbstractModel):\n    \"\"\"\n    The Tapex class inherits from the AbstractModel and specializes it to parse tables using the TAPEX model.\n\n    Attributes:\n        tokenizer (TapexTokenizer): The tokenizer for input preprocessing.\n        model (BartForConditionalGeneration): The model used to answer the queries from the table.\n\n    Note:\n        - The model used in this class is 'microsoft/tapex-large-finetuned-wtq'.\n        - The TAPEX model works specifically with tables that only contain strings\n         and has a model input limit of 1024 tokens.\n\n    Examples:\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; from qatch.models import Tapex\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; data = pd.DataFrame([\n        ...     [\"John Doe\", \"123-456-7890\"],\n        ...     [\"Jane Doe\", \"098-765-4321\"]\n        ... ], columns=[\"Name\", \"Phone Number\"])\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; tapex_model = Tapex(\"microsoft/tapex-large-finetuned-wtq\")\n        &gt;&gt;&gt; query = \"What is John Doe's phone number?\"\n        &gt;&gt;&gt; answer = tapex_model.predict(table=data, query=query, tbl_name='Contact Info')\n        &gt;&gt;&gt; print(answer)\n        [['123-456-7890']]\n    \"\"\"\n\n    def __init__(self, model_name: str, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.tokenizer = TapexTokenizer.from_pretrained(model_name)\n        self.model = BartForConditionalGeneration.from_pretrained(model_name)\n        self.model.to(self.device)\n\n    def process_input(self, table: pd.DataFrame,\n                      query: str,\n                      tbl_name: str) -&gt; Any | None:\n        if table.shape[0] * table.shape[1] &gt; 1024:\n            return None\n\n        # convert table to string\n        table = table.astype(str)\n        # process table\n        for col in table.columns:\n            table[col] = table[col].str.lower()\n\n        # tapex accepts uncased input since it is pre-trained on the uncased corpus\n        query = query.lower()\n        try:\n            model_input = self.tokenizer(table=table, query=query,\n                                         padding=True, return_tensors=\"pt\")\n        except ValueError as e:\n            # we get error when the tokenized input is longer than accepted from model\n            logging.warning(e)\n            return None\n\n        if model_input.input_ids.shape[1] &gt; 1024:\n            warnings.warn(f'After tokenization'\n                          f' the input is longer than 1024 tokens: '\n                          f'{model_input.input_ids.shape[1]}. '\n                          'the input will be skipped')\n            return None\n\n        return model_input.to(self.device)\n\n    def predict_input(self, model_input, table) -&gt; list[Any]:\n        outputs = self.model.generate(**model_input)\n        model_input.to('cpu')\n\n        [model_input[idx].detach() for idx in model_input]\n        outputs = outputs.detach().cpu()\n\n        # decode back to text\n        pred_cells_queries = self.tokenizer.batch_decode(outputs,\n                                                         skip_special_tokens=True)\n        # the output contains list of string for each query. Manually transform the output\n        answers = []\n        for pred_query in pred_cells_queries:\n            query_ans = self._return_cells_aggr_by_row(table, pred_query)\n            answers.extend(query_ans)\n        del model_input\n        del outputs\n        return answers\n\n    @staticmethod\n    def _return_cells_aggr_by_row(table, pred_query):\n        \"\"\"\n        Perform an aggregation operation by row of the cells in a specified table based on a predicate query.\n\n        Args:\n            table (np.array): The table to perform the operation on.\n            pred_query (str): The predicate query used for aggregation operation. It should be a string of comma\n                              separated cell values, e.g., \"cell1,cell2,cell3\".\n\n        Returns:\n            list: Returns a list of lists where each sublist contains aggregated cell values from a single row of the table.\n\n        Example:\n            Let's assume we have a table as below:\n\n            [[\"cell1\", \"cell2\"],\n            [\"cell3\", \"cell1\"],\n            [\"cell1\", \"cell2\"]]\n\n            And pred_query as \"cell1,cell1,cell2\"\n\n            Calling _return_cells_aggr_by_row(table, pred_query) will give:\n\n            [[\"cell1\", \"cell2\"], [\"cell1\"], [\"cell1\", \"cell2\"]]\n\n        Note:\n            If a cell from the pred_query is not present in the table, the method treats it as if it's in an imaginary\n            row indexed as -1. Therefore, if you see a [-1] in the result, it means one or more cells in your pred_query\n            did not appear in the table.\n        \"\"\"\n        # Initializing a defaultdict to store the results of the query\n        query_ans = defaultdict(list)\n        # Splitting the query into cells\n        cells: list = pred_query.split(\",\")\n        # Counting the occurrences of each cell in the query\n        counted_cells = Counter(cells)\n        # Iterating over each cell type and its count from the counted_cells\n        for cell, count in counted_cells.items():\n            # Finding the row ids where the current cell type exists in the table\n            row_ids = np.where(table == cell.strip())[0]\n            if len(row_ids) == 0:\n                # If the cell is not present in the table, set the row_id as -1\n                row_ids = [-1]\n\n            # If the count of cell in the query &gt; 1, select the first 'count' number of rows\n            if count &gt; 1:\n                row_ids = row_ids[:count]\n            # Appending the cell to the rows in the query_ans for each row_id\n            [query_ans[idx].append(cell.strip()) for idx in row_ids]\n        # Return the aggregated cells from each row as a list of lists\n        return list(query_ans.values())\n</code></pre>"}]}